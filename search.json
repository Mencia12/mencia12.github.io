[{"title":"Hexo|用Hexo写博客","url":"/2019/05/19/Hexo%E5%91%BD%E4%BB%A4/","content":"简单总结使用的hexo命令\nHexo更新1、全局升级hexo-cli，先hexo version查看当前版本，然后npm i hexo-cli -g，再次hexo version查看是否升级成功。2、使用npm install -g npm-check和npm-check，检查系统中的插件是否有升级的，可以看到自己前面都安装了那些插件3、使用npm install -g npm-upgrade和npm-upgrade，升级系统中的插件4、使用npm update -g和npm update --save\n部署网站hexo clean #清除缓存 网页正常情况下可以忽略此条命令hexo g #生成静态网页hexo d #开始部署\n创建新文章hexo n title\n屏蔽文章在你不希望渲染的md文章文件前加上一个下划线&quot;_&quot;即可\n服务器hexo server #Hexo会监视文件变动并自动更新，您无须重启服务器。hexo server -s #静态模式hexo server -p 5000 #更改端口hexo server -i 192.168.1.1 #自定义 IP\n插件npm install hexo-neat --save-dev #优化加速npm install hexo-asset-image --save #添加本地图库npm install hexo-generator-searchdb --save #配置本地搜索npm install hexo-generator-index-pin-top --save #文章置顶\n解决无法显示数学公式第一步：更换渲染引擎\nnpm uninstall hexo-renderer-markednpm install hexo-renderer-kramed\n第二步：开启 NexT 主题的 MathJax 支持\n打开 主题配置文件 _config.next.yml（注意不是博客根目录的那个），搜索 math，修改如下配置：\nmath:  # Default (false) will load mathjax / katex script on demand.  # That is it only render those page which has `mathjax: true` in front-matter.  # If you set it to true, it will load mathjax / katex script EVERY PAGE.  every_page: true  mathjax:    enable: true    # Available values: none | ams | all    tags: all  katex:    enable: false    # See: https://github.com/KaTeX/KaTeX/tree/master/contrib/copy-tex    copy_tex: false\n第三步：在文章中启用公式为了防止网站加载过慢，NexT 默认不会在所有页面加载巨大的数学公式库。 你需要在那篇包含数学公式的文章顶部（Front-matter），手动加上 mathjax: true。\n示例：---title: 算法复杂度分析date: 2025-12-22 17:00:00tags: [Algorithm, Math]mathjax: true  &lt;-- 加上这一行---这里是正文...$$T(n)=2T(\\sqrt&#123;n&#125;)+ \\log n$$\nGithub备份博客源文件在github博客仓库下新建一个分支hexo，然后git clone到本地，把.git文件夹拿出来，放在博客根目录下\ngit checkout hexo #切换到hexo分支git add . #添加当前目录下的所有文件到暂存区git commit -m &quot;xxx&quot; #注释git push #提交\n同步git pull #同步\nMarkdown表情https://www.jianshu.com/p/0520359a18d5\n符号&amp;公式https://blog.csdn.net/gsww404/article/details/78684278https://www.jianshu.com/p/16fbd768bfe7\n","tags":["Hexo"]},{"title":"kindle书籍排版","url":"/2025/12/23/kindle/","content":"更新一些用于AZW3格式的排版\n字体通用/* 字体 */@page &#123;  margin-bottom: 5pt;  margin-top: 5pt;&#125;@font-face &#123;  font-family: &quot;&quot;;  src: url(&quot;..&quot;);&#125;@font-face &#123;  font-family: &quot;&quot;;  src: url(&quot;..&quot;);&#125;\n个人专用/* 字体 */@page &#123;  margin-bottom: 5pt;  margin-top: 5pt;&#125;@font-face &#123;  font-family: &quot;fzlt&quot;;  src: url(&quot;../fzltZH.ttf&quot;);&#125;@font-face &#123;  font-family: &quot;syst&quot;;  src: url(&quot;../systB.ttf&quot;);&#125;\n常用字体标题：systB.ttf，fzltZH.ttf\n正文：hysf65W.ttf（比较粗的仿宋），fzyST.ttf\n生僻字：bsh.ttf\n排版格式基本格式/* 文本 */.hd &#123;  display: block;  line-height: 1.4;&#125;.txt &#123;  display: block;  line-height: 1.4;  text-align: justify;  text-indent: 2em;&#125;/* 章标题 */.chapter-sequence-number &#123;  font-family: &quot;fzlt&quot;;  font-size: 1rem;  padding: 2px 4px;&#125;.chapter-title &#123;  display: block;  font-family: &quot;syst&quot;;  font-size: 1.2em;  line-height: 1.4;  text-align: center;&#125;.chapter-subtitle &#123;  font-size: 0.7em;&#125;.hd1 &#123;  display: block;&#125;/* 卷标题 横排 */.volume-title &#123;  display: block;  font-family: &quot;DK-KAITI&quot;, &quot;楷体&quot;, &quot;方正楷体_GBK&quot;, &quot;KaiTi&quot;, &quot;STKaiti&quot;, &quot;STKai&quot;, &quot;kt&quot;, serif;  font-size: 1.3em;  line-height: 1.4;  text-align: center;  margin: 30% auto;&#125;.volume-subtitle &#123;  display: block;  font-family: &quot;syst&quot;;  text-align: center;&#125;.hd1 &#123;  display: block;&#125;\n/* 卷标题下方有字可用 */.vtxt &#123;  display: block;  font-family: &quot;DK-KAITI&quot;, &quot;楷体&quot;, &quot;方正楷体_GBK&quot;, &quot;KaiTi&quot;, &quot;STKaiti&quot;, &quot;STKai&quot;, &quot;kt&quot;, serif;  line-height: 1.4;  text-align: justify;  text-indent: 2em;  margin-top: -20%;  padding-top: 0;  max-width: 60%;  margin-left: auto;  margin-right: auto;&#125;\n/* 卷标题 竖排 */.head &#123;  display: block;  line-height: 1.4;  text-align: center;  width: 1.4em;  margin: 25% auto;&#125;.head1 &#123;  display: block;  font-family: &quot;STKai&quot;, &quot;DK-FANGSONG&quot;, &quot;方正仿宋_GBK&quot;, &quot;kt&quot;, serif;  font-size: 1.4em;  font-weight: bold;  line-height: 1.4;  text-align: center;&#125;.head2 &#123;  display: block;  font-family: &quot;STKai&quot;, &quot;DK-FANGSONG&quot;, &quot;方正仿宋_GBK&quot;, &quot;kt&quot;, serif;  font-size: 1.4em;  font-weight: bold;  line-height: 1.4;  text-align: center;&#125;\n封面图/* 封面图 */.pic &#123;  height: auto;  line-height: 1.4;  width: auto;&#125;.cover &#123;  display: block;  line-height: 1.4;  margin-bottom: 1em;  margin-top: 1em;  text-align: center;  width: 100%;&#125;\n注释/* 注释 */.zhusi &#123;  display: block;  font-family: &quot;DK-KAITI&quot;, &quot;楷体&quot;, &quot;方正楷体_GBK&quot;, &quot;KaiTi&quot;, &quot;STKaiti&quot;, &quot;STKai&quot;, &quot;kt&quot;, serif;  font-size: 1em;  line-height: 1.5;  text-indent: 2em;&#125;.fenge &#123;  color: gray;  display: block;  height: 2px;  line-height: 1.4;  margin: 0.5em auto;  border: currentColor inset 1px;&#125;.math-super &#123;  font-family: &quot;DK-KAITI&quot;, &quot;楷体&quot;, &quot;方正楷体_GBK&quot;, &quot;KaiTi&quot;, &quot;STKaiti&quot;, &quot;STKai&quot;, &quot;kt&quot;, serif;  font-size: 0.75em;  vertical-align: super;&#125;.zs &#123;  line-height: 1.4;  text-decoration: none;&#125;\n分割线/* 分割线 */.fg &#123;  text-align: center;  margin: 2em 0 2em;&#125;\n&lt;p class=&quot;fg&quot;&gt;────── · ✦ · ──────&lt;/p&gt;\n正则替换章节名&lt;h2 class=&quot;chapter-title&quot;&gt;&lt;span class=&quot;chapter-sequence-number&quot;&gt;\\1&lt;/span&gt;&lt;br class=&quot;hd1&quot;/&gt; \\2&lt;span class=&quot;chapter-subtitle&quot;&gt;（\\3）&lt;/span&gt;&lt;/h2&gt;\n&lt;h2 class=&quot;chapter-title&quot;&gt;&lt;span class=&quot;chapter-sequence-number&quot;&gt;\\1&lt;/span&gt;&lt;br class=&quot;hd1&quot;/&gt; \\2&lt;/h2&gt;\n&lt;h2 class=&quot;chapter-title&quot;&gt;\n卷名横排&lt;h1 id=&quot;title&quot; class=&quot;volume-title&quot;&gt;\\1&lt;br class=&quot;hd1&quot;/&gt;&lt;span class=&quot;volume-subtitle&quot;&gt; \\2&lt;/span&gt;&lt;/h1&gt;\n竖排&lt;div class=&quot;head&quot;&gt;  &lt;h1 class=&quot;head1&quot; title=&quot;\\1 \\2&quot;&gt;\\1&lt;/h1&gt;  &lt;p class=&quot;head2&quot;&gt;\\2&lt;/p&gt;&lt;/div&gt;\n注释分隔线\n&lt;hr class=&quot;fenge&quot;/&gt;\n字上标号\n&lt;sup class=&quot;math-super&quot;&gt;&lt;a class=&quot;zs&quot; href=&quot;\\1.html#m\\2&quot; id=&quot;w\\2&quot;&gt;\\2&lt;/a&gt;&lt;/sup&gt;\n注释标号\n&lt;p class=&quot;zhusi&quot;&gt;&lt;a href=&quot;\\1.html#w\\2&quot; id=&quot;m\\2&quot;&gt;[\\2]&lt;/a&gt;\n封面&lt;div class=&quot;cover&quot;&gt;\t&lt;img alt=&quot;&quot; class=&quot;pic&quot; src=&quot;../images/\\2.jpeg&quot;/&gt;&lt;/div&gt;\n默认字体宋体    STSongfont-family: STSong, serif;\n黑体    STHeitifont-family: STHeiti, san-serif;\n楷体    STKaifont-family: STKai, serif;\n圆体    STYuanfont-family: STYuan, san-serif;\nEasyPub查找规则&lt;body class=&quot;calibre1&quot;&gt;|&lt;p class=&quot;a&quot;&gt;　　|&lt;h2 id=&quot;title&quot; class=&quot;titletoc&quot;&gt;.*?&lt;/h2&gt;|&lt;h2 id=&quot;title&quot; class=&quot;titlel2single&quot;&gt;.*?&lt;/h2&gt;\n正则替换函数import redef replace(match, number, file_name, metadata, dictionaries, data, functions, *args, **kwargs):    text = match.group(0)    # &lt;body class=&quot;calibre1&quot;&gt; → &lt;body class=&quot;hd&quot;&gt;    if &#x27;&lt;body class=&quot;calibre1&quot;&gt;&#x27; in text:        return &#x27;&lt;body class=&quot;hd&quot;&gt;&#x27;    # &lt;p class=&quot;a&quot;&gt;　　 → &lt;p class=&quot;txt&quot;&gt;    if re.search(r&#x27;&lt;p class=&quot;a&quot;&gt;　　&#x27;, text):        return re.sub(r&#x27;&lt;p class=&quot;a&quot;&gt;　　&#x27;, &#x27;&lt;p class=&quot;txt&quot;&gt;&#x27;, text)    # &lt;h2 id=&quot;title&quot; class=&quot;titletoc&quot;&gt;X（Y）&lt;/h2&gt;  →  有三段结构（章节号 标题 （副标题））    if re.search(r&#x27;&lt;h2 id=&quot;title&quot; class=&quot;titletoc&quot;&gt;(.*?) (.*?)（(.*?)）&lt;/h2&gt;&#x27;, text):        return re.sub(            r&#x27;&lt;h2 id=&quot;title&quot; class=&quot;titletoc&quot;&gt;(.*?) (.*?)（(.*?)）&lt;/h2&gt;&#x27;,            (                &#x27;&lt;h2 class=&quot;chapter-title&quot;&gt;\\n&#x27;                &#x27;&lt;span class=&quot;chapter-sequence-number&quot;&gt;\\\\1&lt;/span&gt;\\n&#x27;                &#x27;&lt;br  class=&quot;hd1&quot;/&gt; \\\\2\\n&#x27;                &#x27;&lt;span class=&quot;chapter-subtitle&quot;&gt;（\\\\3）&lt;/span&gt;&lt;/h2&gt;&#x27;            ),            text        )    # &lt;h2 id=&quot;title&quot; class=&quot;titletoc&quot;&gt;X Y&lt;/h2&gt; → 两段结构（章节号 标题）    if re.search(r&#x27;&lt;h2 id=&quot;title&quot; class=&quot;titletoc&quot;&gt;(.*?) (.*?)&lt;/h2&gt;&#x27;, text):        return re.sub(            r&#x27;&lt;h2 id=&quot;title&quot; class=&quot;titletoc&quot;&gt;(.*?) (.*?)&lt;/h2&gt;&#x27;,            (                &#x27;&lt;h2 class=&quot;chapter-title&quot;&gt;\\n&#x27;                &#x27;&lt;span class=&quot;chapter-sequence-number&quot;&gt;\\\\1&lt;/span&gt;\\n&#x27;                &#x27;&lt;br  class=&quot;hd1&quot;/&gt; \\\\2&lt;/h2&gt;&#x27;            ),            text        )    # &lt;h2 id=&quot;title&quot; class=&quot;titletoc&quot;&gt;X&lt;/h2&gt; → 单独标题    if re.search(r&#x27;&lt;h2 id=&quot;title&quot; class=&quot;titletoc&quot;&gt;(.*?)&lt;/h2&gt;&#x27;, text):        return re.sub(            r&#x27;&lt;h2 id=&quot;title&quot; class=&quot;titletoc&quot;&gt;(.*?)&lt;/h2&gt;&#x27;,            r&#x27;&lt;h2 class=&quot;chapter-title&quot;&gt;\\1&lt;/h2&gt;&#x27;,            text        )    # &lt;h2 id=&quot;title&quot; class=&quot;titlel2single&quot;&gt;X Y&lt;/h2&gt; → &lt;h1&gt; 卷标题结构    if re.search(r&#x27;&lt;h2 id=&quot;title&quot; class=&quot;titlel2single&quot;&gt;(.*?) (.*?)&lt;/h2&gt;&#x27;, text):        return re.sub(            r&#x27;&lt;h2 id=&quot;title&quot; class=&quot;titlel2single&quot;&gt;(.*?) (.*?)&lt;/h2&gt;&#x27;,            (                &#x27;&lt;h1 id=&quot;title&quot; class=&quot;volume-title&quot;&gt;\\\\1&lt;br class=&quot;hd1&quot;/&gt;\\n&#x27;                &#x27;&lt;span class=&quot;volume-subtitle&quot;&gt; \\\\2&lt;/span&gt;&lt;/h1&gt;&#x27;            ),            text        )    # 未匹配则返回原文    return text\nazw3转epub转换后修改hd1\n.hd1 &#123;  display: block;  margin: 0.1em auto;&#125;\n阿蒙读书查找规则(?s).*\n正则替换函数import redef replace(match, number, file_name, metadata, dictionaries, data, functions, *args, **kwargs):    text = match.group(0)    remove_patterns = [        r&#x27;&lt;div id=&quot;book-columns&quot; class=&quot;calibre1&quot;&gt;&#x27;,        r&#x27;&lt;div id=&quot;book-inner&quot; class=&quot;calibre1&quot;&gt;&#x27;,        r&#x27;&lt;span id=&quot;kobo\\.\\d+\\.\\d+&quot;&gt;&#x27;,        r&#x27;&lt;img[^&gt;]+src=&quot;\\.\\./images/\\d+\\.png&quot;[^&gt;]*/?&gt;\\s*&lt;/span&gt;\\s*&lt;br[^&gt;]*&gt;&#x27;,    ]    for p in remove_patterns:        text = re.sub(p, &#x27;&#x27;, text, flags=re.DOTALL)    text = re.sub(        r&#x27;&lt;div\\s+class=&quot;calibre1&quot;&gt;\\s*&lt;hr\\s+class=&quot;xian&quot;\\s*/&gt;\\s*&lt;/div&gt;\\s*&lt;ol\\s+class=&quot;duokan-footnote-content&quot;\\s*&gt;&#x27;,        &#x27;&lt;hr class=&quot;fenge&quot;/&gt;&#x27;,        text,        flags=re.I | re.S    )        text = re.sub(        r&#x27;&lt;a[^&gt;]*class=&quot;duokan-footnote&quot;[^&gt;]*type=&quot;noteref&quot;[^&gt;]*href=&quot;([^#&quot;]+)#B_(\\d+)&quot;[^&gt;]*id=&quot;A_\\2&quot;[^&gt;]*&gt;.*?&lt;/a&gt;&#x27;,        r&#x27;&lt;sup class=&quot;math-super&quot;&gt;&lt;a class=&quot;zs&quot; href=&quot;\\1#m\\2&quot; id=&quot;w\\2&quot;&gt;\\2&lt;/a&gt;&lt;/sup&gt;&#x27;,        text,        flags=re.I | re.S    )    text = re.sub(        r&#x27;&lt;li class=&quot;duokan-footnote-item&quot; id=&quot;B_(\\d+)&quot;&gt;\\s*&lt;p class=&quot;footnote&quot;&gt;&lt;a href=&quot;(.*?).html#A_\\1&quot; class=&quot;duokan-footnote&quot;&gt;.*?&lt;/a&gt;&#x27;,        r&#x27;&lt;p class=&quot;zhusi&quot;&gt;&lt;a href=&quot;\\2.html#w\\1&quot; id=&quot;m\\1&quot;&gt;[\\1]&lt;/a&gt;&#x27;,        text,        flags=re.DOTALL    )        return text\n","tags":["CSS"]},{"title":"漫画图片整理","url":"/2024/08/20/%E6%BC%AB%E7%94%BB/","content":"简单图片操作\n图片模式双页图片错位向图片文件夹添加图片，并重命名def Img_Copy(source_image, target_folder, new_image_name):    # 获取目标文件夹中的所有子文件夹    subfolders = [f.path for f in os.scandir(target_folder) if f.is_dir()]    for subfolder in subfolders:        # 生成新图片的完整路径        new_image_path = os.path.join(subfolder, new_image_name)        # 将图片复制到子文件夹中，并重命名        shutil.copy(source_image, new_image_path)        print(f&quot;Copied &#123;source_image&#125; to &#123;new_image_path&#125;&quot;)\n移除多余的图片def Img_Move(root_folder, out_folder, idxs, c=0):    for subdir, _, _ in os.walk(root_folder):        if subdir == root_folder:            continue        image_path = []        folder = sorted(os.listdir(subdir))        for image_file in folder:            image_path.append(os.path.join(subdir, image_file))        image_path.sort()        for j in idxs:            if c:                shutil.copy(image_path[j],                            os.path.join(out_folder, os.path.basename(subdir) + &quot;_&quot; + os.path.basename(image_path[j])))            else:                shutil.move(image_path[j], os.path.join(out_folder, os.path.basename(subdir) + &quot;_&quot; + os.path.basename(image_path[j])))\n整理图片每个文件夹下图片命名格式不统一，按顺序重命名图片。还可以指定图片移到最后def rename_image(parent_folder_path, i=1):    # 获取主文件夹下所有子文件夹    subfolders = [f.path for f in os.scandir(parent_folder_path) if f.is_dir()]    for subfolder in subfolders:        # 获取子文件夹中的所有图片文件        images = [f for f in os.listdir(subfolder) if f.lower().endswith((&#x27;.png&#x27;, &#x27;.jpg&#x27;, &#x27;.jpeg&#x27;, &#x27;.bmp&#x27;, &#x27;.gif&#x27;))]        # 确保有足够的图片文件        if len(images) &lt; 2:            print(f&quot;&#123;subfolder&#125; 文件夹中没有足够的图片。&quot;)            continue        # 排序文件名（如果需要按顺序）        images.sort()        for index, image in enumerate(images, start=1):            original_extension = os.path.splitext(image)[1]  # 获取文件后缀            new_name = f&quot;img&#123;index:04d&#125;&#123;original_extension&#125;&quot;  # 新文件名            original_path = os.path.join(subfolder, image)            new_path = os.path.join(subfolder, new_name)            # 重命名文件            os.rename(original_path, new_path)            print(f&quot;已将 &#123;original_path&#125; 重命名为 &#123;new_path&#125;.&quot;)                    # 获取总图片数量        total_images = len(images)        # 找到第i张图片并重命名        original_extension = os.path.splitext(images[i])[1]  # 获取文件后缀        i_image = f&quot;img&#123;i+1:04d&#125;&#123;original_extension&#125;&quot;        new_filename = f&quot;img&#123;total_images+1:04d&#125;&#123;original_extension&#125;&quot;  # 新文件名        original_path = os.path.join(subfolder, i_image)        new_path = os.path.join(subfolder, new_filename)        os.rename(original_path, new_path)        print(f&quot;已将 &#123;subfolder&#125; 中的 &#123;i_image&#125; 重命名为 &#123;new_filename&#125;.&quot;)\n\n\n\n\n","tags":["Python"]},{"title":"刷刷刷","url":"/2023/04/03/%E5%88%B7%E5%88%B7%E5%88%B7/","content":"刷题记录\n\n1053. 交换一次的先前排列解：组合数学字典序法的逆序class Solution &#123;public:    vector&lt;int&gt; prevPermOpt1(vector&lt;int&gt;&amp; arr) &#123;        int n = arr.size();        for (int i = n - 1; i &gt; 0; i--)&#123;            if (arr[i - 1] &gt; arr[i]) &#123;                for (int j = n - 1; j &gt; i - 1; j--) &#123;                    if (arr[j] &lt; arr[i - 1] &amp;&amp; arr[j] != arr[j - 1])&#123;                        int t = arr[j];                        arr[j] = arr[i - 1];                        arr[i - 1] = t;                        return arr;                    &#125;                &#125;            &#125;        &#125;        return arr;    &#125;&#125;;\n2399. 检查相同字母间的距离解：哈希表先记录每个字符的第一次的位置，第二次遇到时计算距离并与距离数组比对。\nclass Solution:    def checkDistances(self, s: str, distance: List[int]) -&gt; bool:        d = defaultdict(int)        for i, c in enumerate(s, 1):            if d[c] and i - d[c] - 1 != distance[ord(c) - ord(&#x27;a&#x27;)]:                return False            d[c] = i        return True\n1125. 最小的必要团队解：\n1019. 链表中的下一个更大节点解：采用单调栈的方法。如果栈顶元素小于等于当前元素，则循环将栈顶元素出栈，直到栈顶元素大于当前元素或者栈为空。如果此时栈为空，则说明当前元素没有下一个更大的元素，否则当前元素的下一个更大的元素就是栈顶元素。更新ans数组。然后将当前元素入栈，继续遍历。\n# Definition for singly-linked list.# class ListNode:#     def __init__(self, val=0, next=None):#         self.val = val#         self.next = nextclass Solution:    def nextLargerNodes(self, head: Optional[ListNode]) -&gt; List[int]:        nums = []        while head:            nums.append(head.val)            head = head.next        stk = []        n = len(nums)        ans = [0] * n        for i in range(n - 1, -1, -1) :            while stk and stk[-1] &lt;= nums[i]:                stk.pop()            if stk:                ans[i] = stk[-1]            stk.append(nums[i])        return ans\n1041. 困于环中的机器人解：模拟。一轮后回到原点或者朝向改变，可以判断为在环中。\nclass Solution:    def isRobotBounded(self, instructions: str) -&gt; bool:        k = 0        dist = [0] * 4        for c in instructions:            if c == &#x27;L&#x27;:                k = (k + 1) % 4            elif c == &#x27;R&#x27;:                k = (k + 3) % 4             else:                dist[k] += 1        return (dist[0] == dist[2] and dist[1] == dist[3]) or k != 0\n1147. 段式回文1157. 子数组中占绝大多数的元素解：随机化 + 二分查找。\n1）若区间的「绝对众数」存在。每次随机至少有$1/2$的概率选中，每次查询的正确性为$1-(1/2)^k$\n2）计算随机数$x$的出现次数。使用一个哈希表来存储每个数出现的位置，在哈希表中以x为键得到的数组上，分别二分查找左右指针的插入位置，两者之差就是区间内$x$的个数。\n3）如果$x$个数大于等于要求值，返回$x$；如果小于要求值且大于等于区间的一半，说明区间内最多的数也无法满足要求，即不存在绝对众数。\nclass MajorityChecker:    k = 20    def __init__(self, arr: List[int]):        self.arr = arr        self.loc = defaultdict(list)        for i, val in enumerate(arr):            self.loc[val].append(i)    def query(self, left: int, right: int, threshold: int) -&gt; int:        arr_ = self.arr        loc_ = self.loc                length = right - left + 1        for i in range(MajorityChecker.k):            x = arr_[randint(left, right)]            pos = loc_[x]            occ = bisect_right(pos, right) - bisect_left(pos, left)            if occ &gt;= threshold:                return x            elif occ * 2 &gt;= length:                return -1        return -1\n2409. 统计共同度过的日子数解：模拟。寻找两个时间区间的交集，即起始为到达时间中最晚的点，末尾为离开时间中最早的点。将日期转换为天数，两者之差即为结果。若为负数，返回0。\nclass Solution:    def countDaysTogether(self, arriveAlice: str, leaveAlice: str, arriveBob: str, leaveBob: str) -&gt; int:        a = max(arriveAlice, arriveBob)        b = min(leaveAlice, leaveBob)        days = (31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31)        x = sum(days[:int(a[:2]) - 1]) + int(a[3:])        y = sum(days[:int(b[:2]) - 1]) + int(b[3:])        return max(y - x + 1, 0)\n分隔数组以得到最大和class Solution:    def maxSumAfterPartitioning(self, arr: List[int], k: int) -&gt; int:        n = len(arr)        f = [0] * (n + 1)        for i in range(1, n + 1):            mx = 0            for j in range(i, max(0, i - k), -1):                mx = max(mx, arr[j - 1])                f[i] = max(f[i], f[j - 1] + mx * (i - j + 1))        return f[n]\n1222. 可以攻击国王的皇后解：先将所有皇后的位置存入哈希表或者二维数组 sss 中。从国王的位置开始，依次向上、下、左、右、左上、右上、左下、右下八个方向搜索，如果某个方向上存在皇后，那么就将其位置加入答案中，并且停止继续搜索该方向。\nclass Solution:    def queensAttacktheKing(self, queens: List[List[int]], king: List[int]) -&gt; List[List[int]]:        n = 8        s = &#123;(i, j) for i, j in queens&#125;        ans = []        for a in range(-1, 2):            for b in range(-1, 2):                if a or b:                    x, y = king                    while 0 &lt;= x + a &lt; n and 0 &lt;= y &lt; n:                        x, y = x + a, y + b                        if (x, y) in s:                            ans.append([x, y])                            break        return ans\n198. 打家劫舍解：我们定义 $f[i]$ 表示前 $i$ 间房屋能偷窃到的最高总金额，初始时 $f[0]=0, f[1]=nums[0]$。\n考虑$i&gt;1$的情况，第$i$间房屋有两个选项：\n\n不偷窃第$i$间房屋，偷窃总金额为$f[i-1]$；\n偷窃第$i$间房屋，偷窃总金额为$f[i-2]+nums[i-1]$\n\nclass Solution:    def rob(self, nums: List[int]) -&gt; int:        n = len(nums)        f = [0] * (n + 1)        f[1] = nums[0]        for i in range(2, n + 1):            f[i] = max(f[i - 1], f[i - 2] + nums[i - 1])        return f[n]\n解：\n解：\n解：\n解：\n解：\n解：\n","tags":["Python","C++"]},{"title":"算法","url":"/2023/02/28/%E7%AE%97%E6%B3%95/","content":"算法课程笔记\n第一章参考链接：https://www.jiangguo.net/c/7l5/0w.html\n复杂度从低到高：$1&lt;logn&lt;n&lt;nlogn&lt;log(n!)$$&lt;n^k&lt;a^n&lt;n!&lt;n^n$\n第二章参考链接：https://www.jianshu.com/p/1a87c98b0eb5\n解递归式的方法归纳法\n猜测解的形式\n用数学归纳法求出解中的常数，并证明解是正确的\n\n\n猜测靠经验\n\n变量替换例题：$T(n)=2T(\\sqrt{n})+ logn$\n可以设 $m=logn$，则 $T(2^m)=2T(2^{m/2})+m$\n再设 $S(m)=T(2^m)$，可得$S(m)=2S(m/2)+m$\n可证 $S(m)=O(mlogm)$, 则$T(n)=O(lognlog(logn))$\n递归树\nmaster定理快速计算$T(n)=aT(n/b)+ O(n^d)$的复杂度判断1) $d &gt; log_b{a}$\n\nT(n) = O(n^d)2) $d = log_b{a}$\n\nT(n) = O(n^dlogn)3) $d &lt; log_b{a}$\n\nT(n) = O(n^{log_b{a}})运用 Master 定理的时候，第一条和第三条中的$ε$必须大于零。例如：$T(n)=2T(n/2)+ nlogn$\n理论证明https://www.cnblogs.com/HIIM/p/12499319.html\n第三章最长公共子序列c[i][j] = \\begin{cases} 0 & \\text{i > 0; j = 0} \\\\ c[i - 1][j - 1] + 1 & \\text{i, j > 0; $(x_i = y_i)$} \\\\ max(c[i][j - 1], c[i - 1][j]) & \\text{i, j > 0;  $(x_i \\neq y_i)$}\\end{cases}计算c[i][j]的算法时间复杂度为$O(mn)$\n根据b[i][j]推导序列的时间复杂度为$O(m + n)$\n01背包m[i][j] = \\begin{cases} max(m[i + 1][j], m[i + 1][j - w_i] + v_i) & \\text{ j ≥ $w_i$ } \\\\ m[i + 1][j] & \\text{ 0 ≤ j < $w_i$ } \\end{cases}时间复杂度：O(cn)\n跳跃点流水作业调度Johnson算法1) 将任务分为两类$a_i &lt; b_i$ 和 $a_i &gt; b_i$2) $a_i &lt; b_i$往前排，按照$a_i$升序排列3) $a_i &gt; b_i$往后排，按照$b_i$降序排列\n第四章主要为贪心选择性和最优子结构证明\n最小生成树Prim算法：从点v1开始选择离v1最近的点；现在v1和v3作为一个整体，看那个点离v1和v3最近，此时有两个点离得最近，按顺序选择v4；。。。时间复杂度：$O(n^2)$\nKruskal算法：将图中的所有边都去掉；将边按权值从小到大的顺序添加到图中，保证添加的过程中不会形成环；重复上一步直到连接所有顶点$O(eloge)$\n","tags":["C++","理论"]},{"title":"C++学习笔记","url":"/2022/11/15/c/","content":"推荐网站：interview.huihut.com\n基础笔记局部变量和全局变量在程序中，局部变量和全局变量的名称可以相同，但是在函数内，局部变量的值会覆盖全局变量的值。\n代码示例二维数组排序以list[i][1]为关键值，从大到小排序sort(list.begin(), list.end(),     [](const vector&lt;int&gt; &amp;a, const vector&lt;int&gt; &amp;b) &#123;            return a[1] &gt; b[1];        &#125;);\n文件路径划分string path1 = &quot;D:/datas/1.bmp&quot;string::size_type iPos = (path1 .find_last_of(&#x27;\\\\&#x27;) + 1) == 0 ?  path1 .find_last_of(&#x27;/&#x27;) + 1: path1 .find_last_of(&#x27;\\\\&#x27;) + 1 ;string ImgName = path1 .substr(iPos, path1 .length() - iPos);//获取带后缀的文件名string ImgPath = path1 .substr(0,iPos);//获取文件路径string ImgNameNoTag = ImgName.substr(0, ImgName.rfind(&quot;.&quot;));//获取不带后缀的文件名string ImgNameTag = ImgName.substr(ImgName.rfind(&quot;.&quot;),ImgName.length());//获取后缀名","tags":["C++"]},{"title":"组合数学","url":"/2022/09/28/%E7%BB%84%E5%90%88%E6%95%B0%E5%AD%A6/","content":"学习总结\n第一章加法法则和乘法法则一一对应例：100位选手要选出1位冠军，要举行多少场比赛？\n\n一场比赛淘汰一人，淘汰99人则要打99场。\n\n排列组合例：五位数中，至少出现一个6，而且被3整除的数有多少个？\n\n五位数中被3除尽的有30000个；&lt;/br&gt;第1位不出现6有8种可能（12345789），&lt;/br&gt;第2，3，4位不出现6有9种可能（012345789）；&lt;/br&gt;想要被3除尽且不含6，则前四位相加后余数为0，1，2时，第5位分别为（039），（258），（147），都是3种可能。&lt;/br&gt;则$89^33=17496$\n\n圆周排列Q(n,r)=P(n,r)/r排列生成算法序数法设整数为$n$，$k! &lt; n &lt; (k+1)!$\nn-1 = a_k*k!+...+a_1$aka{k-1}…a1$为$n$的序数\n\n排列：以4213为例，4的右边比它小的有3个，则$a_3=3$；3的右边比它小的有0个，则$a_2=0$；2的右边比它小的有1个，则$a_1=1$。于是排列(4213)对应的序数(301)\n\n字典序法设序列为$p_1p_2…p_k$,则该序列的下一排列为\n\n从右往左找首次出现$pj&gt;p{j-1}$情况\n从右往左找到首个大于$p{j-1}$的数，并于$p{j-1}$交换\n将$p_j…p_k$顺序逆转（例：1234变4321）\n\n\n3421的下一排列为4123\n\n换位法\n优先活动大值，没有数处于活动状态结束\n\n#允许重复组合（线性方程整数解）\nC(n+r-1,r)不相邻的组合\nC(n-r+1,r)第二章 递推关系与母函数\nC(n,0)+C(n,1)+...+C(n,n) = 2^n\nC(n, 1) + 2C(n, 2) +...+nC(n, n) = n2^{n-1}母函数定义对于序列$C_0,C_1,…$构造一函数\n\nG(x) = C_0 + C_1x + C_2x^2 + ...称G(x)为序列$C_0,C_1,…$的母函数\n\n$(1 + x) ^ n$是序列$C(n,0),C(n,1),…,C(n,n)$的母函数\n\n","tags":["数学"]},{"title":"社团检测","url":"/2022/08/10/%E7%A4%BE%E5%9B%A2%E6%A3%80%E6%B5%8B/","content":"论文阅读笔记\n\n基于深度学习的社区发现研究综述《A Comprehensive Survey on Community Detection with Deep Learning》\n综述(中文版)的学习总结注: Community Detection 本文翻译为社团检测\n\n3. 基于图卷积神经网络（GCN）的社区发现GCN 在深度图卷积层中聚合节点的邻域信息，从全局上捕获用于社区发现的复杂特征。基于GCN 的社区发现方法有两类：（1）监督/半监督社区分类（2）基于无监督网络表示的社区聚类。社区分类方法受到现实世界中缺乏标签的限制。相比之下，通过矩阵重构和目标优化等技术，网络表示可以更灵活地对社区进行聚类。\n4. 基于图注意力网络（GAT）的社区发现基于图注意力网络的社区发现方法可以在复杂的网络场景下进行社区发现。GAT 通过可训练的权重聚合邻域内的节点特征，该权重通过考虑多种因素（尤其是对于具有多种关系类型的网络）的注意力计算而来。\n5. 基于生成对抗网络（GAN）的社区发现GAN 通过生成器$Φ_g$生成人造样本$Z$来欺骗判别器$Φ_d$。判别器将多层感知机（MLP）、图神经网络（GCN）等深度神经网络作用于表征上。因此，真实样本和人造样本会通过竞争博弈进行调优，从而得到最优的社区特征。GAN 中使用的真实样本包括：\n（1）拓扑结构$A$；\n（2）拓扑结构与节点特征$(A,X)$；\n（3）节点嵌入$H_ν$；\n（4）节点的社团归属$H_c$。\n我们在表征中分析网络拓扑（三元组、派系、社区）或直接在 GAN 中分析它们。该方法在融合网络拓扑、属性和表征的过程中发现社区。\n6. 基于自编码器（AE）的社区发现自编码器（AE）最常被用于无监督社区发现，通常被用到的 AE 变体包括栈式 AE、稀疏 AE、去躁 AE、卷积 AE、变分 AE。AE 可以描绘非线性的、带噪声的真实世界网络，并生成平滑的表征。通用的 AE 架构由一个编码器和一个解码器组成。编码器将网络结构和可获取的语义信息映射到一个低维潜在空间中。解码器则根据编码得到的表示重构一个网络。\n\n基于多层网络的社团检测综述《Community Detection in Multiplex Networks》\n全局社区发现算法也可以分为以下三个典型的主要类。\nFlattening第一种方法是通过合并多层网络，使用所谓的扁平化算法，然后应用传统的社区发现算法，将多层网络简化为一个图。\nLayer by layer逐层的方法先对每层(例如,应用传统的社区发现算法)进行处理，再对处理后的结果进行合并。\nMultilayer第三类算法直接在多路复用网络模型上运行。\n\n属于这一类的基于随机游走者的方法允许游走者从一层切换到另一层。\n\n基于深度图信息最大化的社团检测《CommDGI: Community Detection Oriented Deep Graph Infomax》\n目前的挑战：\n\n无标签的图学习：一般来说，社区检测任务是在无标签的情况下进行的，这意味着神经工作本身会产生一些自监督信息，这些信息可以鼓励编码器的输出具有期望的特性。\n社区无关表示：通用图神经网络学习到的表示不能捕获聚类和社区结构信息。将聚类过程与图神经网络相结合以更好地处理社区发现问题是必要的，但也是具有挑战性的。\n纠缠表示：图神经网络在矩阵重构目标下学习到的表示是纠缠的，可解释性差。\n端到端学习：统一图和聚类学习对面向社区的图神经网络来说是具有挑战性但有用的。聚类分配可以帮助以社区相关的方式更新节点表示。\n\n为了克服这些问题，文章提出了CommDGI（Community Deep Graph Infomax）模型。在此框架中，为了编码能够感知到节点结构与社区的表示，采用最大化互信息来捕获局部和全局结构信息。不同于DGI，该模型提出了一种新的最大化互信息的范式。图互信息（Graph mutual information）是通过节点和图来进行计算，社区互信息（community mutual information）是通过节点和社区（子图）来进行计算。这两种互信息一起最大化来编码节点的图和聚类特征（the graph and clustering feature of each node）。\n一致性多图嵌入用于多视图聚类《Consistent Multiple Graph Embedding for Multi-View Clustering》\n本文提出了一种新颖的一致性多图嵌入聚类框架( CMGEC )。具体地，设计了多图自编码器( M-GAE )，利用多图注意力融合编码器对多视图数据的互补信息进行灵活编码。为了指导学习到的共同表示保持每个视图中相邻特征的相似性，引入了多视图互信息最大化模块( MMIM )。此外，设计了一个图融合网络( GFN )，从不同角度探索图之间的关系，并提供M - GAE所需的公共共识图。通过联合训练这些模型，可以得到共同的表示，从多个视图中编码更多的互补信息，更全面地描述数据。\n\n面向无监督的深度图结构学习《Towards Unsupervised Deep Graph Structure Learning》’www22’\n背景目前优化图结构的方法侧重于监督学习场景，这导致了几个问题，即对标签的依赖、边缘分布的偏差以及对应用任务的限制。\n方法首次提出采用GNN无监督的方法。\n简单的无监督图表示学习《Simple Unsupervised Graph Representation Learning》\n背景实现有效且高效的对比学习。\n方法为了获得有效性，我们设计了两个三元组损失来探索结构信息和邻居信息之间的互补信息以扩大类间变异，以及上带损失以减少类内变异。为了提高效率，我们的方法旨在删除用于生成锚嵌入和负嵌入的 GCN，以及从先前的图形对比学习中删除数据增强和鉴别器。\nCommDGI: 面向深度图的社区发现《CommDGI: Community Detection Oriented Deep Graph》’CIKM ‘20’\n背景方法\n 《》\n背景方法\n 《》\n背景方法\n","tags":["深度学习"]},{"title":"Kindle|电子书排版总结","url":"/2021/03/18/calibre/","content":"总结一些用于AZW3格式的排版\n工具Sigil下载地址\nSigil，跨平台的开源 ePub 电子书编辑器，支持Windows、Linux和Mac系统。\n\n个人主要用于切分章节.主要是因为处理文本量较大的文件时会闪退\nEasypub下载地址\n\n可以TXT文档转成带目录的MOBI/EPUB格式,但是排版一般.\n\n一般用这个将txt简单转换下,再细调\nCalibre下载地址\n\nCalibre 是一个免费的开源的“一站式”的电子书解决方案，它可以全面满足你的电子书需求。它是一个完整的电子图书馆，包括图书管理，格式转换，新闻，将材料转换为电子书，以及电子书阅读器同步功能、整合进电子图书阅读器。当然它也内置了一个 ePub 格式电子书编辑工具以满足修改电子书的需要。\n\n主要工具,功能强悍\n\n字体个人主要使用黑体,楷体,思源宋体和方正兰亭\n楷体font-family: &quot;DK-KAITI&quot;, &quot;楷体&quot;, &quot;方正楷体_GBK&quot;, &quot;KaiTi&quot;, &quot;STKaiti&quot;, &quot;STKai&quot;, &quot;kt&quot;, serif;\n思源宋体@font-face &#123;  font-family: &quot;syst&quot;;  src: url(&quot;../fonts/systB.ttf&quot;);&#125;\nfont-family: &quot;syst&quot;;\n方正兰亭@font-face &#123;  font-family: &quot;fzlt&quot;;  src: url(&quot;../fonts/fzltZH.ttf&quot;);&#125;\nfont-family: &quot;fzlt&quot;;\n封面Kindle 电子书封面图片标准规格如下：\n\nJPEG 或 TIFF 格式\n优先使用 1.6:1 的长宽比\n最小尺寸：宽 625 像素，长 1000 像素\n最佳尺寸：宽 1563 像素，长 2500 像素\n\n标题卷标题横板&lt;h1 id=&quot;title&quot; class=&quot;volume-title&quot;&gt;第一卷&lt;br class=&quot;calibre3&quot;/&gt;&lt;span class=&quot;volume-subtitle&quot;&gt; 游戏创新的一般原理&lt;/span&gt;&lt;/h1&gt;\n\n其中.volume-title &#123;  display: block;  font-family: &quot;DK-KAITI&quot;, &quot;楷体&quot;, &quot;方正楷体_GBK&quot;, &quot;KaiTi&quot;, &quot;STKaiti&quot;, &quot;STKai&quot;, &quot;kt&quot;, serif;  font-size: 1.3em;  line-height: 1.4;  text-align: center;  margin: 30% auto;&#125;.volume-subtitle &#123;  display: block;  font-family: &quot;syst&quot;;  text-align: center;&#125;\n竖版&lt;div class=&quot;head&quot;&gt;  &lt;h1 class=&quot;head1&quot; title=&quot;第一卷 天元篇&quot;&gt;第一卷&lt;/h1&gt;  &lt;p class=&quot;head2&quot;&gt;天元篇&lt;/p&gt;&lt;/div&gt;\n.head &#123;  display: block;  line-height: 1.4;  text-align: center;  width: 1.4em;  margin: 25% auto;&#125;.head1 &#123;  display: block;  font-family: &quot;STKai&quot;, &quot;DK-FANGSONG&quot;, &quot;方正仿宋_GBK&quot;, &quot;kt&quot;, serif;  font-size: 1.4em;  font-weight: bold;  line-height: 1.4;  text-align: center;&#125;.head2 &#123;  display: block;  font-family: &quot;STKai&quot;, &quot;DK-FANGSONG&quot;, &quot;方正仿宋_GBK&quot;, &quot;kt&quot;, serif;  font-size: 1.4em;  font-weight: bold;  line-height: 1.4;  text-align: center;&#125;\n章标题&lt;h2 class=&quot;chapter-title&quot;&gt;&lt;span class=&quot;chapter-sequence-number&quot;&gt;第991章&lt;/span&gt;&lt;br/&gt; 黑火石和哨兵&lt;span class=&quot;chapter-subtitle&quot;&gt;（上）&lt;/span&gt;&lt;/h2&gt;\n.chapter-sequence-number &#123;  font-family: &quot;fzlt&quot;;  font-size: 1rem;  padding: 2px 4px;&#125;.chapter-title &#123;  display: block;  font-family: &quot;syst&quot;;  font-size: 1.2em;  line-height: 1.4;  text-align: center;&#125;.chapter-subtitle &#123;  font-size: 0.7em;&#125;\n正文文字.calibre4 &#123;  display: block;  line-height: 1.4;  text-align: justify;  text-indent: 2em;&#125;\n插图&lt;div class=&quot;tupian&quot;&gt;  &lt;img alt=&quot;&quot; class=&quot;image-alone&quot; src=&quot;../images/00079.jpeg&quot;/&gt;&lt;/div&gt;\n.tupian &#123;  display: block;  text-align: center;  margin: 1em auto;&#125;.image-alone &#123;  height: auto;  width: 90%;&#125;\n注释&lt;span class=&quot;math-super&quot;&gt;&lt;a href=&quot;part0107.html#bz1&quot; id=&quot;z1&quot;&gt;[1]&lt;/a&gt;&lt;/span&gt;\n&lt;p class=&quot;zhusi&quot;&gt;&lt;a href=&quot;part0012.html#z1&quot; id=&quot;bz1&quot;&gt;[1]&lt;/a&gt;注释内容&lt;/p&gt;\n.math-super &#123;  font-family: &quot;DK-KAITI&quot;, &quot;楷体&quot;, &quot;方正楷体_GBK&quot;, &quot;KaiTi&quot;, &quot;STKaiti&quot;, &quot;STKai&quot;, &quot;kt&quot;, serif;  font-size: 0.75em;  vertical-align: super;&#125;.zhusi &#123;  display: block;  font-family: &quot;DK-KAITI&quot;, &quot;楷体&quot;, &quot;方正楷体_GBK&quot;, &quot;KaiTi&quot;, &quot;STKaiti&quot;, &quot;STKai&quot;, &quot;kt&quot;, serif;  line-height: 1.5;  margin: 1em 0;&#125;\n其他方框&lt;div class=&quot;reference&quot;&gt;&lt;/div&gt;\n.reference &#123;  display: block;  line-height: 1.4;  margin-bottom: 1em;  margin-top: 1em;  padding: 0 0.25em;  border: #444 dotted 1px;&#125;\n阴影&lt;p class=&quot;indent&quot;&gt;&lt;span class=&quot;titlemode&quot;&gt;原文&lt;/span&gt;&lt;/p&gt;\n.indent &#123;  display: block;  line-height: 140%;  text-align: justify;  text-indent: 2em;&#125;.titlemode &#123;  background-color: #4A494A;  color: #fff;  font-family: &quot;楷体&quot;, &quot;仿宋_gb2312&quot;, &quot;zw&quot;, serif;  font-size: 1.1em;  font-weight: bold;  line-height: 1.4;  padding: 3px;&#125;\n","tags":["CSS"]},{"title":"Python|Pycharm使用技巧","url":"/2020/08/15/Pycharm/","content":"Windows 10 专业版Pycharm 2020.2\nPycharm使用技巧自动调整代码格式问题\n在使用pycharm的代码编辑器时，常常懒得写空格，但这是不符合代码规范的，而且也会影响可读性。\n解决办法\npycharm有自动调整代码格式的快捷键，默认为Alt+Ctrl+L，按下快捷键后，代码自动填充了空格。\n运行当前编辑文件问题\n运行代码时，总是要先选择文件，点击运行或者右击选择运行，需要两步\n解决方法\n设置快捷键，运行当前编辑文件快捷键为Ctrl+Sift+F10\n","tags":["Python"]},{"title":"Python|学习总结","url":"/2020/07/08/Python%E5%B0%8F%E6%8A%80%E5%B7%A7/","content":"记录有趣的小技巧\n基础学习set() 函数set() 函数创建一个无序不重复元素集，可进行关系测试，删除重复数据，还可以计算交集、差集、并集等。x = set(&#x27;runoob&#x27;)y = set(&#x27;google&#x27;)x, y&gt;&gt;&gt; (set([&#x27;b&#x27;, &#x27;r&#x27;, &#x27;u&#x27;, &#x27;o&#x27;, &#x27;n&#x27;]), set([&#x27;e&#x27;, &#x27;o&#x27;, &#x27;g&#x27;, &#x27;l&#x27;]))x &amp; y         # 交集&gt;&gt;&gt; set([&#x27;o&#x27;])x | y         # 并集&gt;&gt;&gt; set([&#x27;b&#x27;, &#x27;e&#x27;, &#x27;g&#x27;, &#x27;l&#x27;, &#x27;o&#x27;, &#x27;n&#x27;, &#x27;r&#x27;, &#x27;u&#x27;])x - y         # 差集&gt;&gt;&gt; set([&#x27;r&#x27;, &#x27;b&#x27;, &#x27;u&#x27;, &#x27;n&#x27;])\nCounter() 函数Counter是dict子类，用于计数可哈希的对象。元素被作为字典的key存储，它们的计数作为字典的value存储。from collections import Countercnt = Counter()for word in [&#x27;red&#x27;, &#x27;blue&#x27;, &#x27;red&#x27;, &#x27;green&#x27;, &#x27;blue&#x27;, &#x27;blue&#x27;]:    cnt[word] += 1  # 如果键不存在，就返回0print cnt&gt;&gt;&gt; Counter(&#123;‘blue’: 3, ‘red’: 2, ‘green’: 1&#125;)\nzip()# 显示列nums = [&#x27;flower&#x27;,&#x27;flow&#x27;,&#x27;flight&#x27;]for i in zip(*nums):    print(i)&gt;&gt;&gt; (&#x27;f&#x27;, &#x27;f&#x27;, &#x27;f&#x27;)    (&#x27;l&#x27;, &#x27;l&#x27;, &#x27;l&#x27;)    (&#x27;o&#x27;, &#x27;o&#x27;, &#x27;i&#x27;)    (&#x27;w&#x27;, &#x27;w&#x27;, &#x27;g&#x27;)\n实用工具一键抠图\n进入官网,可以直接上传图片\n\n\n\n也可以注册账号申请API，通过代码实现# 安装库pip install removebg\n# 从官网获取自己的APIfrom removebg import RemoveBgrmbg = RemoveBg(&quot;自己的API&quot;, &quot;error.log&quot;)rmbg.remove_background_from_img_file(&quot;C:/Code/Picture/new.jpg&quot;)\n\n\n\n\n","tags":["python"]},{"title":"Python|PyTorch学习记录","url":"/2020/07/08/pytorch/","content":"PyTorch使用心得\n创建虚拟环境conda create -n c_d python=3.7\nconda activate c_d\n安装PyTorch进入PyTorch官网\nconda install pytorch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1 pytorch-cuda=11.6 -c pytorch -c nvidia\norpip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116\n安装PyG进入PyG官网pip install torch_geometric# Optional dependencies:pip install torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-1.13.0+cu116.html\n其他CPU, GPU监控# 从 PyPI 获取并安装$ pip3 install --upgrade nvitop# 从 GitHub 获取并安装最新版 (推荐)$ pip3 install git+https://github.com/XuehaiPan/nvitop.git#egg=nvitop\n# 获取并显示机器资源信息 (只打印一次)$ nvitop -1          # 获取并显示机器资源信息 (所有 GPU)$ nvitop -1 -o 0 1   # 只显示 &lt;GPU 0&gt; 和 &lt;GPU 1&gt;$ nvitop -1 -ov      # 只显示 `CUDA_VISIBLE_DEVICES` 中的 GPU$ nvitop -1 -U       # 只使用 ASCII 字符 适用于不支持 Unicode 字符的终端# 资源监视器模式$ nvitop             # 资源监视器$ nvitop -m auto     # 资源监视器 (通过终端大小自动调整显示模式 (默认))$ nvitop -m full     # 资源监视器 (完全模式，无视窗口大小变化)$ nvitop -m compact  # 资源监视器 (紧凑模式，无视窗口大小变化)$ nvitop -m -o 0 1   # 只显示 &lt;GPU 0&gt; 和 &lt;GPU 1&gt;$ nvitop -m -ov      # 只显示 `CUDA_VISIBLE_DEVICES` 中的 GPU$ nvitop -m -U       # 只使用 ASCII 字符 适用于不支持 Unicode 字符的终端","tags":["Python","深度学习","PyTorch"]},{"title":"Python|一行代码生成二维码","url":"/2020/02/28/%E4%BA%8C%E7%BB%B4%E7%A0%81/","content":"简单生成二维码\n二维码二维码也称为二维条码，是指在一维条码的基础上扩展出另一维具有可读性的条码，使用黑白矩形图案表示二进制数据，被设备扫描后可获取其中所包含的信息。一维条码的宽度记载着数据，而其长度没有记载数据。二维码的长度、宽度均记载着数据。二维码有一维条码没有的“定位点”和“容错机制”。容错机制在即使没有识别到全部的条码、或是说条码有污损时，也可以正确地还原条码上的信息。\n二维码在现实生活中的应用越来与普遍，归于功于 QR code 码制的流行。我们常说的二维码就是它。所以，二维码又被称为 QR code。\n\nQR code 是一种矩阵式二维条码（又称棋盘式二维条码）。它是在一个矩形空间通过黑、白像素在矩阵中的不同分布进行编码。在矩阵相应元素位置上，用点（方点、圆点或其他形状）的出现表示二进制“1”，点的不出现表示二进制的“0”，点的排列组合确定了矩阵式二维条码所代表的意义。\n\n二维码的生成安装工具 Myqr：pip install myqr生成一个普通二维码：myqr https://mengqiu233.github.io这时就会在当前目录下生成一个名称为 qrcode.png 的二维码\n\n注意这里的字符串不能指定中文\n\n\n\n\n\n命令\n作用\n~\n\n\n\n\n-d\n输出的文件路径\n\n\n-n\n文件名称\n.jpg .png .gif\n\n\n-l\n二维码的纠错等级\nL、M、Q、H，从左到右依次升高\n\n\n-v\n二维码的边长\n范围是 1 至 40，数字越大边长越大\n\n\n-p\n添加图片\n\n\n\n\n比如将图片结合到二维码中myqr https://mengqiu233.github.io/ -p tree.jpg -c\n","tags":["Python"]},{"title":"Python|基于BOF算法的图像检索","url":"/2019/07/07/BOF/","content":"BoF(Bag of features)算法在图像分类中具有着重要的作用\n简介Bag of Features方法仿照文本检索领域的Bag-of-Words方法，把每幅图像描述为一个局部区域/关键点(Patches/Key Points)特征的无序集合。使用某种聚类算法(如K-means)将局部特征进行聚类，每个聚类中心被看作是词典中的一个视觉词汇(Visual Word)，相当于文本检索中的词，视觉词汇由聚类中心对应特征形成的码字(code word)来表示。图像中的每个特征都将被映射到视觉词典的某个词上，这种映射可以通过计算特征间的距离去实现，然后统计每个视觉词汇的出现与否或次数，图像可描述为一个维数相同的直方图向量。\n基本流程基本流程可以分为四步：\n特征提取从原始图像中提取特征，常用的特征提取方法有SIFT，SURF。SIFT得到的特征描述是128维度的向量，相比SISF，SURF计算量更小些，得到的特征是64维的向量。也有使用HoG和LBP来进行特征提取的。注意特征提取的方法要满足旋转不变性以及尺寸不变性。\n字典生成对所有的图片提取完特征后，将所有的特征进行聚类，比如使用K-Means聚类，得到K类，每个类别看作一个word，这样我们就得到了字典，如下图所示。\n直方图表示上一步训练得到的字典，是为了这一步对图像特征进行量化。对于一幅图像而言，我们可以提取出大量的特征，但这些特征(如SIFT提取的特征)仍然属于一种浅层的表示，缺乏代表性。因此，这一步的目标，是根据字典重新提取图像的高层特征。具体做法是，对于每一张图片得到的每一个特征(如SIFT提取的特征)，都可以在字典中找到一个最相似的word(实际上就是将特征输入到得到的聚类模型，得到类别)，统计相似的每种word的数量，于是就得到一个K维的直方图。如下图所示。\n训练分类器对于每张图片，我们得到了其对应的直方图向量，当然也知道其对应的属于哪种物品的标记。这样我们就可以构造训练集来训练某种分类器。当需要进行预测时，我们先测试集的图片中提取特征，然后利用字典量化得到直方图，输入训练好的分类器，得到预测的类别。\n算法实现数据预处理本次实验采用了三个类别：[‘aeroplane’, ‘bicycle’, ‘car’]，在train文件夹下有三个子文件夹表示各类。def read_paths(path):    # 获取训练数据类别    training_names = os.listdir(path)    # 获取图片路径及标签    image_paths = [] # 获取所有图片路径    image_classes = [] #记录每张图片的标签，[0,...,0,1,...,1,2,...,2]    class_id = 0    for training_name in training_names:        name = os.path.join(path, training_name)        class_path = list(paths.list_images(name))        image_paths += class_path        image_classes += [class_id] * len(class_path)        class_id += 1    print(&quot;Label \\t\\t  count&quot;)    print(&quot;---------------------&quot;)    i = 0    for training_name in training_names:        print(&#x27;&#123;0:10&#125; &#123;1:6d&#125;&#x27;.format(training_name, image_classes.count(i)))        i += 1    print(&quot;\\n&quot;)    return training_names, image_paths, image_classes\n提取图像特征这里采用的是OpenCV自带的SIFT算法生成图像库中每幅图的特征点及描述符。#创建特征提取和关键点检测器对象sift=cv2.xfeatures2d.SIFT_create()# 特征提取与描述子生成des_list = []for image_path in image_paths:    im = cv2.imread(image_path)    kpts, des = sift.detectAndCompute(im, None)    des_list.append((image_path, des))    print(&quot;image file path : &quot;, image_path)# 描述子向量聚合descriptors = des_list[0][1]for image_path, descriptor in des_list[1:]:    descriptors = np.vstack((descriptors, descriptor))\n对特征进行聚类# kmeans聚类k = 100voc,_= kmeans(descriptors, k, 1)\n根据字典将图片表示成向量# 生成特征直方图im_features = np.zeros((len(image_paths), k), &quot;float32&quot;)for i in range(len(image_paths)):    words, distance = vq(des_list[i][1], voc)    for w in words:        im_features[i][w] += 1\n\n特征集进行加权及量化在一篇文档里，“的”“你”“我”等字眼的出现频率高，那么这些word在直方图上的bin就会比较高，并且在每篇文档里都会出现，但是这些并不能作为文档的标识，因此要弱化这些共性特征的权重。\n\n这里采用了TF-IDF加权TF:如果某个关键词在一篇文章中出现的频率高，说明该词语能够表征文章的内容，该关键词在其它文章中很少出现，则认为此词语具有很好的类别区分度，对分类有很大的贡献。IDF:如果文件数据库中包含词语A的文件越少，则IDF越大，说明词语A具有很好的类别区分能力。# TF-IDFnbr = np.sum((im_features &gt; 0) * 1, axis=0)idf = np.array(np.log((1.0 * len(image_paths) + 1) / (1.0 * nbr + 1)), &#x27;float32&#x27;)im_features = im_features * idftf = np.zeros((len(image_paths), k), &quot;float32&quot;)for i in range(len(image_paths)):     tf[i] = im_features[i] / (np.sum(im_features, axis=1)[i])     im_features[i] = im_features[i] * tf[i]# 尺度化stdSlr = StandardScaler().fit(im_features)im_features = stdSlr.transform(im_features)\n训练分类器clf = LinearSVC()clf.fit(im_features, np.array(image_classes))\n最后可以将训练的结果打包并保存print(&quot;training and save model...&quot;)sklearn.externals.joblib.dump((clf, training_names,std_slr, k, voc, idf), &quot;bof.pkl&quot;, compress=3)print(&quot;========================================&quot;)\n预测并测试预测步骤和训练相似，先提取图像特征，将提取的图像特征加权并尺度化，代入训练好的分类器def predict_image(image_path):    clf, classes_names, std_slr, k, voc, idf = sklearn.externals.joblib.load(&quot;bof.pkl&quot;)    sift = cv2.xfeatures2d.SIFT_create()    im = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)    kpts, des = sift.detectAndCompute(im, None)    test_features = np.zeros((1, k), &quot;float32&quot;)    words, distance = vq(des, voc)    for w in words:        test_features[0][w] += 1    test_features = test_features * idf    tf = test_features / np.sum(test_features, axis=1)    test_features = test_features * tf    # Scale the features    test_features = std_slr.transform(test_features)    # Perform the predictions    predictions = [classes_names[i] for i in clf.predict(test_features)]    return predictions读取测试数据，并输出结果def test(test_path):    _, image_paths, _ = read_paths(test_path)    i = 0    for image_path in image_paths:        i += 1        predictions = predict_image(image_path)        img = cv2.imread(image_path)        img = cv2.resize(img, (int(img.shape[1]*2), int(img.shape[0] * 2))) #图片扩大两倍        output=cv2.putText(img, predictions[0], (10, 150), cv2.FONT_HERSHEY_COMPLEX, 2.0, (100, 200, 200), 5)        cv2.imshow(image_path, output)        cv2.waitKey(0)        print(&quot;image%d: %s, classes : %s&quot; % (i, image_path, predictions))\n\n代码import osimport cv2import numpy as npimport sklearn.externalsfrom imutils import pathsfrom sklearn.svm import LinearSVCfrom scipy.cluster.vq import *from sklearn.preprocessing import StandardScalerdef read_paths(path):    # 获取训练数据类别    training_names = os.listdir(path)    # 获取图片路径及标签    image_paths = [] # 获取所有图片路径    image_classes = [] #记录每张图片的标签，[0,...,0,1,...,1,2,...,2]    class_id = 0    for training_name in training_names:        name = os.path.join(path, training_name)        class_path = list(paths.list_images(name))        image_paths += class_path        image_classes += [class_id] * len(class_path)        class_id += 1    print(&quot;Label \\t\\t  count&quot;)    print(&quot;---------------------&quot;)    i = 0    for training_name in training_names:        print(&#x27;&#123;0:10&#125; &#123;1:6d&#125;&#x27;.format(training_name, image_classes.count(i)))        i += 1    print(&quot;\\n&quot;)    return training_names, image_paths, image_classesdef train(train_path):    training_names, image_paths, image_classes = read_paths(train_path)    # 创建SIFT特征提取器    sift = cv2.xfeatures2d.SIFT_create()    # 特征提取与描述子生成    des_list = []    for image_path in image_paths:        im = cv2.imread(image_path)        kpts, des = sift.detectAndCompute(im, None)        des_list.append(des)    # 描述子向量    descriptors = des_list[0]    for descriptor in des_list[1:]:        descriptors = np.vstack((descriptors, descriptor))    # 100 聚类 K-Means    k = 100    voc, _ = kmeans(descriptors, k, 1)    # 生成特征直方图    im_features = np.zeros((len(image_paths), k), &quot;float32&quot;)    for i in range(len(image_paths)):        words, distance = vq(des_list[i], voc)        for w in words:            im_features[i][w] += 1    # TF-IDF    nbr = np.sum((im_features &gt; 0) * 1, axis=0)    idf = np.array(np.log((1.0 * len(image_paths) + 1) / (1.0 * nbr + 1)), &#x27;float32&#x27;)    im_features = im_features * idf    tf = np.zeros((len(image_paths), k), &quot;float32&quot;)    for i in range(len(image_paths)):        tf[i] = im_features[i] / (np.sum(im_features, axis=1)[i])        im_features[i] = im_features[i] * tf[i]    # 尺度化    std_slr = StandardScaler().fit(im_features)    im_features = std_slr.transform(im_features)    # SVM    clf = LinearSVC()    clf.fit(im_features, np.array(image_classes))    # Save the SVM    print(&quot;training and save model...&quot;)    sklearn.externals.joblib.dump((clf, training_names, std_slr, k, voc, idf), &quot;bof.pkl&quot;, compress=3)    print(&quot;========================================&quot;)def predict_image(image_path):    clf, classes_names, std_slr, k, voc, idf = sklearn.externals.joblib.load(&quot;bof.pkl&quot;)    sift = cv2.xfeatures2d.SIFT_create()    im = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)    kpts, des = sift.detectAndCompute(im, None)    test_features = np.zeros((1, k), &quot;float32&quot;)    words, distance = vq(des, voc)    for w in words:        test_features[0][w] += 1    test_features = test_features * idf    tf = test_features / np.sum(test_features, axis=1)    test_features = test_features * tf    # Scale the features    test_features = std_slr.transform(test_features)    # Perform the predictions    predictions = [classes_names[i] for i in clf.predict(test_features)]    return predictionsdef test(test_path):    _, image_paths, _ = read_paths(test_path)    i = 0    for image_path in image_paths:        i += 1        predictions = predict_image(image_path)        print(&quot;image%d: %s, classes : %s&quot; % (i, image_path, predictions))if __name__ == &quot;__main__&quot;:    train_path = &quot;C:/Code/Picture/dataset/train/&quot;    train(train_path)    test_path = &quot;C:/Code/Picture/dataset/test/&quot;    test(test_path)\n缺陷\n字典大小的选择也是问题，字典过大，单词缺乏一般性，对噪声敏感，计算量大，关键是图象投影后的维数高；字典太小，单词区分性能差，对相似的目标特征无法表示。\n这种一个特征点对应于一个词的方法显然忽略图像空间上下文，这很容易造成词语义的模糊。\n图像中一般都存在同主题无关的内容，会影响分类的结果，改进方法是检测兴趣区域并给不同的权重。\n\n","tags":["Python","BOF","OpenCV","SIFT","Kmeans"]},{"title":"Math|距离计算","url":"/2019/06/28/%E8%B7%9D%E7%A6%BB%E8%AE%A1%E7%AE%97/","content":"机器学习常用距离计算总结\n曼哈顿距离曼哈顿距离（Manhattan Distance）又称计程车几何距离或方格线距离，是由十九世纪的赫尔曼·闵可夫斯基所创词汇 ，为欧几里得几何度量空间的几何学之用语，用以标明两个点上在标准坐标系上的绝对轴距之总和。曼哈顿距离的正式意义为L1-距离或城市区块距离，也就是在欧几里得空间的固定直角坐标系上两点所形成的线段对轴产生的投影的距离总和。曼哈顿距离公式为\nd=\\sum_{i=1}^n|x_i-y_i|欧几里得距离欧几里得度量（Euclidean Distance）也称欧氏距离： 在数学中，欧几里得距离或欧几里得度量是欧几里得空间中两点间“普通”（即直线）距离。在欧几里得空间中，点$x=\\left(x{1}, x{2}, \\ldots, x{n}\\right)$和$y=\\left(y{1}, y{2}, \\ldots, y{n}\\right)$之间的欧氏距离为:\nd=\\sqrt{\\sum_{i=1}^{n}\\left(x_{i}-y_{i}\\right)^{2}}切比雪夫距离数学上，切比雪夫距离（Chebyshev distance）或是$L_{\\infty}$度量是向量空间中的一种度量，二个点之间的距离定义为其各座标数值差的最大值。以p(x1,y1)和q(x2,y2)二点为例，其切比雪夫距离为：\nD_{\\text {Chebyshev}}(p, q)=\\max \\left(\\left|x_{2}-x_{1}\\right|,\\left|y_{2}-y_{1}\\right|\\right)一般形式为：\nD_{\\text { Chebyshev }}(p, q)=\\max _{i}\\left(\\left|p_{i}-q_{i}\\right|\\right)=\\lim _{k \\rightarrow \\infty}\\left(\\sum_{i=1}^{n}\\left|p_{i}-q_{i}\\right|^{k}\\right)^{1 / k}闵可夫斯基距离闵可夫斯基距离或闵氏距离（Minkowski Distance）：以俄罗斯数学家闵可夫斯基命名的距离；是欧式距离的推广，闵氏距离不是一种距离，而是一组距离的定义。其定义如下：\nd=\\sqrt[p]{\\sum_{i=1}^{n}\\left|x_{i}-y_{i}\\right|^{p}}从上面公式可以看出：当$p=1$时，就是曼哈顿距离当$p=2$时，就是欧氏距离当$p \\rightarrow \\infty$时，就是切比雪夫距离\n马氏距离马氏距离(Mahalanobis distance)： 由印度统计学家马哈拉诺比斯提出，表示数据的协方差距离。它是一种有效的计算两个未知样本集的相似度的方法。与欧氏距离不同的是它考虑到各种特性之间的联系（例如：一条关于身高的信息会带来一条关于体重的信息，因为两者是有关联的）并且是尺度无关的(scale-invariant)，即独立于测量尺度，如果协方差矩阵为单位矩阵，马氏距离就简化为欧式距离，如果协方差矩阵为对角阵，其也可称为正规化的马氏距离。 计算公式如下：\nD_{M}(x)=\\sqrt{(x-\\mu)^{T} \\Sigma^{-1}(x-\\mu)}马氏距离也可以定义为两个服从同一分布并且其协方差矩阵为$\\Sigma$的随机变量$\\vec{x}$与$\\vec{y}$的差异程度：\nd(\\vec{x}, \\vec{y})=\\sqrt{(\\vec{x}-\\vec{y})^{T} \\Sigma^{-1}(\\vec{x}-\\vec{y})}汉明距离在信息论中，两个等长字符串之间的汉明距离（Hamming distance）是两个字符串对应位置的不同字符的个数。换句话说，它就是将一个字符串变换成另外一个字符串所需要替换的字符个数。\n\n1011101 与 1001001 之间的汉明距离是 2。2143896 与 2233796 之间的汉明距离是 3。“toned” 与 “roses” 之间的汉明距离是 3。\n\n余弦相似度余弦相似度通过测量两个向量的夹角的余弦值来度量它们之间的相似性。0度角的余弦值是1，而其他任何角度的余弦值都不大于1；并且其最小值是-1。从而两个向量之间的角度的余弦值确定两个向量是否大致指向相同的方向。两个向量有相同的指向时，余弦相似度的值为1；两个向量夹角为90°时，余弦相似度的值为0；两个向量指向完全相反的方向时，余弦相似度的值为-1。这结果是与向量的长度无关的，仅仅与向量的指向方向相关。余弦相似度通常用于正空间，因此给出的值为0到1之间。给定两个属性向量，A和B，其余弦相似性θ由点积和向量长度给出，如下所示：\n\\cos \\theta=\\frac{A \\cdot B}{\\|A\\|\\|B\\|}=\\frac{\\sum_{i=1}^{n} A_{i} \\times B_{i}}{\\sqrt{\\sum_{i=1}^{n}\\left(A_{i}\\right)^{2}} \\times \\sqrt{\\sum_{i=1}^{n}\\left(B_{i}\\right)^{2}}}杰卡德距离杰卡德距离(Jaccard Distance) ：它是杰卡德相似系数的补集，被定义为1减去Jaccard相似系数。而杰卡德相似系数(Jaccard similarity coefficient)，也称杰卡德指数(Jaccard Index)，是用来衡量两个集合相似度的一种指标。Jaccard相似指数用来度量两个集合之间的相似性，它被定义为两个集合交集的元素个数除以并集的元素个数。\nJ(A, B)=\\frac{|A \\cap B|}{|A \\cup B|}杰卡德距离如下：\nd_{J}(A, B)=1-J(A, B)=\\frac{|A \\cup B|-|A \\cap B|}{|A \\cup B|}性质：1）若$A、B$两个集合都为空，则$J(A,B)=1$2）$0 \\leq J(A, B) \\leq 1$\n皮尔森相关系数皮尔森相关系数（Pearson correlation coefficient）：也称皮尔森积矩相关系数(Pearson product-moment correlation coefficient) ，是一种线性相关系数。皮尔森相关系数是用来反映两个变量线性相关程度的统计量。相关系数用r表示，其中n为样本量，分别为两个变量的观测值和均值。r描述的是两个变量间线性相关强弱的程度。r的绝对值越大表明相关性越强。计算公式：\n\nr=\\frac{\\sum_{i=1}^{n}\\left(X_{i}-\\overline{x}\\right)\\left(Y_{i}-\\overline{y}\\right)}{\\sqrt{\\sum_{i=1}^{n}\\left(X_{i}-\\overline{x}\\right)^{2}} \\sqrt{\\sum_{i=1}^{n}\\left(Y_{i}-\\overline{y}\\right)^{2}}}分子是两个集合的交集大小，分母是两个集合大小的几何平均值。是余弦相似性的一种形式\n编辑距离编辑距离（Edit Distance）:又称Levenshtein距离，是指两个字串之间，由一个转成另一个所需的最少编辑操作次数。许可的编辑操作包括将一个字符替换成另一个字符，插入一个字符，删除一个字符。一般来说，编辑距离越小，两个串的相似度越大。俄罗斯科学家Vladimir Levenshtein在1965年提出这个概念。编辑距离越小的两个字符串越相似，当编辑距离为0时，两字符串相等。\nf(n) = \\begin{cases}max(i,j) & \\text{if min(i,j)=0} \\\\ min{\\begin{cases} lev_{a,b}(i-1,j)+1 \\\\ lev_{a,b}(i,j-1)+1 \\\\ lev_{a,b}(i-1,j-1)+1_{(a_i \\neq b_j)} \\end{cases}} & \\text{otherwise.}\\end{cases}K-L散度K-L散度即相对熵；是衡量两个分布(P、Q)之间的距离；越小越相似。计算公式：\nD(P||Q)=\\sum_{i=1}^nP(i)log{P(i) \\over Q(i)}\n参考博客：\n[1] 机器学习中常用的距离公式\n[2] 常用的相似性度量算法\n[3] 机器学习和统计学中常见的距离和相似度度量\n[4] 几种距离度量方法比较\n","tags":["机器学习"]},{"title":"JAVA|MapReduce-TopN","url":"/2019/06/28/TopN/","content":"问题描述：有一个很大的文件，这文件中的内容全部都是数字，要求尝试从这个文件中找出最大的N个数字。设置数据集data.txt14323344352436327342845945102343424436324647427668778923324\n代码import java.io.IOException;import java.util.Arrays;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.DoubleWritable;import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.Mapper;import org.apache.hadoop.mapreduce.Reducer;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;import org.apache.hadoop.util.GenericOptionsParser;public class TopN &#123;\tpublic static class TMap extends Mapper&lt;Object, Text, Text, Text&gt;&#123;\t\tint[] topN;\t\tint length;\t\t\t\tpublic void setup(Context context) throws IOException, InterruptedException &#123;\t\t\tlength = context.getConfiguration().getInt(&quot;N&quot;,5);\t\t\ttopN = new int[length+1];\t\t&#125;\t\tpublic void map(Object key, Text value, Context context) throws IOException, InterruptedException &#123;\t\t\tString data = value.toString();\t\t\tint cost = Integer.valueOf(data);\t\t\ttopN[0] = cost;\t\t\tArrays.sort(topN);\t\t&#125;\t\tprotected void cleanup(Context context) throws IOException, InterruptedException &#123;            for (int i = 1; i &lt; length+1;i++)&#123;                context.write(new Text(String.valueOf(topN[i])),new Text(String.valueOf(topN[i])));            &#125;\t\t&#125;\t&#125;\tpublic static class TReducer extends Reducer&lt;Text,Text,Text,Text&gt; &#123;\t\tint[] topN;        int length;        protected void setup(Context context) throws IOException, InterruptedException &#123;            length = context.getConfiguration().getInt(&quot;N&quot;,5);            topN = new int[length+1];        &#125;\t\t\t\tpublic void reduce(Text key, Iterable&lt;Text&gt; values, Context context) throws IOException, InterruptedException &#123;\t\t\ttopN[0] = Integer.valueOf(key.toString());\t\t\tArrays.sort(topN);\t\t&#125;\t\t\t\tprotected void cleanup(Context context) throws IOException, InterruptedException &#123;            for (int i = 1; i &lt; length+1;i++)&#123;                context.write(new Text(String.valueOf(i)),new Text(String.valueOf(topN[length-i+1])));            &#125;\t\t&#125;\t&#125;\tpublic static void main(String[] args) throws Exception &#123;\t\tConfiguration conf = new Configuration();\t\tconf.setInt(&quot;N&quot;,3);\t\tString[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();\t\tif (otherArgs.length &lt; 2) &#123;\t\t  System.err.println(&quot;Usage: TopN&lt;in&gt; [&lt;in&gt;...] &lt;out&gt;&quot;);\t\t  System.exit(2);\t\t&#125;\t\tJob job = Job.getInstance(conf, &quot;TopN&quot;);\t\tjob.setJarByClass(TopN.class);\t\tjob.setMapperClass(TMap.class);\t\tjob.setReducerClass(TReducer.class);\t\tjob.setOutputKeyClass(Text.class);\t\tjob.setOutputValueClass(Text.class);\t\tfor (int i = 0; i &lt; otherArgs.length - 1; ++i) &#123;\t\t\tFileInputFormat.addInputPath(job, new Path(otherArgs[i]));\t\t&#125;\t\tFileOutputFormat.setOutputPath(job,new Path(otherArgs[otherArgs.length - 1]));\t\tSystem.exit(job.waitForCompletion(true) ? 0 : 1);\t&#125;&#125;\nsetcp.batset classpath=%classpath%;C:\\Soft\\Hadoop\\etc\\hadoop;C:\\Soft\\Hadoop\\share\\hadoop\\common;C:\\Soft\\Hadoop\\share\\hadoop\\common\\lib\\*;C:\\Soft\\Hadoop\\share\\hadoop\\common\\*;C:\\Soft\\Hadoop\\share\\hadoop\\hdfs;C:\\Soft\\Hadoop\\share\\hadoop\\hdfs\\lib\\*;C:\\Soft\\Hadoop\\share\\hadoop\\hdfs\\*;C:\\Soft\\Hadoop\\share\\hadoop\\yarn;C:\\Soft\\Hadoop\\share\\hadoop\\yarn\\lib\\*;C:\\Soft\\Hadoop\\share\\hadoop\\yarn\\*;C:\\Soft\\Hadoop\\share\\hadoop\\mapreduce\\*\n基本步骤setcpjavac TopN.javajar cvf TopN.jar *.classhadoop jar TopN.jar TopN /test /outputhadoop fs -ls /outputhadoop fs -cat /output/part-r-00000hadoop fs -rm -r /output\n","tags":["Java","分布式","Hadoop","MapReduce"]},{"title":"NOTE|机器学习","url":"/2019/06/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/","content":"目前学习的机器学习知识点总结\nPerceptron原理感知机(Perceptron) 由两层神经元组成。输入层接收外界输入信号后传递给输出层， 输出层是M-P 神经元，亦称”阔值逻辑单元” (threshold logic unit)。\n构成可以看到，一个感知器有如下组成部分：\n\n输入权值 一个感知器可以接收多个输入$\\left(x{1}, x{2}, \\ldots, x{n} | x{i} \\in \\mathfrak{R}\\right)$，每个输入上有一个权值$w{i} \\in \\Re$，此外还有一个偏置项$b \\in \\mathfrak{R}$，就是上图中的$w{0}$。\n激活函数 感知器的激活函数可以有很多选择，比如我们可以选择下面这个阶跃函数$f$来作为激活函数：f(z)=\\left\\{\\begin{array}{ll}{1} & {z>0} \\\\ {0} & {\\text { otherwise }}\\end{array}\\right.\n输出 感知器的输出由下面这个公式来计算y=f(w \\bullet x+b) \\quad 公式1\n\n实现感知器训练算法：将权重项和偏置项初始化，然后，利用下面的感知器规则迭代修改$w_{i}$和$b$，直到训练完成。\n\\begin{array}{c}{w_{i} \\leftarrow w_{i}+\\Delta w_{i}} \\\\ {b \\leftarrow b+\\Delta b}\\end{array}其中\n\\begin{aligned} \\Delta w_{i} &=\\eta(y-y_{'}) x_{i} \\\\ \\Delta b &=\\eta(y-y_{'}) \\end{aligned}$w{i}$是与输入$x{i}$对应的权重项，是$b$偏置项。$y$是训练样本的实际值。而$y_{‘}$是感知器的输出值，它是根据公式(1)计算得出。$\\eta$是一个称为学习速率的常数，其作用是控制每一步调整权的幅度。\n代码from functools import reduceclass VectorOp(object):    &quot;&quot;&quot;    实现向量计算操作    &quot;&quot;&quot;    def dot(x, y):        &quot;&quot;&quot;        计算两个向量x和y的内积        &quot;&quot;&quot;        # 首先把x[x1,x2,x3...]和y[y1,y2,y3,...]按元素相乘        # 变成[x1*y1, x2*y2, x3*y3]        # 然后利用reduce求和        return reduce(lambda a, b: a + b, VectorOp.element_multiply(x, y), 0.0)    def element_multiply(x, y):        &quot;&quot;&quot;        将两个向量x和y按元素相乘        &quot;&quot;&quot;        # 首先把x[x1,x2,x3...]和y[y1,y2,y3,...]打包在一起        # 变成[(x1,y1),(x2,y2),(x3,y3),...]        # 然后利用map函数计算[x1*y1, x2*y2, x3*y3]        return list(map(lambda x_y: x_y[0] * x_y[1], zip(x, y)))    def element_add(x, y):        &quot;&quot;&quot;        将两个向量x和y按元素相加        &quot;&quot;&quot;        # 首先把x[x1,x2,x3...]和y[y1,y2,y3,...]打包在一起        # 变成[(x1,y1),(x2,y2),(x3,y3),...]        # 然后利用map函数计算[x1+y1, x2+y2, x3+y3]        return list(map(lambda x_y: x_y[0] + x_y[1], zip(x, y)))    def scala_multiply(v, s):        &quot;&quot;&quot;        将向量v中的每个元素和标量s相乘        &quot;&quot;&quot;        return map(lambda e: e * s, v)class Perceptron(object):    def __init__(self, input_num, activator):        &quot;&quot;&quot;        初始化感知器，设置输入参数的个数，以及激活函数。        &quot;&quot;&quot;        self.activator = activator        # 权重向量初始化为0        self.weights = [0.0] * input_num        # 偏置项初始化为0        self.bias = 0.0    def __str__(self):        &quot;&quot;&quot;        打印学习到的权重、偏置项        &quot;&quot;&quot;        return &#x27;weights\\t:%s\\nbias\\t:%f\\n&#x27; % (self.weights, self.bias)    def predict(self, input_vec):        &quot;&quot;&quot;        输入向量，输出感知器的计算结果        &quot;&quot;&quot;        # 计算向量input_vec[x1,x2,x3...]和weights[w1,w2,w3,...]的内积        # 然后加上bias        return self.activator(VectorOp.dot(input_vec, self.weights) + self.bias)    def train(self, input_vecs, labels, iteration, rate):        &quot;&quot;&quot;        输入训练数据：一组向量、与每个向量对应的label；以及训练轮数、学习率        &quot;&quot;&quot;        for i in range(iteration):            self._one_iteration(input_vecs, labels, rate)    def _one_iteration(self, input_vecs, labels, rate):        &quot;&quot;&quot;        一次迭代，把所有的训练数据过一遍        &quot;&quot;&quot;        # 把输入和输出打包在一起，成为样本的列表[(input_vec, label), ...]        # 而每个训练样本是(input_vec, label)        samples = zip(input_vecs, labels)        # 对每个样本，按照感知器规则更新权重        for (input_vec, label) in samples:            # 计算感知器在当前权重下的输出            output = self.predict(input_vec)            # 更新权重            self._update_weights(input_vec, output, label, rate)    def _update_weights(self, input_vec, output, label, rate):        &quot;&quot;&quot;        按照感知器规则更新权重        &quot;&quot;&quot;        # 首先计算本次更新的delta        # 然后把input_vec[x1,x2,x3,...]向量中的每个值乘上delta，得到每个权重更新        # 最后再把权重更新按元素加到原先的weights[w1,w2,w3,...]上        delta = label - output        self.weights = VectorOp.element_add(            self.weights, VectorOp.scala_multiply(input_vec, rate * delta))        # 更新bias        self.bias += rate * deltadef f(x):    &quot;&quot;&quot;    定义激活函数f    &quot;&quot;&quot;    return 1 if x &gt; 0 else -1\n\n\n","tags":["NOTE","机器学习"]},{"title":"JAVA|面向消息中间件","url":"/2019/06/22/%E4%B8%AD%E9%97%B4%E4%BB%B6/","content":"面向消息中间件（Message Oriented Middleware）提供了一种分布式消息队列服务，使得节点之间可以实现基于消息的形式灵活的异步通信。\n工作原理\n两种通信模式点对点通信模式：\n用于消息生产者和消息消费者之间点点对点通信，相当于在生产者和消费者之间建立了一个点对点消息队列\n每个消息只有一个消费者，不可重复消费(一旦被消费，消息就不再在消息队列中)\n高级队列模式：带优先级的队列；支持持久性的队列\n\n发布/订阅通信模式：\n支持向一个特定的消息主题发布消息。 多个订阅者可以同时关注并接收来自特定消息主题的消息\n可以灵活地实现广播、组播和多对多等通信模式\n可以支持持久性、事务机制等高级功能\n\n常用的MOM中间件ActiveMQ：\n\n由 Apache 出品，完全兼容JMS（Java Message Service）为多种编程语言提供客户端API内部支持多种通信协议必须部署中心服务器作为消息路由代理。中心服务器可由服务器集群代替。\n\nRabbitMQ：\n\n采用Erlang语言实现的AMQP协议的消息中间件，最初起源于金融系统。\n\nRocketMQ：\n\n阿里 的开源产品，用 Java 语言实现；在阿里内部被广泛应用在订单，交易，充值，流计算，消息推送，日志流式处理等场景。\n\nApache Kafka：\n\n提供完全分布式架构，与Apache的其他平台如Hadoop、Apache Storm、Spark、Flink等集成方便。\n\nZeroMQ：\n\n号称史上最快的消息队列，基于C语言开发。\n\nWebsphereMQ：\n\nIBM的MOM中间件产品\n\n编程示例题目利用MOM消息队列技术实现一个分布式随机信号分析系统，具体要求：\n\n随机信号产生器每隔10毫秒左右就产生一个正态分布的随机数字，并作为一个消息发布。\n多个随机信号分析模块订阅并接收该随机数字，然后对信号进行分析并实时显示分析结果。至少包含如下分析模块：\n计算随机信号的均值；\n计算过去N个随机信号的方差（N为常量，可设置）\n实现基于正态分布的异常点检测$\\mu \\pm 3 \\sigma$\n\n\n\n代码Publisher.javapackage topic;import java.io.IOException;import java.util.Random;import java.util.Scanner;import javax.jms.Connection;import javax.jms.ConnectionFactory;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageProducer;import javax.jms.Session;import javax.jms.Topic;import org.apache.activemq.ActiveMQConnectionFactory;public class Publisher &#123;    private static String brokerURL = &quot;tcp://localhost:61616&quot;;    private static ConnectionFactory factory;    private Connection connection;    private Session session;    private MessageProducer producer;\tprivate Topic topic;\tprivate Random random=new Random();\tprivate String d;\tstatic Scanner in=new Scanner(System.in);        public Publisher(String topicName) throws JMSException &#123;\t\t    \tfactory = new ActiveMQConnectionFactory(brokerURL);    \tconnection = factory.createConnection();                session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);\t\ttopic = session.createTopic(topicName);        producer = session.createProducer(topic);        producer.setTimeToLive(1000);\t\tconnection.start();    &#125;            public void close() throws JMSException &#123;        if (connection != null) &#123;            connection.close();        &#125;    &#125;    \tpublic static void main(String[] args) throws JMSException, InterruptedException, IOException &#123;//    \tSystem.out.println(&quot;Please input u and a&quot;);//    \tint u=in.nextInt();//    \tint a=in.nextInt();    \tint u=0;    \tint a=1;    \tPublisher publisher = new Publisher(&quot;Gaussian&quot;);    \tint i=0;    \tlong t1 = System.currentTimeMillis();    \twhile(true)    \t&#123;    \t\ti++;    \t\tlong t2 = System.currentTimeMillis();    \t\tif(t2-t1&gt;10000)    \t\t&#123;    \t\t\tbreak;    \t\t&#125;    \t\tpublisher.sendMessage(u,a,i);    \t\tThread.sleep(10);\t\t&#125;    \tpublisher.close();\t&#125;\t    public void sendMessage(int a,int b,int i) throws JMSException &#123;    \td = Double.toString(b*random.nextGaussian()+a);        Message message = session.createTextMessage(d);        producer.send(message);        System.out.println(&quot;Sent number &quot;+i+&quot; :&quot;+d);    &#125;\t&#125;\nASyncConsumer_ave.java（计算均值）package topic;import javax.jms.Connection;import javax.jms.ConnectionFactory;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageConsumer;import javax.jms.MessageListener;import javax.jms.Session;import javax.jms.TextMessage;import javax.jms.Topic;import org.apache.activemq.ActiveMQConnectionFactory;class Average implements MessageListener &#123;\tint num=0;\tdouble sum=0;\tpublic void onMessage(Message message) &#123;\t\ttry &#123;\t\t\tString ss=((TextMessage)message).getText();\t\t\tnum++;\t\t\tsum+=Double.valueOf(ss);\t\t\tSystem.out.println(&quot;number:&quot;+num+&quot; average:&quot;+sum/num);\t\t&#125; catch (Exception e) &#123;\t\t\te.printStackTrace();\t\t&#125;\t&#125;&#125;public class ASyncConsumer_ave &#123;    public static void main(String[] args) throws JMSException &#123;\t\tString brokerURL = &quot;tcp://localhost:61616&quot;;\t\tConnectionFactory factory = null;\t\tConnection connection = null;\t\tSession session = null;\t\tTopic topic = null;\t\tMessageConsumer messageConsumer = null;\t\tAverage average=null;\t\t\t\ttry &#123;\t\t\tfactory = new ActiveMQConnectionFactory(brokerURL);\t\t\tconnection = factory.createConnection();\t\t\tconnection.start();\t\t\t\t\t\tsession = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);\t\t\ttopic = session.createTopic(&quot;Gaussian&quot;);\t\t\tmessageConsumer = session.createConsumer(topic);\t\t\t\t\t\taverage = new Average();\t\t\t\t\t\tmessageConsumer.setMessageListener(average);\t\t\t\t\t\tSystem.out.println(&quot;Press any key to exit.&quot;);\t\t\tSystem.in.read();\t\t&#125; catch (Exception e) &#123;\t\t\te.printStackTrace();\t\t&#125; finally &#123;\t\t\tconnection.close();\t\t&#125;\t&#125;\t&#125;\nASyncConsumer_var.java（计算方差）package topic;import java.util.ArrayList;import java.util.Scanner;import javax.jms.Connection;import javax.jms.ConnectionFactory;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageConsumer;import javax.jms.MessageListener;import javax.jms.Session;import javax.jms.TextMessage;import javax.jms.Topic;import org.apache.activemq.ActiveMQConnectionFactory;class Variance implements MessageListener &#123;\tprivate ArrayList&lt;Double&gt; p = new ArrayList&lt;Double&gt;();\tprivate int n=0;\tpublic Variance(int N) &#123;\t\tthis.n=N;\t&#125;\t\tpublic void onMessage(Message message) &#123;\t\ttry &#123;\t\t\tString ss=((TextMessage)message).getText();\t\t\tp.add(Double.valueOf(ss));\t\t\tdouble ave = 0.0;\t\t\tdouble var = 0.0;\t\t\tif(p.size()&gt;=n)\t\t\t&#123;\t\t\t\tfor (int i=0;i&lt;n;i++) &#123;\t\t\t\t\tave += p.get(i);\t\t\t\t&#125;\t\t\t\tave /= n;\t\t\t\tfor (int i=0;i&lt;n;i++) &#123;\t\t\t\t\tvar += (p.get(i) - ave) * (p.get(i) - ave);\t\t\t\t&#125;\t\t\t\tSystem.out.println(&quot;Variance：&quot;+var/n);\t\t\t&#125;\t\t&#125; catch (Exception e) &#123;\t\t\te.printStackTrace();\t\t&#125;\t&#125;&#125;public class ASyncConsumer_var &#123;\tstatic Scanner in=new Scanner(System.in);    public static void main(String[] args) throws JMSException &#123;\t\tString brokerURL = &quot;tcp://localhost:61616&quot;;\t\tConnectionFactory factory = null;\t\tConnection connection = null;\t\tSession session = null;\t\tTopic topic = null;\t\tMessageConsumer messageConsumer = null;\t\tVariance variance=null;\t\t        \t\ttry &#123;\t\t\tfactory = new ActiveMQConnectionFactory(brokerURL);\t\t\tconnection = factory.createConnection();\t\t\tconnection.start();\t\t\t\t\t\tsession = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);\t\t\ttopic = session.createTopic(&quot;Gaussian&quot;);\t\t\tmessageConsumer = session.createConsumer(topic);\t\t\tSystem.out.println(&quot;Input N:&quot;);\t\t\tint n=in.nextInt();\t\t\t\t\t\tvariance=new Variance(n);\t\t\tmessageConsumer.setMessageListener(variance);\t\t\t\t\t\tSystem.out.println(&quot;Press any key to exit.&quot;);\t\t\tSystem.in.read();\t\t&#125; catch (Exception e) &#123;\t\t\te.printStackTrace();\t\t&#125; finally &#123;\t\t\tconnection.close();\t\t&#125;\t&#125;\t&#125;\nASyncConsumer_err.java（异常点检测）package topic;import javax.jms.Connection;import javax.jms.ConnectionFactory;import javax.jms.JMSException;import javax.jms.Message;import javax.jms.MessageConsumer;import javax.jms.MessageListener;import javax.jms.Session;import javax.jms.TextMessage;import javax.jms.Topic;import org.apache.activemq.ActiveMQConnectionFactory;class Error implements MessageListener &#123;\tdouble u=0;\tdouble a=0;\tdouble v=0;\tdouble sum=0;\tint num=0;\t\tpublic void onMessage(Message message) &#123;\t\ttry &#123;\t\t\tdouble d = Double.valueOf(((TextMessage)message).getText());\t\t\tsum += d;\t\t\tnum++;\t\t\tif(num&gt;1)\t\t\t&#123;\t\t\t\tu=sum/num;\t\t\t\tv += (d - u) * (d - u);\t\t\t\ta=Math.sqrt(v/num);\t\t\t\tif(d&gt;u-3*a&amp;&amp;d&lt;u+3*a)\t\t\t\t&#123;\t\t\t\t\tSystem.out.println(&quot;TRUE &quot;+d);\t\t\t\t&#125;\t\t\t\telse &#123;\t\t\t\t\tSystem.out.println(&quot;ERROR &quot;+d);\t\t\t\t&#125;\t\t\t&#125;\t\t&#125; catch (Exception e) &#123;\t\t\te.printStackTrace();\t\t&#125;\t&#125;&#125;public class ASyncConsumer_err &#123;    public static void main(String[] args) throws JMSException &#123;\t\tString brokerURL = &quot;tcp://localhost:61616&quot;;\t\tConnectionFactory factory = null;\t\tConnection connection = null;\t\tSession session = null;\t\tTopic topic = null;\t\tMessageConsumer messageConsumer = null;\t\tError error=null;        \t\ttry &#123;\t\t\tfactory = new ActiveMQConnectionFactory(brokerURL);\t\t\tconnection = factory.createConnection();\t\t\tconnection.start();\t\t\t\t\t\tsession = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);\t\t\ttopic = session.createTopic(&quot;Gaussian&quot;);\t\t\tmessageConsumer = session.createConsumer(topic);\t\t\t\t\t\terror=new Error();\t\t\t\t\t\tmessageConsumer.setMessageListener(error);\t\t\t\t\t\tSystem.out.println(&quot;Press any key to exit.&quot;);\t\t\tSystem.in.read();\t\t&#125; catch (Exception e) &#123;\t\t\te.printStackTrace();\t\t&#125; finally &#123;\t\t\tconnection.close();\t\t&#125;\t&#125;\t&#125;\n实现\n开启ActiveMQ\n用三个窗口分别运行ASyncConsumer_ave.java，ASyncConsumer_var.java和ASyncConsumer_err.java。\n运行Publisher.java输入均值和方差\n结果\n\n","tags":["Java","分布式","MOM"]},{"title":"JAVA|Socket编程实例","url":"/2019/06/21/Java-Socket/","content":"多线程版UDP及线程池版的TCP\nTCP/IP网络体系TCP/IP先于OSI模型，不完全符合OSI标准\nTCP/IP四层模型\n也可分为五层，将网络接口层分为两层\n\n\n各层网络协议的存在位置\n路由器中只包含物理层、链路层、网络层协议实现模块\n主机中包含五层协议实现模块\n操作系统负责实现传输层及以下网络协议的实现\n\nSocket套接字什么是socket？传输层和网络层提供给应用层的标准化编程接口（或称为编程接口）\nSocket类型\n流式套接字\n数据报套接字\n原始套接字\n\nTCP套接字编程典型模型\nUDP套接字编程典型模型\n并发服务技术基于多线程的并发服务技术\n基于线程池的并发服务技术\nJava实现多线程版UDPUDPClient.javapackage yun_computer;import java.net.*;import java.io.*;public class UDPClient &#123;    public static void main(String[] args) throws IOException &#123;    \t        InetAddress address = InetAddress.getByName(&quot;localhost&quot;);        int port = 8800;        String userInput = null;                byte[] data= new byte[1024];        byte[] reply = new byte[1024];                BufferedReader stdIn = new BufferedReader(new InputStreamReader(System.in));        DatagramSocket socket = new DatagramSocket();        DatagramPacket p1,p2 = null;                while ((userInput=stdIn.readLine())!=null) &#123;        \tdata = userInput.getBytes();            p1 = new DatagramPacket(data, data.length, address, port);            socket.send(p1);                        p2 = new DatagramPacket(reply, reply.length);            socket.receive(p2);                        String info = new String(reply, 0, p2.getLength());            System.out.println(&quot;Server：&quot; + info);\t\t&#125;        socket.close();    &#125;&#125;\nUDPThread.javapackage yun_computer;import java.net.*;import java.io.*;public class UDPThread implements Runnable &#123;\tDatagramSocket socket = null;    DatagramPacket packet = null;    public UDPThread(DatagramSocket socket, DatagramPacket packet) &#123;        this.socket = socket;        this.packet = packet;    &#125;    public void run() &#123;        String info = null;        byte[] reply = null;        DatagramPacket p = null;        try &#123;        \tInetAddress address = packet.getAddress();            System.out.println(&quot;IP：&quot; + address.getHostAddress());                        info = new String(packet.getData(), 0, packet.getLength());            System.out.println(&quot;Message from Client：&quot; + info);            reply = &quot;Successful reception&quot;.getBytes();            p = new DatagramPacket(reply, reply.length, packet.getAddress(), packet.getPort());            socket.send(p);                    &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125;    &#125;&#125;\nUDPServer.javapackage yun_computer;import java.net.*;import java.io.*;public class UDPServer &#123;    public static void main(String[] args) throws IOException &#123;    \t    \tbyte[] data = new byte[1024];        DatagramSocket socket = new DatagramSocket(8800);        DatagramPacket packet = new DatagramPacket(data, data.length);                System.out.println(&quot;Server...&quot;);        while (true) &#123;            socket.receive(packet);            UDPThread udp = new UDPThread(socket, packet);            udp.run();        &#125;    &#125;&#125;\n线程池版的TCPTCPClient.javapackage yun_computer;import java.io.*;import java.net.*;public class TCPClient &#123;    public static void main(String[] args) throws Exception &#123;\t\t \t\tString userInput = null;\t\tString echoMessage = null;\t\t\t\tBufferedReader stdIn = new BufferedReader(new InputStreamReader(System.in));\t\t\t\tSocket socket = new Socket(&quot;127.0.0.1&quot;, 8189);\t\tSystem.out.println(&quot;Connected to Server&quot;);\t\t\t\tInputStream inStream = socket.getInputStream();\t\tOutputStream outStream = socket.getOutputStream();\t\tBufferedReader in = new BufferedReader(new InputStreamReader(inStream));\t\tPrintWriter out = new PrintWriter(outStream);\t\t\t\twhile((userInput=stdIn.readLine())!=null)        &#123;            out.println(userInput);\t\t\tout.flush();\t\t\techoMessage = in.readLine();\t\t\tSystem.out.println(&quot;Echo from server: &quot; + echoMessage);\t\t&#125;\t\tsocket.close();\t&#125;&#125;\nTCPThread.javapackage yun_computer;import java.io.*;import java.net.*;public class TCPThread extends Thread &#123;        Socket socket = null;    public TCPThread(Socket socket) &#123;        this.socket = socket;    &#125;    public void run()&#123;        InputStream is=null;        InputStreamReader isr=null;        BufferedReader br=null;        OutputStream os=null;        PrintWriter pw=null;        try &#123;            is = socket.getInputStream();            isr = new InputStreamReader(is);            br = new BufferedReader(isr);\t\t\tos = socket.getOutputStream();            pw = new PrintWriter(os);            String info=null;            while((info=br.readLine())!=null)&#123;            \tInetAddress address = socket.getInetAddress();                System.out.println(&quot;IP：&quot; + address.getHostAddress());                System.out.println(&quot;Message from client:&quot;+info);\t\t\t\tpw.println(info);\t\t\t\tpw.flush();            &#125;        &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125;finally&#123;            try &#123;                if(pw!=null)                    pw.close();                if(os!=null)                    os.close();                if(br!=null)                    br.close();                if(isr!=null)                    isr.close();                if(is!=null)                    is.close();                if(socket!=null)                    socket.close();            &#125; catch (IOException e) &#123;                e.printStackTrace();            &#125;        &#125;    &#125;&#125;\nTCPServer.javapackage yun_computer;import java.net.*;import java.util.concurrent.*;public class TCPServer &#123;\t public static void main(String[] args) throws Exception &#123;\t\t int n=2;\t\t int m=4;\t\t \t\t ThreadPoolExecutor executor = new ThreadPoolExecutor(n, m, 200, TimeUnit.MILLISECONDS,  \t                new ArrayBlockingQueue&lt;Runnable&gt;(n));\t\t \t\t ServerSocket listenSocket = new ServerSocket(8189); \t\t System.out.println(&quot;Server listening at 8189&quot;);\t\t \t\t for(int i=0;i&lt;(n+m);i++) &#123;\t\t\t Socket clientSocket = listenSocket.accept();\t\t\t System.out.println(&quot;Accepted connection from client&quot;);\t\t\t TCPThread tcp=new TCPThread(clientSocket);\t\t\t executor.execute(tcp);\t\t &#125;\t\t executor.shutdown();\t\t listenSocket.close();\t &#125;&#125;\n","tags":["Java","Socket","分布式","TCP","UDP"]},{"title":"NOTE|人工智能","url":"/2019/06/19/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/","content":"人工智能简单的笔记ψ(｀∇´)ψ\n第一章 绪论什么是人工智能？\n智能机器：能够在各类环境中自主地或交互地执行各种拟人任务的机器。\n人工智能(学科)：人工智能(学科)是计算机科学中涉及研究、设计和应用智能机器的一个分支。它的近期主要目标在于研究用机器来模仿和执行人脑的某些智力功能，并开发相关理论和技术。\n人工智能(能力)：人工智能(能力)是智能机器所执行的通常与人类智能有关的智能行为，如判断、推理、证明、识别、感知、理解、通信、设计、思考、规划、学习和问题求解等思维活动。人工智能有哪些学派？符号主义：以知识的符号表达为基础，通过推理进行问题求解连接主义：认为人的思维基元是神经元，而不是符号处理过程行为主义：主张从行为方面模拟、延伸、扩展人的智能，认为“智能”可以不需要“知识”\n\n第二章 知识表示方法什么是知识\n数据与信息：数据是信息的载体和表示；信息是数据的语义。\n知识：一般来说，把有关信息关联在一起所形成的信息结构称为知识。一些重要的等价式一些重要的永真蕴含式状态空间的搜索策略搜索策略\n\n\n广度优先搜索按照“先扩展出的节点先被考察”的原则进行搜索；\n深度优先搜索按照“后扩展出的节点先被考察”的原则进行搜索；\n有界深度优先搜索的原则与深度优先搜索相同，但是它规定了深度限界，使搜索不得无限制地向纵深方向发展；\n代价树的广度优先搜索按照“哪个节点到根节点的代价小就先考察哪个节点”的原则进行搜索；\n代价树的深度优先搜索按照“当前节点的哪个子节点到其父节点的代价小就先考察哪个子节点”的原则进行搜索；\n局部择优搜索按照“当前节点的哪个子节点到目标节点的估计代价小就先考察哪个子节点”的原则进行搜索；\n全局择优搜索按照“哪个节点到目标节点的估计代价小就先考察哪个节点”的原则进行搜索\n\n以重排九宫为例\n盲目搜索广度优先搜索\n\n优点：    只要问题有解，用广度优先搜索总可以得到解，而且得到的是路径最短的解。缺点：    广度优先搜索盲目性较大，当目标节点距初始节点较远时将会产生许多无用节点，搜索效率低。\n\n深度优先搜索\n\n1.在深度优先搜索中，搜索一旦进入某个分支，就将沿着该分支一直向下搜索。如果目标节点恰好在此分支上，则可较快地得到解。但是，如果目标节点不在此分支上，而该分支又是一个无穷分支，则就不可能得到解。所以深度优先搜索是不完备的，即使问题有解，它也不一定能求得解。2.用深度优先求得的解，不一定是路径最短的解。3.本质：以初始节点为根节点，在状态空间图中按照深度优先的原则，生成一棵搜索树。\n\n有界深度优先搜索\n\n1.如果问题有解，且其路径长度≤dm，则上述搜索过程一定能求得解。但是，若解的路径长度&gt;dm,则上述搜索过程就得不到解。这说明在有界深度优先搜索中，深度界限的选择是很重要的。2.要恰当地给出dm的值是比较困难的。即使能求出解，它也不一定是最优解。\n\n代价树上标有代价(或费用)的树称为代价树。\n用g(x)表示从初始节点S0到节点x的代价，用c(x1,x2)表示从父节点x1到子节点x2的代价，则有：\ng(x_2)=g(x_1)+c(x_1,x_2)代价树的广度优先搜索搜索过程\n\n把初始节点S0放入OPEN表，令g(S0)=0。\n如果OPEN表为空，则问题无解，退出。\n把OPEN表的第一个节点（记为节点n）取出放入CLOSE表。\n考察节点n是否为目标节点。若是，则求得了问题的解，退出。\n若节点n不可扩展，则转第2步。\n扩展节点n，为每一个子节点都配置指向父节点的指针，并将各子节点放入OPEN表中；计算各子节点的代价，按各节点的代价对OPEN表中的全部节点进行排序(按从小到大的顺序)，然后转第2步\n\n代价树的深度优先搜索搜索过程\n\n把初始节点S0放入OPEN表，令g(S0)=0。\n如果OPEN表为空，则问题无解，退出。\n把OPEN表的第一个节点（记为节点n）取出放入CLOSE表。\n考察节点n是否为目标节点。若是，则求得了问题的解，退出。\n若节点n不可扩展，则转第2步。\n扩展节点n，将其子节点按“边”代价从小到大的顺序放到OPEN表中的首部，并为每一个子节点都配置指向父节点的指针，然后转第2步。\n代价树的深度优先搜索是不完备的。\n\n\n\n启发式搜索盲目搜索具有较大的盲目性，产生的无用节点较多，效率不高。\n启发式搜索采用问题自身的特性信息，以指导搜索朝着最有希望的方向前进。这种搜索针对性较强，因而效率较高\n启发性信息与估价函数可用于指导搜索过程，且与具体问题有关的信息称为启发性信息。用于评估节点重要性的函数称为估价函数。其一般形式为：\nf(x) = g(x)+h(x)\n其中g(x)表示从初始节点S0到节点x的代价；h(x)是从节点x到目标节点Sg的最优路径的代价的估计，它体现了问题的启发性信息，称为启发函数。 f(x) 决定节点在OPEN表中的次序。g(x) 指出了搜索的横向趋势，有利于搜索的完备性，但影响搜索的效率。h(x)指出了搜索的纵向趋势，有利于提高搜索的效率，但影响搜索的完备性。\n\n局部择优搜索局部择优搜索是一种启发式搜索方法，是对深度优先搜索方法的一种改进。基本思想：当一个节点被扩展以后，按f(x)对每一个子节点计算估价值，并选择最小者作为下一个要考察的节点。\n搜索过程\n\n把初始节点S0放入OPEN表，计算f(S0)。\n如果OPEN表为空，则问题无解，退出。\n把OPEN表的第一个节点（记为节点n）取出放入CLOSE表。\n考察节点n是否为目标节点。若是，则求得了问题的解，退出。\n若节点n不可扩展，则转第2步。\n扩展节点n，用估价函数f(x)计算每个子节点的估价值，并按估价值从小到大的顺序放到OPEN表中的首部，并为每一个子节点都配置指向父节点的指针，然后转第2步。\n\n\n在局部择优搜索中，若令f(x) = g(x)，则局部择优搜索就成为代价树的深度优先搜索。在局部择优搜索中，若令f(x) =d(x)，这里d(x) 表示节点x的深度，则局部择优搜索就成为深度优先搜索。因此：深度优先搜索、代价树的深度优先搜索均为局部择优搜索的特例\n\n全局择优搜索每当要选择下一个节点进行考察时，全局择优搜索每次总是从OPEN表的全体节点中选择一个估价值最小的节点。搜索过程\n\n把初始节点S0放入OPEN表，计算f(S0)。\n如果OPEN表为空，则问题无解，退出。\n把OPEN表的第一个节点（记为节点n）取出放入CLOSE表。\n考察节点n是否为目标节点。若是，则求得了问题的解，退出。\n若节点n不可扩展，则转第2步。\n扩展节点n，用估价函数f(x)计算每个子节点的估价值，并为每一个子节点都配置指向父节点的指针。把这些子节点都送入OPEN表中，然后对OPEN表中的全部节点按估价值从小至大的顺序进行排序，然后转第2步。\n\n\n在全局择优搜索中，若令f(x) = g(x)，则它就成为代价树的广度优先搜索。在全局择优搜索中，若令f(x) =d(x)，这里d(x) 表示节点x的深度，则它就成为广度优先搜索。因此：广度优先搜索、代价树的广度优先搜索是全局择优搜索的两个特例。\n\n例子设估价函数为 f(x)=d(x)+h(x)，其中，d(x)表示节点x的深度，h(x)表示节点x的格局与目标节点格局不相同的牌数。\n第三章变量代换代换是一个形如${t_1/x_1,t_2/x_2,…,t_n/x_n}$的有限集合。其中$t_1,t_2,…,t_n$是项（常量、变量、函数）;$x_1,x_2,…,x_n$是（某一公式中）互不相同的变元；$t_i/x_i$表示用$t_i$代换$x_i$不允许$t_i$与$x_i$相同，也不允许变元$x_i$循环地出现在另一个$t_j$中。\n\n例如：{a/x,f(b)/y,w/z}是一个代换{g(y)/x,f(x)/y}不是代换{g(a)/x,f(x)/y}是代换\n\n代换的复合定义 设$\\theta={t_1/x_1,t_2/x_2,\\cdots,t_n/x_n}$$\\lambda={u_1/y_1,u_2/y_2,\\cdots,u_m/y_m}$是两个代换则这两个代换的复合也是一个代换，它是从\n\\{t_1\\lambda/x_1,t_2\\lambda/x_2,\\cdots,t_n\\lambda/x_n,u_1/y_1,u_2/y_2,\\cdots,u_m/y_m\\}中删去如下两种元素：$t_i\\lambda/x_i \\quad 当t_i\\lambda=x_i$$u_i/y_i \\quad 当y_i\\in{x_1,x_2,\\cdots,x_n}$后剩下的元素所构成的集合，记为θ°λ\n\n(1) $t_i\\lambda$表示对$t_i$运用λ进行代换。(2)θ°λ就是对一个公式F先运用θ进行代换，然后再运用λ进行代换：F(θ°λ)=（F θ）λ\n\n最一般合一\nF={P(a,x,f(g(y))),P(z,f(z),f(u))}\n求其最一般合一的过程：\n令F0=F, σ0=ε。 F0中有两个表达式，所以σ0不是最一般合一。差异集：D0={a,z}。代换：$ {a/z}F1= F0 {a/z}={P(a,x,f(g(y))),P(a,f(a),f(u))} 。σ1=σ0°{a/z}={a/z}D1={x,f(a)} 。代换： {f(a)/x}F2=F1{f(a)/x}={P(a,f(a),f(g(y))),P(a,f(a),f(u))} 。σ2=σ1°{f(a)/x}={a/z,f(a)/x}D2={g(y),u} 。代换： {g(y)/u}F3=F2{g(y)/u}={P(a,f(a),f(g(y))),P(a,f(a),f(g(y)))} 。σ3=σ2°{g(y)/u}={a/z,f(a)/x,g(y)/u} $\n\n子句集定义： 任何文字的析取式称为子句(1) 合取范式：C1 ∧C2 ∧C3… ∧Cn(2) 子句集:     S= {C1 ,C2 ,C3… ,Cn}(3)任何谓词公式F都可通过等价关系及推理规则化为相应的子句集S\n把谓词公式化成子句集\n利用等价关系消去“→”和“↔”例如公式$(\\forall x)((\\forall y) P(x, y) \\rightarrow \\neg(\\forall y)(Q(x, y) \\rightarrow R(x, y)))$可等价变换成$(\\forall x)(\\neg(\\forall y) P(x, y) \\vee \\neg(\\forall y)(\\neg Q(x, y) \\vee R(x, y)))$\n利用等价关系把“¬”移到紧靠谓词的位置上上式经等价变换后$(\\forall x)((\\exists y) \\neg P(x, y) \\vee(\\exists y)(Q(x, y) \\wedge \\neg R(x, y)))$\n重新命名变元，使不同量词约束的变元有不同的名字上式经变换后$(\\forall x)((\\exists y) \\neg P(x, y) \\vee(\\exists z)(Q(x, z) \\wedge \\neg R(x, z)))$\n消去存在量词a.存在量词前面没有全称量词时，则只要用一个新的个体常量替换受该量词约束的变元。b.存在量词前面有一个或者多个全称量词时，要用函数f(x1,x2,…,xn)替换受该存在量词约束的变元。上式中存在量词($\\exists y$)及($\\exists z$)都位于($\\forall x$)的后面，所以需要用函数替换，设替换y和z的函数分别是f(x)和g(x)，则替换后得到$(\\forall x)(\\neg P(x, f(x)) \\vee(Q(x, g(x)) \\wedge \\neg R(x, g(x))))$\n把全称量词全部移到公式的左边$(\\forall x)(\\neg P(x, f(x)) \\vee(Q(x, g(x)) \\wedge \\neg R(x, g(x))))$\n利用等价关系把公式化为Skolem标准形$P \\vee(Q \\wedge R) \\Leftrightarrow(P \\vee Q) \\wedge(P \\vee R)$Skolem标准形的一般形式是$\\left(\\forall x{1}\\right)\\left(\\forall x{2}\\right) \\cdots\\left(\\forall x_{n}\\right) M$其中，M是子句的合取式，称为Skolem标准形的母式。上式化为Skolem标准形后得到$(\\forall x)((\\neg P(x, f(x)) \\vee Q(x, g(x))) \\wedge(\\neg P(x, f(x)) \\vee \\neg R(x, g(x))))$\n消去全称量词\n对变元更名，使不同子句中的变元不同名$(\\neg P(x, f(x)) \\vee Q(x, g(x))) \\wedge(\\neg P(y, f(y)) \\vee \\neg R(y, g(y)))$\n消去合取词，就得到子句集$\\neg P(x, f(x)) \\vee Q(x, g(x))$$\\neg P(y, f(y)) \\vee \\neg R(y, g(y))$\n\n海伯伦理论（Herbrand）为了判断子句集的不可满足性，需要对所有可能论域上的所有解释进行判定。只有当子句集对任何非空个体域上的任何一个解释都是不可满足的时候，才可断定该子句集是不可满足的。\n鲁滨逊归结原理子句集S的不可满足性：对于任意论域中的任意一个解释，S中的子句不能同时取得真值T。一旦S中包含空子句，则S必不可满足。    \n基本思想：检查子句集S中是否包含空子句。若包含，则S不可满足；若不包含，就在子句集中选择合适的子句进行归结，一旦通过归结能推出空子句，就说明子句集S是不可满足的。\n归结反演的步骤设F为已知前提的公式集，Q为目标公式(结论)，用归结反演证明Q为真的步骤是：\n\n否定Q，得到¬Q；\n把¬Q并入到公式集F中，得到{F, ¬Q};\n把公式集{F, ¬Q}化为子句集S；\n应用归结原理对子句集S中的子句进行归结，并把每次归结得到的归结式都并入S中。如此反复进行，若出现了空子句，则停止归结，此时就证明了Q为真。\n\n应用归结原理求取问题的答案求解的步骤：\n把已知前提用谓词公式表示出来，并且化为相应的子句集。设该子句集的名字为S。\n把待求解的问题也用谓词公式表示出来，然后把它否定并与谓词Answer构成析取式。Answer是一个为了求解问题而专设的谓词，其变元须与问题公式的变元完全一致。\n把此析取式化为子句集，并且把该子句集并入到子句集S中，得到子句集S’。\n对S’应用归结原理进行归结。\n若得到归结式Answer，则答案就在Answer中。\n\n第四章可信度方法概念\n\n根据经验对一个事物和现象为真的相信程度称为可信度。\n在可信度方法中，由专家给出规则或知识的可信度，从而可避免对先验概率、条件概率的要求。\n可信度方法首先在专家系统MYCIN中得到了成功的应用。\n\nC-F模型组合证据不确定性的算法可采用最大最小法。若$\\mathrm{E}=\\mathrm{E}{1} \\text { AND } \\mathrm{E}{2} \\text { AND } \\ldots \\text { AND } \\mathrm{E}_{\\mathrm{n}}$，则\n\\mathrm{CF}(\\mathrm{E})=\\min \\left\\{\\mathrm{CF}\\left(\\mathrm{E}_{1}\\right), \\mathrm{CF}\\left(\\mathrm{E}_{2}\\right), \\ldots, \\mathrm{CF}\\left(\\mathrm{E}_{n}\\right)\\right\\}若$\\mathrm{E}=\\mathrm{E}{1} \\text { OR } \\mathrm{E}{2} \\text { OR } \\ldots \\text { OR } \\mathrm{E}_{\\mathrm{n}}$，则\n\\mathrm{CF}(\\mathrm{E})=\\max \\left\\{\\mathrm{CF}\\left(\\mathrm{E}_{1}\\right), \\mathrm{CF}\\left(\\mathrm{E}_{2}\\right), \\ldots, \\mathrm{CF}\\left(\\mathrm{E}_{\\mathrm{n}}\\right)\\right\\}结论不确定性的合成算法若由多条不同知识推出了相同的结论，但可信度不同，则用合成算法求出综合可信度。设有如下知识：IF $\\quad \\mathrm{E}{1} \\quad$ THEN $\\quad \\mathrm{H} \\quad\\left(\\mathrm{CF}\\left(\\mathrm{H}, \\mathrm{E}{1}\\right)\\right)$IF $\\quad \\mathrm{E}{2} \\quad$ THEN $\\quad \\mathrm{H} \\quad\\left(\\mathrm{CF}\\left(\\mathrm{H}, \\mathrm{E}{2}\\right)\\right)$则结论H的综合可信度分如下两步算出：首先分别对每一条知识求出$CF(H)$: 计算$CF1(H)$,$CF_2(H)$然后用下述公式求出E1与E2对H的综合可信度$CF{12}(H)$:\nP(H | S)=\\left\\{\\begin{array}{ll}{C F_{1}(H)+C F_{2}(H)-C F_{1}(H) \\times C F_{2}(H), C F_{1}(H) \\geq 0, C F_{2}(H) \\geq 0}\\\\ {C F_{1}(H)+C F_{2}(H)+C F_{1}(H) \\times C F_{2}(H), C F_{1}(H)","tags":["NOTE"]},{"title":"Windows|linux子系统安装及使用","url":"/2019/06/19/linux%E5%AD%90%E7%B3%BB%E7%BB%9F/","content":"Windows 10 专业版\n最近用c语言写socket套接字，需要在Linux上编译运行。但用虚拟机不仅占内存大而且耗电也挺多的，突然想起来有个Linux子系统。于是就决定放弃vbox，试试系统自带的。\n安装首先在windows功能中启动”适用于Linux的windows子系统“\n\n然后在Microsoft store里搜索ubuntu\n\n在前三个里选一个下载(我选的是18.04的)，下载完后启动并根据提示设置用户名和密码，最后结果如下图\n\n最后安装编译环境，由于目前只用C和C++,所以我只安装了gcc和g++\nsudo apt-get install build-essential\n\n使用经过上面的步骤安装成功后，打开命令行，打开你要编译的文件的文件夹下，输入bash，启动子系统。下来的操作就和Linux中一样了。\nLinux子系统的位置以我的系统为例，WSL的root目录对应windows的：C:\\Users\\name\\AppData\\Local\\Packages\\CanonicalGroupLimited.Ubuntu18.04onWindows_79rhkp1fndgsc\\LocalState\\rootfs但实际上微软为我们提供了一个默认的变量可以直接指向WSL的目录，你可以在运行(win+R)或资源管理器的路径里直接输入\\\\wsl$进入Ubuntu的目录\n\n以上就是Linux子系统的简单使用，如果有新的发现将会继续更新。同时欢迎留言分享！ヾ(•ω•`)o\nWSL安装软件报错/sbin/ldconfig.real: /usr/lib/wsl/lib/libcuda.so.1 is not a symbolic link解决cd /usr/lib/wslsudo mkdir lib2sudo ln -s lib/* lib2\n更改wsl配置文件sudo vim /etc/ld.so.conf.d/ld.wsl.conf将 /usr/lib/wsl/lib 改为 /usr/lib/wsl/lib2测试修改是否生效sudo ldconfig\n永久修改sudo cat &gt;&gt; /etc/wsl.conf &lt;&lt; EOF[automount]ldconfig = fasleEOF\n","tags":["Windows","Linux"]},{"title":"NOTE|网络程序设计","url":"/2019/06/14/%E7%BD%91%E7%BB%9C%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/","content":"网络程序设计简单的总结ψ(｀∇´)ψ\nLinux 编程基础C语言编译gcc hello.c –o hello \nLinux常用网络调试命令查看网络配置（网卡）ifconfig查看所有网络连接状态nestat – a查看TCP协议网络连接状态netstat –t查看网络连接所属进程PIDnetstat -p检查网络是否可达ping 127.0.0.1 \nLinux操作基础ls 显示当前目录中的内容 ls －l\ncd 切换目录cd /mnt/usbcd ..\nmkdir 创建目录mkdir workrmdir 删除目录rmdir work\ncp 复制文件cp prog1.c prog2.ccp prog1.c /mnt/usb\nrm 删除文件或目录rm prog1.crm *.*\nmv 移动或改变文件名称mv prog1.c ..mv pro1.c prog2.c\nmore命令ls –l|more 显示画面暂停more prog1.c 显示文本文件内容pwd 显示当前所在目录\n基本socket函数必须的头文件#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;netinet/in.h&gt;#include &lt;errno.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;\n创建网络端点int sock;if((sock=socket(AF_INET,SOCK_STREAM,0))&lt;0)    exit(1);\n\nint socket (int family, int type, int protocol)功能：创建socket描述符参数：（P34表2－1描述了可能的参数值）family（协议簇）：AF_INET、AF_UNIXtype（类型）：SOCK_STREAM、SOCK_DGRAM、SOCK_RAWprotocol（协议）：默认为0返回值：&gt;0－socket描述符， -1－失败， 系统全局变量errno为错误代码\n设置地址struct sockaddr_in addr;bzero(&amp;srvaddr,sizeof(srvaddr));addr.sin_family=AF_INET;addr.sin_port=htons(1234);if(inet_aton(&quot;127.0.0.1&quot;,srvaddr.sin_addr.s_addr)==-1)&#123;\tprintf(&quot;addr convert error\\n&quot;);\texit(1);\t&#125;\nTCP/IP协议的socket地址常用地址形式（字符串）：“127.0.0.1”地址转换函数:inet_aton(const char *cp,struct in_addr *inp);char* inet_ntoa(struct in_addr in);\n\n绑定服务器地址和端口if( bind(sockfd,(struct sockaddr *)&amp;addr,sizeof(struct sockaddr))==-1)&#123;\t\t\tprintf(&quot;bind error\\n&quot;);\t\t\texit(1);\t&#125;\n\nint bind(int sockfd,struct sockaddr *myaddr,int addrlen);功能：绑定本地地址和端口参数：sockfd－socket描述符myaddr－自己的地址addrlen－地址结构长度返回值：0－成功，-1－失败，errno为错误代码 \n\n监听端口if( listen(sockfd,BACKLOG) ==-1)&#123;\t\tprintf(&quot;listen error\\n&quot;);\t\texit(1);\t&#125;\n\nint listen(int sockfd,int backlog)功能：监听本地地址和端口参数：sockfd－已绑定的socket描述符backlog－以完成连接，等待接受的队列长度返回值0－成功，-1－失败，errno为错误代码\n\n接受客户端连接int sin_size=sizeof(struct sockaddr_in);\tint new_fd= accept(sockfd,(struct sockaddr *)&amp;clientaddr,&amp;sin_size);if(( new_fd==-1)&#123;\t\t\tprintf(&quot;accept errot\\n&quot;);\t\tcontinue;\t&#125;\n\nint accept(int sockfd,struct sockaddr *clientaddr,int addrlen);功能：接受连接参数：sockfd－socket描述符clientaddr－客户端地址addrlen－地址结构长度返回值:0－成功，返回新的socket描述符标识已接受的连接-1－失败，errno为错误代码\n\n接收数据\nint read(int fd,char *buf,int len);功能：从socket读取数据参数：fd－socket描述符buf－接收数据缓冲区len－要读取数据大小返回值≥0－成功，-1－失败，errno为错误代码\n\n发送数据\nint write(int fd,char *buf,int len);功能：从socket读取数据参数：fd－socket描述符buf－发送数据缓冲区len－要发送数据大小返回值≥0－成功，-1－失败，errno为错误代码\n\n关闭socket\nint close(int sockfd)功能：关闭socket参数：sockfd－socket描述符返回值0－成功，-1－失败，errno为错误代码说明调用close只是将对sockfd的引用减1，直到对sockfd的引用为0时才清除sockfd ，TCP协议将继续使用sockfd，直到所有数据发送完成 \n\n连接服务器if( connect(sockfd,(struct sockaddr *)&amp;srvaddr,sizeof(struct sockaddr) )==-1)&#123;\tprintf(&quot;connect error\\n&quot;);\texit(1);\t&#125;\n\nint connect(int sockfd,struct sockaddr *servaddr,int addrlen)功能：连接服务器参数：sockfd－socket描述符servaddr－服务器地址addrlen－地址结构长度返回值：0－成功，-1－失败，errno为错误代码\n\n高级socket函数域名访问struct hostent *he=gethostbyname(“www.sina.com.cn”);if(he!=NULL)&#123;\tprintf(&quot;h_name:%s\\n&quot;,he-&gt;h_name);\tprintf(&quot;h_length:%d\\n&quot;,he-&gt;h_length);\tprintf(&quot;h_addrtype:%d&quot;,he-&gt;h_addrtype;\tfor(i=0;he-&gt;h_aliases[i] !=NULL;i++)\t\tprintf(&quot;h_aliases%d:%s\\n&quot;,i+1,he-&gt;h_aliases[i]); \t//列出所有地址\tfor(i=0;he-&gt;h_addr_list[i]!=NULL;i++)&#123;\t\tstruct in_addr *addr;\t\taddr=(struct in_addr *)he-&gt;h_addr_list[i];\t\tprintf(&quot;ip%d:%s\\n&quot;,(i+1),inet_ntoa(*addr));\t&#125;&#125;else\tprintf(&quot;gethostbyname error:%s\\n&quot;,hstrerror(h_errno));\n\n域名到IP的转换函数struct hostent gethostbyname(const char name)功能：查询域名对应的IPstruct hostent&#123;\tchar\t h_name;\t/*主机正式名称*/\tchar\t**h_aliases;\t/*别名列表，以NULL结束*/\tint \th_addrtype;\t/*主机地址类型：AF_INET*/\tint \th_length;\t/*主机地址长度：4字节32位*/\tchar \t**h_addr_list;\t/*主机网络地址列表，以NULL结束*/&#125;#define \th_addr \th_addr_list[0]; //主机的第一个网络地址\nrecv和sendint recv(int sockfd,void* buf,int len, int flags);int send(int sockfd,void* buf,int len,int flags);\n功能：通过参数控制读写数据参数：sockfd－socket描述符buf－发送或接收数据缓冲区len－发送或接收数据长度flags－发送或接收数据的控制参数返回值：≥0－成功，-1失败\n\n控制参数说明\n\nflags=0，相当于read和write函数flags=MSG_DONTROUTE，发送数据不查找路由表，适用于局域网，或同一网段flags=MSG_OOB，发送和接收带外数据flags=MSG_PEEK，接收数据时不从缓冲区移走数据，其他进程调用read或recv仍然可以读到数据flags=MSG_WAITALL，数据量不够时，读操作等待，不返回，但在收到、文件结束符、信号以及出错时，仍然会结束。\n高级socket函数\n多路复用多路复用函数selectint select(int maxfd,fd_set rdset,fd_set wrest,fd_set exset,struct timeval timeout);功能：检查多个文件描述符（socket描述符）是否就绪，当某一个描述符就绪（可读、可写或发生异常）时函数返回。可以实现输入输出多路复用返回值：有描述符就绪则返回就绪的描述符个数；超时时间内没有描述符就绪返回0；执行失败返回-1。\n\n参数：\n\nmaxfd－需要测试的描述符的最大值，实际测试的描述符从0－maxfd-1rdset－需要测试是否可读的描述符集合（包括处于listen状态的socket接收到连接请求）wrset－需要测试是否可写的描述符集合（包括以非阻塞方式调用connect是否成功）exset－需要测试是否异常的描述符集合（包括接收带外数据的socket有带外数据到达）timeout－指定测试超时的时间 \n\ntimeout参数\n\ntimeval结构timeout=NULL，select将永远阻塞直到有一个描述符就绪，或者出现错误（接收到信号）。timeout&gt;0，在timeout时间内如果有描述符就绪则返回，否则在timeout时间后返回0；如果将3个描述符集合都设定为NULL则select相当于sleep函数，只是时间可以精确到毫秒timeout=0，select检查完描述符集合后立即返回 \n\n设置描述符集合\n\nFD_ZERO(fd_set fdset)－清空描述符集合FD_SET(int fd,fd_set fdset)－将一个描述符添加到描述符集合FD_CLR(int fd,fd_set fdset)－将一个描述符从描述符集合中清除FD_ISSET(int fd,fd_set fdset)－检测一个描述符是否就绪在设置描述符集合前应该先调用FD_ZERO将集合清空，每次调用select函数前应该重新设置这3个集合三个集合中的描述符可以交叉 \n\nsocket选项设置/获取socket选项函数int getsockopt(int sockfd,int level,int optname,void *optval,sock_len *optlen);int setsockopt(int sockfd,int level,int optname,void *optval,sock_len optlen);\n\n功能：获取或设置socket选项返回值： 0－成功，－1失败\n\n参数：\n\nsockfd－socket描述符level－选项级别SOL_SOCKET —通用socket选项IPPROTO_IP—IP选项IPPROTO_TCP—TCP选项optname—选项名称optval—选项值optlen—选项值的长度/存放选项值长度的指针  \n\n通用socket选项\n\nSO_KEEPALIVE设置该选项后，2小时内没有数据交换时，TCP协议将自动发送探测数据包，检查网络连接SO_RCVBUF和SO_SNDBUF设置发送和接收数据缓冲区的大小（在连接建立以前设置）SO_RCVTIMEO和SO_SNDTIMEO设置发送和接收超时，当指定时间内数据没有成功接收或发送，发送和接收函数将返回。SO_REUSEADDR快速重启服务器程序启动服务器程序的多个实例（绑定本地IP地址的多个别名）\n\n阻塞/非阻塞模式int fcntl(int fd,int cmd,…)\n\n功能：设置socket为阻塞/非阻塞模式设置/获取socket的所有者参数：fd－文件（socket）描述符cmd－执行的操作其他参数－根据cmd选择适当参数返回值：≥0－成功，-1－失败\n\n\n\n\n\n操作类型\n参数\n返回值\n说明\n\n\n\n\nF_GETFL\n0\n描述符标志\n获得描述符标志\n\n\nF_SETFL\nO_NONBLOCK\n成功0，否则-1\n设置socket为非阻塞方式\n\n\nF_GETOWN\nint *\n成功0，否则-1\n获得socket的所有者\n\n\nF_SETOWN\nint *\n成功0，否则-1\n设置socket的所有者\n\n\n\n\n非阻塞方式fcntl(socket_fd,F_SETFL,fcntl(socket_fd,F_GETFL,0)|O_NONBLOCK);阻塞方式fcntl(socket_fd,F_SETFL,fcntl(socket_fd,F_GETFL,0)&amp;^O_NONBLOCK);\n控制输入输出int ioctl(int fd,int req,…);\n\n功能：控制输入输出参数：fd－文件（socket）描述符req－执行的操作类型第三个参数－总是指针类型，存储操作返回的数据或操作所需的数据返回值：0－成功，-1－失败\n\n\n\n\n\n操作类型\n参数类型\n说明\n\n\n\n\nSIOCATMARK\nint*\n是否到达带外标志\n\n\nFIOASYNC\nint*\n异步输入/输出标志\n\n\nFIONREAD\nint*\n缓冲区中有多少字节数据可读\n\n\n\n\nUDP Socket编程#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;string.h&gt;#include &lt;arpa/inet.h&gt;typedef struct sockaddr* saddrp;int main(int argc, char const *argv[])&#123;     //创建socket     int sockfd = socket(AF_INET,SOCK_DGRAM,0);     if (0 &gt; sockfd)     &#123;          perror(&quot;sockfd&quot;);          return -1;     &#125;     //准备地址     struct sockaddr_in addr = &#123;&#125;;     addr.sin_family = AF_INET;//ipv4     addr.sin_port = htons(5577);//端口号     addr.sin_addr.s_addr = inet_addr(&quot;192.168.2.177&quot;);//我的ip地址     //绑定     int ret = bind(sockfd,(saddrp)&amp;addr,sizeof(addr));     if (0 &gt; ret)     &#123;          perror(&quot;bind&quot;);          return -1;     &#125;     struct sockaddr_in src_addr =&#123;&#125;;     socklen_t addr_len = sizeof(struct sockaddr_in);     while(1)     &#123;          char buf[255] = &#123;&#125;;          //接收数据和来源的ip地址          recvfrom(sockfd,buf,sizeof(buf),0,(saddrp)&amp;src_addr,&amp;addr_len);          printf(&quot;Recv:%s\\n&quot;,buf);          if (0 == strcmp(buf,&quot;q&quot;)) break;          //发送数据给目标地址          printf(&quot;Please input the return value:&quot;);          gets(buf);          sendto(sockfd,buf,strlen(buf)+1,0,(saddrp)&amp;src_addr,addr_len);          if (0 == strcmp(buf,&quot;q&quot;)) break;     &#125;       //关闭socket对象     close(sockfd);     return 0;&#125;\n原始socket编程创建原始socketint socket (int family, int type, int protocol)\n\n参数：family－AF_INETtype－SOCK_RAWprotocolIPPROTO_ICMP－ICMP数据包IPPROTO_IGMP－IGMP数据包IPPROTO_IP－IP数据包void send_icmp(int sockfd,sockaddr_in send_addr)&#123;     static short int seq=0;     char buf[8+8];     struct icmphdr *icmp=(struct icmphdr *)buf;     icmp-&gt;type=ICMP_ECHO;     icmp-&gt;code=0;     icmp-&gt;checksum=CHECK_SUM;     icmp-&gt;un.echo.id=getpid();     icmp-&gt;un.echo.sequence=seq++;     int len=send(sockfd,buf,buflen);&#125;void recv_icmp(int sockfd,sockaddr_in send_addr)&#123;     char buf[256];     struct icmphdr *icmp;     struct ip *ip;     int ipheadlen;     int icmplen;     int n=recvfrom(sockfd,buf,sizeof(buf),0,NULL,NULL);     if(n&lt;=0)&#123;          cout&lt;&lt;&quot;recv error&quot;&lt;&lt;endl;          return;     &#125;     ip=(struct ip *)buf;\t     ipheadlen=ip-&gt;ip_hl&lt;&lt;2;     icmplen=n-ipheadlen;     icmp=(struct icmphdr *)(buf+ipheadlen);     if(icmp-&gt;type==ICMP_ECHOREPLY)          cout&lt;&lt;&quot;recv from &quot;&lt;&lt;inet_ntoa(send_addr.sin_addr);&#125;\n\n","tags":["Socket","Linux","NOTE","C"]},{"title":"JAVA|RPC/RMI-书籍信息管理系统","url":"/2019/06/10/%E8%BF%9C%E7%A8%8B%E7%B1%BB%E8%B0%83%E7%94%A8/","content":"使用RPC/RMI实现书籍信息管理系统及Web Service改写\n基本原理RPC远程过程调用(Remote Procedure Call): 使应用程序可以像调用本地节点上的过程(子程序) 那样去调用一个远程节点上的子程序。\n\n对于被调用者而言也无法区分调用者来自于本地还是远程\nRPC将面向过程的通用编程模型扩展到了分布式环境。\n实现了跨进程、跨语言、跨网络、跨平台的过程调用\n强化了面向接口编程的编程风格\n实现RPC必须要有RPC中间件的支持。\n\nRPC一般采用同步调用方式\nRMI远程方法调用(Remote Method Invocation): 将面向对象的编程模型扩展到了分布式环境。\n\nRMI使应用程序可以像调用本机上对象的方法一样调用远程主机中对象的方法。\n利用RMI调用一个远程对象方法时，参数可以是一个本地对象，也可以是另外一个远程对象(可能存在于第三个节点)。\n在整个系统范围内支持垃圾回收。\n实现RMI也必须要有中间件的支持。\n\n中间件实现原理\nRPC/RMI中间件在调用者进程中植入stub模块，stub模块作为远程过程的本地代理，并且暴露与远程过程相同的接口。\nRPC/RMI中间件在被调用者进程中植入skeleton模块，skeleton作为调用者在远程主机中的代理。\nstub模块与skeleton模块利用Socket进行通信。\nskeleton模块相当于Client-Server通信模式中的服务器端，要先于客户端运行，并且在某个Socket端口进行监听。\n\n作用\n定义并利用Socket服务接口实现了一套调用者和被调用者之间的通信协议。(远程过程调用协议)。例如Java RMI的Java Remote Method Protocol (JRMP)\n实现了过程参数的序列化、反序列化；过程运算结果的序列化、反序列化。\n通信过程中的错误处理\n过程服务进程(或远程对象)的集中注册与发现（目录服务）\n远程对象的生命周期管理\n在服务端支持并发访问。（多采用多线程技术）\n\n常用的RPC/RMI中间件有很多种，本文章使用的是Java RMI，其他的欢迎尝试和分享。\n\n常用的RPC/RMI中间件：Java RMI：Java的自娱自乐Microsoft .NET Remoting：.Net的自娱自乐CORBA：重量级分布式对象中间件，跨语言gRPC：Google的RPC中间件，高效，开源，跨语言Thrift：Facebook、Apache的RPC中间件，高效，开源，跨语言Hessian：基于HTTP+二进制，跨语言Dubbo：淘宝开源中间件，JavaMotan：新浪开源中间件，JavaWebService：基于HTTP + SOAP/XML/JSONGoogle Protocol Buffers：一种对象序列化标准和开发库\n\n例子实现一个书籍信息管理系统，具体要求：\n\n客户端实现用户交互，服务器端实现书籍信息存储和管理。\n服务器端至少暴露如下接口：\n\n\nbool add(Book b) 添加一个书籍对象。\nBook queryByID(int bookID) 查询指定ID号的书籍对象。\nBookList queryByName(String name) 按书名查询符合条件的书籍对象列表，支持模糊查询。\nbool delete(int bookID) 删除指定ID号的书籍对象\n\nRPC/RMI实现创建book类，包含图书ID和名称，构建getid()和getname()方法，能够在类外访问。并继承序列化接口Serializable。Book.javapackage RMI;import java.io.Serializable;public class Book implements Serializable &#123;\tprivate int id;\tprivate String name=null;\t\tpublic Book(int id,String name) &#123;\t\tthis.id=id;\t\tthis.name=name;\t&#125;\t\tpublic int getID() &#123;\t\treturn id;\t&#125;\tpublic String getname() &#123;\t\treturn name;\t&#125;&#125;新建一个txt文件，使用IO的方式读取书籍信息book.txt1001 分布式计算1002 大数据1003 机器学习1004 计算机系统1005 计算机组成1006 Java1007 数据结构1008 计算机网络1009 虚拟现实声明接口，继承于 Remote类，声明要实现的方法。ComputingService.javaimport java.rmi.Remote;import java.rmi.RemoteException;import java.util.ArrayList;public interface ComputingService extends Remote &#123;\t\tboolean add(Book b) throws RemoteException;\tBook queryByID(int bookID) throws RemoteException;\tArrayList&lt;Book&gt; BookList(String name) throws RemoteException;\tboolean delete(int bookID) throws RemoteException;\tArrayList&lt;Book&gt; showAll() throws RemoteException;\tvoid end() throws RemoteException;&#125;实现接口中实现的方法。其中BookFlies类用于读取和保存文件ComputingServiceImpl.javaimport java.rmi.RemoteException;import java.rmi.server.UnicastRemoteObject;import java.util.ArrayList;import java.util.regex.Matcher;import java.util.regex.Pattern;import java.io.*;public class ComputingServiceImpl extends UnicastRemoteObject implements ComputingService &#123;\t\tBookFlies bookFlies=new BookFlies();\tArrayList&lt;Book&gt; booklist = new ArrayList&lt;Book&gt;();\t    ComputingServiceImpl() throws RemoteException &#123;    \tsuper();\t\tbookFlies.load(booklist);\t&#125;        public boolean add(Book b) throws RemoteException &#123;    \tif(queryByID(b.getID())==null) &#123;    \t\tbooklist.add(b);    \t\treturn true;    \t&#125;\t\treturn false;    &#125;    \tpublic Book queryByID(int bookID) throws RemoteException &#123;\t\tfor(Book b:booklist) &#123;\t\t\tif(b.getID()==bookID) &#123;\t\t\t\treturn b;\t\t\t&#125;\t\t&#125;\t\treturn null;\t&#125;\t\tpublic ArrayList&lt;Book&gt; BookList(String name) throws RemoteException &#123;\t\tArrayList&lt;Book&gt; books=new ArrayList&lt;Book&gt;();\t\tPattern pattern = Pattern.compile(name);\t\tfor(Book b:booklist) &#123;\t\t\tMatcher matcher = pattern.matcher(b.getname());\t\t\tif(matcher.find())&#123;\t\t\t\tbooks.add(b);\t\t\t&#125;\t\t&#125;\t\treturn books;\t&#125;\t\tpublic boolean delete(int bookID)  throws RemoteException &#123;\t\tfor(Book b:booklist) &#123;\t\t\tif(b.getID()==bookID) &#123;\t\t\t\tbooklist.remove(b);\t\t\t\treturn true;\t\t\t&#125;\t\t&#125;\t\treturn false;\t&#125;\t\tpublic ArrayList&lt;Book&gt; showAll() throws RemoteException &#123;\t\treturn booklist;\t&#125;\tpublic void end() throws RemoteException &#123;\t\tbookFlies.save(booklist);\t&#125;&#125;class BookFlies&#123;\tpublic void load(ArrayList&lt;Book&gt; booklist)//读取文件\t&#123;\t\ttry &#123;\t\t\tString filename = &quot;book.txt&quot;;\t\t\tFile file = new File(filename);\t\t\tBufferedReader reader = new BufferedReader(new FileReader(file));\t\t\tString temp;\t\t\twhile((temp = reader.readLine()) != null)\t\t\t&#123;\t\t\t\tString[] a=temp.split(&quot; &quot;);\t\t\t\tString idstr = a[0];\t\t\t\tString name = a[1];\t\t\t\tint id =Integer.parseInt(idstr);\t\t\t\tBook book = new Book(id,name);\t\t\t\tbooklist.add(book);\t\t\t&#125;\t\t\treader.close();\t\t&#125; catch (FileNotFoundException e) &#123;\t\t\t// TODO Auto-generated catch block\t\t\te.printStackTrace();\t\t&#125; catch (NumberFormatException e) &#123;\t\t\t// TODO Auto-generated catch block\t\t\te.printStackTrace();\t\t&#125; catch (IOException e) &#123;\t\t\t// TODO Auto-generated catch block\t\t\te.printStackTrace();\t\t&#125;\t&#125;\t\tpublic void save(ArrayList&lt;Book&gt; booklist)//写入文件\t&#123;\t\tString fileName = &quot;book.txt&quot;;\t\tString allbook=&quot;&quot;;\t\tfor(int i = 0; i &lt; booklist.size()-1; i++)\t\t&#123;\t\t\tBook book = booklist.get(i);\t\t\tString temp = book.getID() + &quot; &quot; + book.getname()+&quot;\\n&quot;;\t\t\tallbook += temp;\t\t&#125;\t\tBook book=booklist.get(booklist.size()-1);\t\tallbook += book.getID()+ &quot; &quot; + book.getname();\t\ttry &#123;\t\t\tFileWriter fileWriter = new FileWriter(new File(fileName));\t\t\tfileWriter.write(allbook);\t\t\tfileWriter.close();\t\t&#125; catch (IOException e) &#123;\t\t\t// TODO Auto-generated catch block\t\t\te.printStackTrace();\t\t&#125;\t\t\t&#125;&#125;创建服务端。在端口8196声明了一个注册表，用Naming.bind将地址信息和类ComputingServiceImpl的一个对象computingServan绑定在一起并放入注册表。RMIServer.javaimport java.net.MalformedURLException;import java.rmi.AlreadyBoundException;import java.rmi.Naming;import java.rmi.RemoteException;import java.rmi.registry.LocateRegistry;public class RMIServer &#123;    public static void main(String[] args) throws RemoteException, AlreadyBoundException, MalformedURLException &#123;    \tLocateRegistry.createRegistry(8196);        ComputingService computingServant = new ComputingServiceImpl();        Naming.bind(&quot;rmi://192.168.43.204:8196/ComputingService&quot;,computingServant);        System.out.println(&quot;ComputingService is online.&quot;);    &#125;&#125;创建客户端。通过在注册表中查找名字，获得一个远程对象。设置提示信息，根据用户输入，调用所需方法。(有兴趣的话可以加一个UI)RMIClient.javaimport java.net.MalformedURLException;import java.rmi.Naming;import java.rmi.NotBoundException;import java.rmi.RemoteException;import java.util.ArrayList;import java.util.Scanner;public class RMIClient &#123;\tstatic Scanner s = new Scanner(System.in);    public static void main(String[] args) throws RemoteException, NotBoundException, MalformedURLException &#123;                ComputingService c =(ComputingService)Naming.lookup(&quot;rmi://localhost:8196/ComputingService&quot;);        int chose;        int bookID;        String name;        Book b=null;        System.out.println(&quot;欢迎使用!&quot;);        printMenu();        while((chose=s.nextInt())!=6) &#123;        \tSystem.out.println(&quot;-------------------------&quot;);        \tswitch (chose) &#123;\t\t\tcase 1:\t\t\t\tSystem.out.println(&quot;请输入图书ID：&quot;);\t\t\t\tbookID=s.nextInt();\t\t\t\tSystem.out.println(&quot;请输入图书名称：&quot;);\t\t\t\tname=s.next();\t\t\t\tb=new Book(bookID, name);\t\t\t\tif(c.add(b)) &#123;\t\t\t\t\tSystem.out.println(&quot;增加成功!&quot;);\t\t\t\t\tSystem.out.println(&quot;ID   名称&quot;);\t\t\t\t\tfor(Book book:c.showAll()) &#123;\t\t\t\t\t\tSystem.out.println(book.getID() + &quot; &quot; + book.getname());\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t\telse &#123;\t\t\t\t\tSystem.out.println(&quot;增加失败,ID重复!&quot;);\t\t\t\t&#125;\t\t\t\tbreak;\t\t\tcase 2:\t\t\t\tSystem.out.println(&quot;请输入图书ID:&quot;);\t\t\t\tbookID=s.nextInt();\t\t\t\tb=c.queryByID(bookID);\t\t\t\tif(b==null) &#123;\t\t\t\t\tSystem.out.println(&quot;图书信息不存在&quot;);\t\t\t\t&#125;\t\t\t\telse &#123;\t\t\t\t\tSystem.out.println(&quot;ID   名称&quot;);\t\t\t\t\tSystem.out.println(b.getID() + &quot; &quot; + b.getname());\t\t\t\t\tSystem.out.println(&quot;确认删除?&lt;Y/n&gt;&quot;);\t\t\t\t\tString order=s.next();\t\t\t\t\tif(order.equalsIgnoreCase(&quot;Y&quot;)) &#123;\t\t\t\t\t\tif(c.delete(bookID)) &#123;\t\t\t\t\t\t\tSystem.out.println(&quot;删除成功!&quot;);\t\t\t\t\t\t&#125;\t\t\t\t\t\telse&#123;\t\t\t\t\t\t\tSystem.out.println(&quot;删除失败!&quot;);\t\t\t\t\t\t&#125;\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t\tbreak;\t\t\tcase 3:\t\t\t\tSystem.out.println(&quot;请输入图书ID:&quot;);\t\t\t\tbookID=s.nextInt();\t\t\t\tb=c.queryByID(bookID);\t\t\t\tif(b==null) &#123;\t\t\t\t\tSystem.out.println(&quot;查询ID不存在&quot;);\t\t\t\t&#125;\t\t\t\telse &#123;\t\t\t\t\tSystem.out.println(&quot;ID   名称&quot;);\t\t\t\t\tSystem.out.println(b.getID() + &quot; &quot; + b.getname());\t\t\t\t&#125;\t\t\t\tbreak;\t\t\tcase 4:\t\t\t\tSystem.out.println(&quot;请输入图书名称：&quot;);\t\t\t\tname=s.next();\t\t\t\tArrayList&lt;Book&gt; books=c.BookList(name);\t\t\t\tif(books.size()==0) &#123;\t\t\t\t\tSystem.out.println(&quot;查询图书不存在&quot;);\t\t\t\t&#125;\t\t\t\telse &#123;\t\t\t\t\tSystem.out.println(&quot;ID   名称&quot;);\t\t\t\t\tfor(Book book:books) &#123;\t\t\t\t\t\tSystem.out.println(book.getID() + &quot; &quot; + book.getname());\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t\tbreak;\t\t\tcase 5:\t\t\t\tSystem.out.println(&quot;ID   名称&quot;);\t\t\t\tfor(Book book:c.showAll()) &#123;\t\t\t\t\tSystem.out.println(book.getID() + &quot; &quot; + book.getname());\t\t\t\t&#125;\t\t\t\tbreak;\t\t\tdefault:\t\t\t\tSystem.out.println(&quot;输入错误!!!&quot;);\t\t\t\tbreak;\t\t\t&#125;        \tSystem.out.println(&quot;-------------------------&quot;);        \tprintMenu();        &#125;\t\tSystem.out.println(&quot;感谢使用!&quot;);        c.end();    &#125;    static void printMenu()&#123;\t\tSystem.out.println(&quot;增加图书...1&quot;);\t\tSystem.out.println(&quot;删除图书...2&quot;);\t\tSystem.out.println(&quot;书号查询...3&quot;);\t\tSystem.out.println(&quot;书名查询...4&quot;);\t\tSystem.out.println(&quot;查看目录...5&quot;);\t\tSystem.out.println(&quot;退出系统...6&quot;);\t\tSystem.out.print(&quot;请输入选项：&quot;);\t&#125;&#125;\n运行结果由于我的Eclipse出了问题，所以使用的是命令行编译运行的。javac *.javarmic ComputingServiceImpljava RMIServerjava RMIClient\nWeb Service改写\n前面几篇博客简单讲了Web Service的使用，不知道各位有没有发现Web的实现过程以及结果都和RPC/RMI的十分相似。那么能不能把我们写的方法发布出去，从而实现远程调用。让我们试一试吧。\n\n改写主要变动在Book.java,Pulisher.java和Client.java。Book需要调用javax.xml.bind.annotation这个包转化为xml; Pulisher中使用Websevice的方法发布接口；Client中请求并调用方法。\n先创建两个个文件夹，分别放服务端和客户端代码\n服务端在wsserver文件夹里创建book类Book.javapackage wsserver;import java.io.Serializable;import javax.xml.bind.annotation.XmlRootElement;import javax.xml.bind.annotation.XmlAccessType;import javax.xml.bind.annotation.XmlAccessorType;import javax.xml.bind.annotation.XmlElement;import javax.xml.bind.annotation.XmlType;@XmlRootElement(name=&quot;book&quot;, namespace=&quot;http://localhost:9999/ws/books&quot;)@XmlAccessorType(XmlAccessType.FIELD)@XmlType(name=&quot;book&quot;, namespace=&quot;http://localhost:9999/ws/books&quot;)public class Book implements Serializable &#123;\tprivate static final long serialVersionUID = 1L;\t@XmlElement(name = &quot;id&quot;, namespace = &quot;&quot;)\tprivate int id;\t@XmlElement(name = &quot;name&quot;, namespace = &quot;&quot;)\tprivate String name;\t\tpublic void set(int id,String name) &#123;\t\tthis.id=id;\t\tthis.name=name;\t&#125;\t\tpublic int getID() &#123;\t\treturn this.id;\t&#125;\tpublic String getname() &#123;\t\treturn this.name;\t&#125;&#125;book.txt1001 分布式计算1002 大数据1003 机器学习1004 计算机系统1005 计算机组成1006 Java1007 数据结构1008 计算机网络1009 虚拟现实定义Web服务接口Bookstore.javapackage wsserver;import wsserver.Book;import java.util.ArrayList;import javax.jws.WebService;import javax.jws.soap.SOAPBinding;import javax.jws.soap.SOAPBinding.Style;@WebService(targetNamespace=&quot;http://localhost:9999/ws/books&quot;)@SOAPBinding(style = Style.RPC)public interface Bookstore &#123;\tpublic boolean add(Book b);\tpublic Book queryByID(int bookID);\tpublic ArrayList&lt;Book&gt; BookList(String name);\tpublic boolean delete(int bookID);\tpublic ArrayList&lt;Book&gt; showAll();\tpublic void end();&#125;定义实现接口的Web服务实现类BookstoreImpl.javapackage wsserver;import java.io.BufferedReader;import java.io.File;import java.io.FileNotFoundException;import java.io.FileReader;import java.io.FileWriter;import java.io.IOException;import java.util.ArrayList;import java.util.regex.Matcher;import java.util.regex.Pattern;import javax.jws.WebService;@WebServicepublic class BookstoreImpl implements Bookstore&#123;\tBookFlies bookFlies=new BookFlies();\tArrayList&lt;Book&gt; booklist = new ArrayList&lt;Book&gt;();\t\tBookstoreImpl()&#123;\t\tbookFlies.load(booklist);\t&#125;    @Override    public boolean add(Book b)&#123;    \tif(queryByID(b.getID())==null) &#123;    \t\tbooklist.add(b);    \t\treturn true;    \t&#125;\t\treturn false;    &#125;    @Override\tpublic Book queryByID(int bookID) &#123;\t\tfor(Book b:booklist) &#123;\t\t\tif(b.getID()==bookID) &#123;\t\t\t\treturn b;\t\t\t&#125;\t\t&#125;\t\treturn null;\t&#125;\t@Override\tpublic ArrayList&lt;Book&gt; BookList(String name)&#123;\t\tArrayList&lt;Book&gt; books=new ArrayList&lt;Book&gt;();\t\tPattern pattern = Pattern.compile(name);\t\tfor(Book b:booklist) &#123;\t\t\tMatcher matcher = pattern.matcher(b.getname());\t\t\tif(matcher.find())&#123;\t\t\t\tbooks.add(b);\t\t\t&#125;\t\t&#125;\t\treturn books;\t&#125;\t@Override\tpublic boolean delete(int bookID)&#123;\t\tfor(Book b:booklist) &#123;\t\t\tif(b.getID()==bookID) &#123;\t\t\t\tbooklist.remove(b);\t\t\t\treturn true;\t\t\t&#125;\t\t&#125;\t\treturn false;\t&#125;\t@Override\tpublic ArrayList&lt;Book&gt; showAll()&#123;\t\treturn booklist;\t&#125;\t@Override\tpublic void end()&#123;\t\tbookFlies.save(booklist);\t&#125;&#125;class BookFlies&#123;\tpublic void load(ArrayList&lt;Book&gt; booklist)//读取文件\t&#123;\t\ttry &#123;\t\t\tString filename = &quot;wsserver\\\\book.txt&quot;;\t\t\tFile file = new File(filename);\t\t\tBufferedReader reader = new BufferedReader(new FileReader(file));\t\t\tString temp;\t\t\twhile((temp = reader.readLine()) != null)\t\t\t&#123;\t\t\t\tString[] a=temp.split(&quot; &quot;);\t\t\t\tString idstr = a[0];\t\t\t\tString name = a[1];\t\t\t\tint id =Integer.parseInt(idstr);\t\t\t\tBook book = new Book();\t\t\t\tbook.set(id,name);\t\t\t\tbooklist.add(book);\t\t\t&#125;\t\t\treader.close();\t\t&#125; catch (FileNotFoundException e) &#123;\t\t\t// TODO Auto-generated catch block\t\t\te.printStackTrace();\t\t&#125; catch (NumberFormatException e) &#123;\t\t\t// TODO Auto-generated catch block\t\t\te.printStackTrace();\t\t&#125; catch (IOException e) &#123;\t\t\t// TODO Auto-generated catch block\t\t\te.printStackTrace();\t\t&#125;\t&#125;\t\tpublic void save(ArrayList&lt;Book&gt; booklist)//写入文件\t&#123;\t\tString fileName = &quot;wsserver\\\\book.txt&quot;;\t\tString allbook=&quot;&quot;;\t\tfor(int i = 0; i &lt; booklist.size()-1; i++)\t\t&#123;\t\t\tBook book = booklist.get(i);\t\t\tString temp = book.getID() + &quot; &quot; + book.getname()+&quot;\\n&quot;;\t\t\tallbook += temp;\t\t&#125;\t\tBook book=booklist.get(booklist.size()-1);\t\tallbook += book.getID()+ &quot; &quot; + book.getname();\t\ttry &#123;\t\t\tFileWriter fileWriter = new FileWriter(new File(fileName));\t\t\tfileWriter.write(allbook);\t\t\tfileWriter.close();\t\t&#125; catch (IOException e) &#123;\t\t\t// TODO Auto-generated catch block\t\t\te.printStackTrace();\t\t&#125;\t\t\t&#125;&#125;将Web服务实现类绑定到Web服务器Publisher.javapackage wsserver;import javax.xml.ws.Endpoint;public class Publisher&#123;\tpublic static void main(String[] args) &#123;\t   BookstoreImpl b = new BookstoreImpl();\t   Endpoint.publish(&quot;http://localhost:9999/ws/books&quot;, b);\t   System.out.println(&quot;Web service is online.&quot;);  &#125;&#125;\n客户端在wsclient文件夹里根据WSDL生成Web服务代理类，利用Web服务代理类调用Web服务接口中定义的具体方法。Client.javapackage wsclient;import wsproxy.*;import java.util.ArrayList;import java.util.Scanner;public class Client &#123;\tstatic Scanner s = new Scanner(System.in);\tpublic static void main(String[] args) &#123;\t\tBookstoreImplService service = new BookstoreImplService();\t\tBookstoreImpl pService = service.getBookstoreImplPort();        int chose;        int bookID;        String name;        Book b=new Book();        System.out.println(&quot;Welcome!!!&quot;);        printMenu();        while((chose=s.nextInt())!=6) &#123;        \tSystem.out.println(&quot;-------------------------&quot;);        \tswitch (chose) &#123;\t\t\tcase 1:\t\t\t\tSystem.out.println(&quot;Input book ID:&quot;);\t\t\t\tbookID=s.nextInt();\t\t\t\tSystem.out.println(&quot;Input book Name:&quot;);\t\t\t\tname=s.next();\t\t\t\tb.setId(bookID);b.setName(name);\t\t\t\tif(pService.add(b)) &#123;\t\t\t\t\tSystem.out.println(&quot;Added successfully!&quot;);\t\t\t\t\tSystem.out.println(&quot;ID   Name&quot;);\t\t\t\t\tfor(Book book:pService.showAll()) &#123;\t\t\t\t\t\tSystem.out.println(book.getId() + &quot; &quot; + book.getName());\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t\telse &#123;\t\t\t\t\tSystem.out.println(&quot;Failure, ID duplication&quot;);\t\t\t\t&#125;\t\t\t\tbreak;\t\t\tcase 2:\t\t\t\tSystem.out.println(&quot;Input book ID:&quot;);\t\t\t\tbookID=s.nextInt();\t\t\t\tb=pService.queryByID(bookID);\t\t\t\tif(b==null) &#123;\t\t\t\t\tSystem.out.println(&quot;Not exist&quot;);\t\t\t\t&#125;\t\t\t\telse &#123;\t\t\t\t\tSystem.out.println(&quot;ID   Name&quot;);\t\t\t\t\tSystem.out.println(b.getId() + &quot; &quot; + b.getName());\t\t\t\t\tSystem.out.println(&quot;Confirm?&lt;Y/n&gt;&quot;);\t\t\t\t\tString order=s.next();\t\t\t\t\tif(order.equalsIgnoreCase(&quot;Y&quot;)) &#123;\t\t\t\t\t\tif(pService.delete(bookID)) &#123;\t\t\t\t\t\t\tSystem.out.println(&quot;Successfully deleted!&quot;);\t\t\t\t\t\t&#125;\t\t\t\t\t\telse&#123;\t\t\t\t\t\t\tSystem.out.println(&quot;Failed to delete!&quot;);\t\t\t\t\t\t&#125;\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t\tbreak;\t\t\tcase 3:\t\t\t\tSystem.out.println(&quot;Input book ID:&quot;);\t\t\t\tbookID=s.nextInt();\t\t\t\tb=pService.queryByID(bookID);\t\t\t\tif(b==null) &#123;\t\t\t\t\tSystem.out.println(&quot;Not exist&quot;);\t\t\t\t&#125;\t\t\t\telse &#123;\t\t\t\t\tSystem.out.println(&quot;ID   Name&quot;);\t\t\t\t\tSystem.out.println(b.getId() + &quot; &quot; + b.getName());\t\t\t\t&#125;\t\t\t\tbreak;\t\t\tcase 4:\t\t\t\tSystem.out.println(&quot;Input book Name:&quot;);\t\t\t\tname=s.next();\t\t\t\tArrayList&lt;Book&gt; books=(ArrayList&lt;Book&gt;) pService.bookList(name);\t\t\t\tif(books.size()==0) &#123;\t\t\t\t\tSystem.out.println(&quot;Not exist&quot;);\t\t\t\t&#125;\t\t\t\telse &#123;\t\t\t\t\tSystem.out.println(&quot;ID   Name&quot;);\t\t\t\t\tfor(Book book:books) &#123;\t\t\t\t\t\tSystem.out.println(book.getId() + &quot; &quot; + book.getName());\t\t\t\t\t&#125;\t\t\t\t&#125;\t\t\t\tbreak;\t\t\tcase 5:\t\t\t\tSystem.out.println(&quot;ID   Name&quot;);\t\t\t\tfor(Book book:pService.showAll()) &#123;\t\t\t\t\tSystem.out.println(book.getId() + &quot; &quot; + book.getName());\t\t\t\t&#125;\t\t\t\tbreak;\t\t\tdefault:\t\t\t\tSystem.out.println(&quot;Error!!!&quot;);\t\t\t\tbreak;\t\t\t&#125;        \tSystem.out.println(&quot;-------------------------&quot;);        \tprintMenu();        &#125;\t\tSystem.out.println(&quot;Thanks for using!&quot;);\t\tpService.end();\t&#125;    static void printMenu()&#123;\t\tSystem.out.println(&quot;Add books ......1&quot;);\t\tSystem.out.println(&quot;Delete books ...2&quot;);\t\tSystem.out.println(&quot;Query By ID ....3&quot;);\t\tSystem.out.println(&quot;Query By Name ..4&quot;);\t\tSystem.out.println(&quot;Show All .......5&quot;);\t\tSystem.out.println(&quot;Exit ...........6&quot;);\t\tSystem.out.print(&quot;Please enter the option:&quot;);\t&#125;&#125;\n运行结果编译并启动服务商javac .\\wsserver\\*.javajava wsserver.Publisher\n浏览器打开http://localhost:9999/ws/books?wsdl看到如下界面，即wsdl文件\n使用wsimport命令，将wsdl文件生成本地代理wsimport -keep -p wsproxy http://localhost:9999/ws/books?wsdl\n编译并启动客户端javac .\\wsclient\\*.javajava wsclient.Client\n\n最后，总算圆满完成。虽然看起来并不困难，刚开始我就是这么想的，但是从头开始写真的会遇到很多想不到的问题，比如不知道Book类需要转化为xml，就查了好几天的资料。总之，学知识还需要多动手啊。\n","tags":["Java","分布式","Web","RMI"]},{"title":"Python|SIFT算法","url":"/2019/06/08/SIFT/","content":"尺度不变特征变换（Scale-invariant feature transform，SIFT），是用于图像处理领域的一种描述。\n简介SIFT算法是一种提取局部特征的算法，基于物体上的一些局部外观的兴趣点而与影像的大小和旋转无关。对于光线、噪声、微视角改变的容忍度也相当高。基于这些特性，它们是高度显著而且相对容易撷取，在母数庞大的特征数据库中，很容易辨识物体而且鲜有误认。使用SIFT特征描述对于部分物体遮蔽的侦测率也相当高，甚至只需要3个以上的SIFT物体特征就足以计算出位置与方位。在现今的电脑硬件速度下和小型的特征数据库条件下，辨识速度可接近即时运算。SIFT特征的信息量大，适合在海量数据库中快速准确匹配。匹配的过程就是对比这些特征点的过程，这个流程可以用下图表述：\n特点\nSIFT特征是图像的局部特征，其对旋转、尺度缩放、亮度变化保持不变性，对视角变化、仿射变换、噪声也保持一定程度的稳定性。 \n独特性好，信息量丰富，适用于在海量特征数据库中进行快速、准确匹配。 \n多量性，即使少数的几个物体也可以产生大量SIFT特征向量。 \n高速性，经优化的SIFT匹配算法甚至可以达到实时的要求。 \n可扩展性，可以很方便的与其他形式的特征向量进行联合。\n\n算法步骤\n检测尺度空间极值点\n精确定位极值点\n为每个关键点指定方向参数\n关键点描述子的生成\n\n应用OpenCV中带有SIFT算法。可以直接调用import cv2img= cv2.imread(&#x27;C:/Code/Picture/apple.jpg&#x27;)gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)sift=cv2.xfeatures2d.SIFT_create()keypoints,descriptor=sift.detectAndCompute(gray,None)img=cv2.drawKeypoints(image=img,outImage=img,keypoints=keypoints,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS,color=(51,163,236))cv2.imshow(&#x27;sift_keypoints&#x27;,img)cv2.waitKey(0)cv2.destroyAllWindows()\n\nOpenCV使用SIFT时报错,建议卸载后安装opencv-contrib-python,同时3.4.3.18以上的版本会出现专利问题而无法使用。安装前记得卸载原来的。pip install opencv-contrib-python==3.4.2.17\n\n\n\n参考文献Sift算子特征点提取、描述及匹配全流程解析Sift中尺度空间、高斯金字塔、差分金字塔（DOG金字塔）、图像金字塔\n\n","tags":["Python","OpenCV","SIFT"]},{"title":"JAVA|MapReduce-自连接算法","url":"/2019/06/04/hadoop2/","content":"环境: Hadoop 3.0.0+Win10实现功能：找出所有具有grandchild-grandparent关系的人名组。输入文件的每一行为具有child-parent关系的一对人名Input2.txt(提取码:2vd7)首先启动hadoop（记得以管理员模式启动），新建一个input2文件夹，把输入文件上传到文件夹中hadoop fs -mkdir /input2hadoop fs -put input2.txt /input2按照上一个博客里，启动setcp。准备工作完成。\n设计思路数据量很大，我们先从一个小样本开始a,b #a是b的儿子b,c #b是c的儿子很明显a是c的孙子，最后输出的肯定就是a,c 爷爷就是爸爸的爸爸，如何识别出谁是子女，谁是父母呢？很容易想到加标签。在父母前加个“0”，在子女前加个“1”，结果如下：#&lt;key,value&gt;&lt;a,0_b&gt;&lt;b,1_a&gt;&lt;b,0_c&gt;&lt;c,1_b&gt;在同样的key中，前缀为0的就是前缀为1的grandparent\n代码import java.io.IOException;import java.util.*;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.Mapper;import org.apache.hadoop.mapreduce.Reducer;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;import org.apache.hadoop.util.GenericOptionsParser;public class Grand &#123;\tpublic static class GrandMap extends Mapper&lt;Object, Text, Text, Text&gt; &#123;\t\tpublic void map(Object key, Text value, Context context) throws IOException, InterruptedException &#123;\t\t\tString[] array = value.toString().split(&quot;,&quot;);            context.write(new Text(array[0]),new Text(&quot;0_&quot;+array[1]));            context.write(new Text(array[1]),new Text(&quot;1_&quot;+array[0]));\t\t&#125;\t&#125;\tpublic static class GrandReducer extends Reducer&lt;Text,Text,Text,Text&gt; &#123;\t\tpublic void reduce(Text key, Iterable&lt;Text&gt; values, Context context) throws IOException, InterruptedException &#123;\t\t\tIterator&lt;Text&gt; iterator = values.iterator();\t\t\tArrayList&lt;String&gt; grandChildList = new ArrayList&lt;String&gt;();            ArrayList&lt;String&gt; grandParentList = new ArrayList&lt;String&gt;();            while (iterator.hasNext())&#123;                String[] splited = iterator.next().toString().split(&quot;_&quot;);                if (splited[0].equals(&quot;1&quot;))&#123;                    grandChildList.add(splited[1]);                &#125;else &#123;                    grandParentList.add(splited[1]);                &#125;            &#125;            if (grandChildList.size() &gt;0 &amp;&amp; grandParentList.size()&gt;0)&#123;                for(String grandChild:grandChildList)&#123;                    for (String grandParent:grandParentList)&#123;                        context.write(new Text(grandChild),new Text(grandParent));                    &#125;                &#125;            &#125;\t\t&#125;\t&#125;\tpublic static void main(String[] args) throws Exception &#123;\t\tConfiguration conf = new Configuration();\t\tString[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();\t\tif (otherArgs.length &lt; 2) &#123;\t\t  System.err.println(&quot;Usage: Grand&lt;in&gt; [&lt;in&gt;...] &lt;out&gt;&quot;);\t\t  System.exit(2);\t\t&#125;\t\tJob job = Job.getInstance(conf, &quot;grand&quot;);\t\tjob.setJarByClass(Grand.class);\t\tjob.setMapperClass(GrandMap.class);\t\tjob.setReducerClass(GrandReducer.class);\t\tjob.setOutputKeyClass(Text.class);\t\tjob.setOutputValueClass(Text.class);\t\tfor (int i = 0; i &lt; otherArgs.length - 1; ++i) &#123;\t\t\tFileInputFormat.addInputPath(job, new Path(otherArgs[i]));\t\t&#125;\t\tFileOutputFormat.setOutputPath(job,new Path(otherArgs[otherArgs.length - 1]));\t\tSystem.exit(job.waitForCompletion(true) ? 0 : 1);\t&#125;&#125;\n编译并打包javac Grand.javajar cvf Grand.jar *.class运行并查看结果hadoop jar Grand.jar Grand /input2 /output3hadoop fs -cat /output3/part-r-00000\n","tags":["Java","分布式","Hadoop","MapReduce"]},{"title":"Python|遗传算法实现","url":"/2019/06/02/ga/","content":"遗传算法（genetic algorithm）是计算数学中用于解决最优化的搜索算法，是进化算法的一种。\n原理简述\n参照维基百科\n\n在遗传算法里，优化问题的解被称为个体，它表示为一个变量序列，叫做染色体或者基因串。染色体一般被表达为简单的字符串或数字符串，不过也有其他的依赖于特殊问题的表示方法适用，这一过程称为编码。首先，算法随机生成一定数量的个体，有时候操作者也可以干预这个随机产生过程，以提高初始种群的质量。在每一代中，都会评价每一个体，并通过计算适应度函数得到适应度数值。按照适应度排序种群个体，适应度高的在前面。这里的“高”是相对于初始的种群的低适应度而言。\n下一步是产生下一代个体并组成种群。这个过程是通过选择和繁殖完成，其中繁殖包括交配（crossover，在算法研究领域中我们称之为交叉操作）和突变（mutation）。选择则是根据新个体的适应度进行，但同时不意味着完全以适应度高低为导向，因为单纯选择适应度高的个体将可能导致算法快速收敛到局部最优解而非全局最优解，我们称之为早熟。作为折中，遗传算法依据原则：适应度越高，被选择的机会越高，而适应度低的，被选择的机会就低。初始的数据可以通过这样的选择过程组成一个相对优化的群体。之后，被选择的个体进入交配过程。一般的遗传算法都有一个交配概率（又称为交叉概率），范围一般是0.6~1，这个交配概率反映两个被选中的个体进行交配的概率。例如，交配概率为0.8，则80%的“夫妻”会生育后代。每两个个体通过交配产生两个新个体，代替原来的“老”个体，而不交配的个体则保持不变。交配父母的染色体相互交换，从而产生两个新的染色体，第一个个体前半段是父亲的染色体，后半段是母亲的，第二个个体则正好相反。不过这里的半段并不是真正的一半，这个位置叫做交配点，也是随机产生的，可以是染色体的任意位置。再下一步是突变，通过突变产生新的“子”个体。一般遗传算法都有一个固定的突变常数（又称为变异概率），通常是0.1或者更小，这代表变异发生的概率。根据这个概率，新个体的染色体随机的突变，通常就是改变染色体的一个字节（0变到1，或者1变到0）。\n经过这一系列的过程（选择、交配和突变），产生的新一代个体不同于初始的一代，并一代一代向增加整体适应度的方向发展，因为总是更常选择最好的个体产生下一代，而适应度低的个体逐渐被淘汰掉。这样的过程不断的重复：评价每个个体，计算适应度，两两交配，然后突变，产生第三代。周而复始，直到终止条件满足为止。一般终止条件有以下几种：\n计算耗费的资源限制（例如计算时间、计算占用的内存等）；\n一个个体已经满足最优值的条件，即最优值已经找到；\n适应度已经达到饱和，继续进化不会产生适应度更好的个体；\n人为干预；以及以上两种或更多种的组合。\n基本思想\n首先对问题进行编码，产生初始种群。\n然后对个体进行交叉、变异等遗传操作，产生出新的个体。\n再按照优胜劣汰的原则对个体进行选择。\n如此往复，逐代演化产生出越来越好的个体。\n\n编码将问题的解变换为位串形式编码表示的过程叫编码\n\n编码是进化计算解决问题的先决条件编码的重要性主要体现在三方面：（1） 编码决定了个体基因的排列形式，从而决定了选择、交叉及变异的方式。（2） 编码决定了搜索的困难度与复杂性。（3） 编码决定了问题的求解精度。\n\n交叉单点交叉两点交叉部分匹配交叉顺序交叉\n变异\n选择轮盘赌选择可能出现的问题两两竞争法选择锦标赛选择精英保留\n算法流程\n[初始化] 确定种群规模$N$，交叉概率$p_c$，变异概率$p_m$和终止条件。随机生成$N$个个体作为初始种群$P(0)$，设种群代数$t$=0.\n[个体评价] 计算种群$P(t)$中每个个体的适应度值.\n[种群进化]\n(选择父代) 运用选择算子从$P(t)$中选择出$N/2$对父代；\n(交叉) 对选择的$N/2$对父代，依概率$p_c$进行交叉，生成的子代个体记为集合$O_1$；\n(变异) 对集合$O_1$中的个体依概率$p_m$进行变异，生成的子代个体记为集合$O_2$；\n(选择子代) 从集合$P(t)\\cup O_1\\cup O_2$中依据选择算子选出$N$个个体组成下代种群$P(t+1)$；\n\n\n[终止检验] 如算法满足终止条件，则输出$P(t+1)$中具有最大适应度值的个体作为最优解，终止算法，否则令$t=t+1$转入步骤2\n\n算法实现\n敬请期待\n\n","tags":["Python","GA"]},{"title":"JAVA|MapReduce-计算平均成绩","url":"/2019/06/02/hadoop1/","content":"环境: Hadoop 3.0.0+Win10实现功能：1 每个同学必修课的平均成绩2 按科目统计每个班的平均成绩\n配置数据和环境变量输入文件为学生成绩信息，包含了必修课与选修课成绩：Input1.txt(提取码:xrq7)\n首先启动hadoop（记得以管理员模式启动），新建一个input1文件夹，把输入文件上传到文件夹中hadoop fs -mkdir /input1hadoop fs -put input1.txt /input1由于程序里会用到hadoop的jar包，所以要把路径配置到环境中，一种是直接在系统变量中修改classpath，但是会影响以后的编译，不推荐；第二种是新建一个.bat文件，在编译前启动就行了。查看自己hadoop里jar包的路径hadoop classpath新建一个文件夹Map,里面新建一个setcp.bat，内容如下set classpath=%classpath%;上一步查看的内容在Map文件下，启动setcp到此准备工作就做完了。\n程序构成\n具体实现问题一问题是求每个同学必修课的平均成绩，思路很简单。以同学的名字为主键，如果是必修课成绩就读取，最后计算总分数和个数，求取平均数。\n\n这里要注意一下中文编码问题，输入数据为utf-8的格式，而hadoop读取时会转为GBK，在判断必修的时候注意编码。\n\nScore.javaimport java.io.IOException;import java.util.StringTokenizer;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.DoubleWritable;import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.Mapper;import org.apache.hadoop.mapreduce.Reducer;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;import org.apache.hadoop.util.GenericOptionsParser;public class Score &#123;\tpublic static class SMap extends Mapper&lt;Object, Text, Text, DoubleWritable&gt; &#123;\t\tpublic void map(Object key, Text value, Context context) throws IOException, InterruptedException &#123;\t\t\tString[] split=value.toString().split(&quot;,&quot;);\t\t\tString Name=split[1];\t\t\tString t=split[3];\t\t\tif(t.equals(&quot;▒пля&quot;))\t\t\t&#123;\t\t\t\tDoubleWritable Score = new DoubleWritable(Integer.parseInt(split[4]));\t\t\t\tcontext.write(new Text(Name),Score);\t\t\t&#125;\t\t&#125;\t&#125;\tpublic static class SReducer extends Reducer&lt;Text,DoubleWritable,Text,DoubleWritable&gt; &#123;\t\tpublic void reduce(Text key, Iterable&lt;DoubleWritable&gt; values, Context context) throws IOException, InterruptedException &#123;\t\t\tint sum = 0;\t\t\tint count=0;\t\t\tfor (DoubleWritable val : values) &#123;\t\t\t\tsum += val.get();\t\t\t\tcount++;\t\t\t&#125;\t\t\tdouble average=sum/(double)count;\t\t\tcontext.write(key,new DoubleWritable(average));\t\t&#125;\t&#125;\tpublic static void main(String[] args) throws Exception &#123;\t\tConfiguration conf = new Configuration();\t\tString[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();\t\tif (otherArgs.length &lt; 2) &#123;\t\t  System.err.println(&quot;Usage: Score&lt;in&gt; [&lt;in&gt;...] &lt;out&gt;&quot;);\t\t  System.exit(2);\t\t&#125;\t\tJob job = Job.getInstance(conf, &quot;score&quot;);\t\tjob.setJarByClass(Score.class);\t\tjob.setMapperClass(SMap.class);\t\tjob.setReducerClass(SReducer.class);\t\tjob.setOutputKeyClass(Text.class);\t\tjob.setOutputValueClass(DoubleWritable.class);\t\tfor (int i = 0; i &lt; otherArgs.length - 1; ++i) &#123;\t\t\tFileInputFormat.addInputPath(job, new Path(otherArgs[i]));\t\t&#125;\t\tFileOutputFormat.setOutputPath(job,new Path(otherArgs[otherArgs.length - 1]));\t\tSystem.exit(job.waitForCompletion(true) ? 0 : 1);\t&#125;&#125;编译写好的程序，并打包。没问题的话，会在文件夹里看到生成的Score.jarjavac Score.javajar cvf Score.jar *.class执行程序，hadoop会读取input1的数据，将输出文件放到output1中。\n\n在执行这步时，可能会遇到各种各样的问题，多查一查，网上都会有解决方法的。当然，重装可以解决百分之五十的问题:yum:hadoop jar Score.jar Score /input1 /output1最后，能在output1里看到两个文件，part-r-00000是最终结果。如果要多次运行，记得每次运行前把output文件夹删了，否则会由于文件夹存在报错。hadoop fs -ls /output1hadoop fs -cat /output1/part-r-00000在命令行打开应该会乱码，打开http://localhost:9870/explorer.html#/output1下载下来。最终结果\n\n问题二思路和问题一直，把学生姓名换成课程名称+班级就行了cScore.javaimport java.io.IOException;import java.util.StringTokenizer;import org.apache.hadoop.conf.Configuration;import org.apache.hadoop.fs.Path;import org.apache.hadoop.io.FloatWritable;import org.apache.hadoop.io.IntWritable;import org.apache.hadoop.io.Text;import org.apache.hadoop.mapreduce.Job;import org.apache.hadoop.mapreduce.Mapper;import org.apache.hadoop.mapreduce.Reducer;import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;import org.apache.hadoop.util.GenericOptionsParser;public class cScore &#123;\tpublic static class cSMap extends Mapper&lt;Object, Text, Text, IntWritable&gt; &#123;\t\tpublic void map(Object key, Text value, Context context) throws IOException, InterruptedException &#123;\t\t\tString[] split=value.toString().split(&quot;,&quot;);\t\t\tString room=split[0];\t\t\tString course=split[2];\t\t\tString Name=course+&quot; &quot;+room;\t\t\tint Score=Integer.parseInt(split[4]);\t\t\tcontext.write(new Text(Name),new IntWritable(Score));\t\t&#125;\t&#125;\tpublic static class cSReducer extends Reducer&lt;Text,IntWritable,Text,FloatWritable&gt; &#123;\t\tpublic void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException &#123;\t\t\tint sum = 0;\t\t\tint count=0;\t\t\tfor (IntWritable val : values) &#123;\t\t\t\tsum += val.get();\t\t\t\tcount++;\t\t\t&#125;\t\t\tfloat average=sum/(float)count;\t\t\tcontext.write(key,new FloatWritable(average));\t\t&#125;\t&#125;\tpublic static void main(String[] args) throws Exception &#123;\t\tConfiguration conf = new Configuration();\t\tString[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();\t\tif (otherArgs.length &lt; 2) &#123;\t\t  System.err.println(&quot;Usage: cScore&lt;in&gt; [&lt;in&gt;...] &lt;out&gt;&quot;);\t\t  System.exit(2);\t\t&#125;\t\tJob job = Job.getInstance(conf, &quot;cscore&quot;);\t\tjob.setJarByClass(cScore.class);\t\tjob.setMapperClass(cSMap.class);\t\tjob.setReducerClass(cSReducer.class);\t\tjob.setOutputKeyClass(Text.class);\t\tjob.setOutputValueClass(IntWritable.class);\t\tfor (int i = 0; i &lt; otherArgs.length - 1; ++i) &#123;\t\t\tFileInputFormat.addInputPath(job, new Path(otherArgs[i]));\t\t&#125;\t\tFileOutputFormat.setOutputPath(job,new Path(otherArgs[otherArgs.length - 1]));\t\tSystem.exit(job.waitForCompletion(true) ? 0 : 1);\t&#125;&#125;运行方法和上面一直javac cScore.javajar cvf cScore.jar *.classhadoop fs -mkdir /input1hadoop fs -put input1.txt /input1hadoop jar cScore.jar cScore /input1 /output2最后，能在output2里找到最终结果part-r-00000。打开http://localhost:9870/explorer.html#/output2下载下来。最终结果\n","tags":["Java","分布式","Hadoop","MapReduce"]},{"title":"Hadoop|在Windows上安装Hadoop及WordCount示例","url":"/2019/05/27/hadoop/","content":"Hadoop集群安装\n什么是Hadoop　　Hadoop是一款支持数据密集型分布式应用程序并以Apache 2.0许可协议发布的开源软件框架。它支持在商品硬件构建的大型集群上运行的应用程序。Hadoop是根据谷歌公司发表的MapReduce和Google文件系统的论文自行实现而成。所有的Hadoop模块都有一个基本假设，即硬件故障是常见情况，应该由框架自动处理。\n　　Hadoop框架透明地为应用提供可靠性和数据移动。它实现了名为MapReduce的编程范式：应用程序被分割成许多小部分，而每个部分都能在集群中的任意节点上运行或重新运行。此外，Hadoop还提供了分布式文件系统，用以存储所有计算节点的数据，这为整个集群带来了非常高的带宽。MapReduce和分布式文件系统的设计，使得整个框架能够自动处理节点故障。它使应用程序与成千上万的独立计算的计算机和PB级的数据连接起来。\n以上内容来自维基百科。不过对于我来说，开始学习某一套技术只有当我亲自动手实践后，才能真正理解这套技术解决了什么问题，并且有益于后续的学习。下来就让我们开始吧！\nWindows安装环境：操作系统：Windows 10JDK版本：JDK 1.8以上的Java开发和运行环境\nHadoop配置1 先检查下自己的配置环境，主要是JDK版本2 下载进制压缩包文件:hadoop-3.0.0.tar.gz 3 下载针对Windows环境的Hadoop修正程序:winutils-master.zip4 将hadoop-3.0.0.tar.gz解压至 C:\\Soft\\Hadoop（可以根据自己喜好更改Hadoop安装目录）5 新增环境变量HADOOP_HOME（作为系统变量），并将其值设为C:\\Soft\\Hadoop\\bin(这里根据你自己解压的位置设置)（设置方法：进入“控制面板\\系统和安全\\系统”，然后点击“高级系统设置”，然后点击“环境变量(N)..”按钮）6 观察JAVA_HOME变量设置是否正确，这个后面会用到。7 将C:\\Soft\\Hadoop\\bin路径添加到Path环境变量。(这是本人的，记得换成自己的)8 将如下内容粘贴到..\\Hadoop\\etc\\hadoop\\core-site.xml文件&lt;configuration&gt;    &lt;property&gt;    &lt;name&gt;fs.defaultFS&lt;/name&gt;    &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;9 将如下内容粘贴到..\\Hadoop\\etc\\hadoop\\mapred-site.xml文件&lt;configuration&gt;    &lt;property&gt;    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;    &lt;value&gt;yarn&lt;/value&gt;    &lt;/property&gt;&lt;/configuration&gt;10 在..\\Hadoop路径下创建“data”子目录；在..\\Hadoop\\data路径下创建“namenode”子目录；在..\\Hadoop\\data路径下创建“datanode”子目录。11 将如下内容粘贴到..\\Hadoop\\etc\\hadoop\\hdfs-site.xml文件（里面的路径记得换成自己的）&lt;configuration&gt;   &lt;property&gt;       &lt;name&gt;dfs.replication&lt;/name&gt;       &lt;value&gt;1&lt;/value&gt;   &lt;/property&gt;   &lt;property&gt;       &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;       &lt;value&gt;file:///C:/Soft/hadoop/data/namenode&lt;/value&gt;   &lt;/property&gt;   &lt;property&gt;       &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;       &lt;value&gt;file:///C:/Soft/hadoop/data/datanode&lt;/value&gt;   &lt;/property&gt;&lt;/configuration&gt;12 将如下内容粘贴到..\\Hadoop\\etc\\hadoop\\yarn-site.xml文件&lt;configuration&gt;   &lt;property&gt;    \t&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;    \t&lt;value&gt;mapreduce_shuffle&lt;/value&gt;   &lt;/property&gt;   &lt;property&gt;      \t&lt;name&gt;yarn.nodemanager.auxservices.mapreduce.shuffle.class&lt;/name&gt;  \t&lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;   &lt;/property&gt;&lt;/configuration&gt;13 编辑文件C:\\Hadoop\\etc\\hadoop\\hadoop-env.cmd：把“set JAVA_HOME=%JAVA_HOME%”修改为“set JAVA_HOME=C:\\PROGRA~1\\Java\\自己的jdk版本”可以回到第6步看一下，本人的是jdk1.8.0_20114 C:\\Hadoop\\bin目录下的内容删除。15 将第3步下载的“winutils-master.zip”解压，然后将解压文件中“..\\winutils-master\\hadoop-3.0.0\\bin”目录下的内容拷贝到“..\\Hadoop\\bin”目录。\n测试到此为止，Hadoop的安装就完成了，接下来运行几个命令测试Hadoop是否可以正常运行1 打开终端cd ..\\Hadoop\\bin2 先对HDFS分布式文件系统进行格式化。hdfs namenode –format如果成功，能看到下面这句INFO common.Storage: Storage directory C:\\Soft\\hadoop\\data\\namenode has been successfully formatted3 输入下面的命令。如果一切正常，将会启动一个“hdfs namenode”进程和一个“hdfs datanode”进程，构成了只有1个主节点和1个从节点的“HDFS分布式文件系统集群”。可以通过http://localhost:9870监控HDFS系统。cd ..\\Hadoop\\sbinstart-dfs4 关闭HDFS分布式文件系统。cd ..\\Hadoop\\sbinstop-dfs\nWordCount示例的使用首先，以管理员身份启动命令行，进到sbin文件夹下cd C:\\Soft\\Hadoop\\sbin启动Hadoopstart-all如果正常的话会打开四个窗口新建一个txt文件作为数据样本test.txthelloworldqitstopsdfappleEAsteamorange在Hadoop中新建一个test文件夹hadoop fs -mkdir /test\n将test.txt上传到test文件夹中，查看一下hadoop fs -put C:\\Else\\test.txt \\testhadoop fs -ls /hadoop fs -ls /test到此准备工作就已经做完了。\nWordCount是Hadoop自带的一个示例程序，在../Hadoop\\share\\hadoop\\mapreduce文件夹下能找到名称里带有examples的jar包hadoop jar C:\\Soft\\Hadoop\\share\\hadoop\\mapreduce\\hadoop-mapreduce-examples-3.0.0.jar wordcount \\test \\output运行完成后能在output文件夹下看的两个文件，最终的结果就存在part-r-00000中hadoop fs -ls /outputhadoop fs -cat /output/part-r-00000输入结束命令，关闭系统stop-all\nLinux安装环境：\n\n操作系统：Centos 7\nJDK版本：JDK 1.8以上的Java开发和运行环境\n\nCentos 7 下载地址：https://mirrors.aliyun.com/centos/7/isos/x86_64/CentOS-7-x86_64-DVD-2009.iso\n\nVM虚拟机安装时记得配置网络和主机名！！！\n修改网络配置文件vi /etc/sysconfig/network-scripts/ifcfg-ens33\n按i开始编辑，按esc后输入:wq保存退出（:q不保存退出）TYPE=&quot;Ethernet&quot;PROXY_METHOD=&quot;none&quot;BROWSER_ONLY=&quot;no&quot;#BOOTPROTO=&quot;dhcp&quot;BOOTPROTO=&quot;static&quot;DEFROUTE=&quot;yes&quot;IPV4_FAILURE_FATAL=&quot;no&quot;IPV6INIT=&quot;yes&quot;IPV6_AUTOCONF=&quot;yes&quot;IPV6_DEFROUTE=&quot;yes&quot;IPV6_FAILURE_FATAL=&quot;no&quot;IPV6_ADDR_GEN_MODE=&quot;stable-privacy&quot;NAME=&quot;ens33&quot;UUID=&quot;84be3b82-7dd7-45ae-a35c-62f84b9f1c1c&quot;DEVICE=&quot;ens33&quot;ONBOOT=&quot;yes&quot;IPADDR=192.168.142.131NETMASK=255.255.255.0GATEWAY=192.168.142.2DNS1=114.114.114.114其中IPADDR根据自己的虚拟网络编辑器的NAT模式中子网地址填写，NETMASK为子网掩码，GATEWAY为网关。\n\n重启网络，测试网络链接systemctl restart networkping www.baidu.com切换阿里源mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bak curl -o /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo\n重命名主机名hostnamectl set-hostname hadoop01安装 epel-release\n\nExtra Packages for Enterprise Linux 是为“红帽系”的操作系统提供额外的软件包，适用于 RHEL、CentOS 和 Scientific Linux。相当于是一个软件仓库，大多数 rpm 包在官方 repository 中是找不到的）\n\nyum install -y epel-release\n关闭防火墙 ，关闭防火墙开机自启systemctl stop firewalldsystemctl disable firewalld.service\n使用拷贝在 hadoop103 上操作，将 hadoop102 中/opt/module 目录下所有目录拷贝到hadoop104 上。scp -r leokadia@hadoop102:/opt/module/* leokadia@hadoop104:/opt/module\n同步同步 hadoop102 中的/opt/module/hadoop-3.1.3 到 hadoop103rsync -av hadoop-3.1.3/ leokadia@hadoop103:/opt/module/hadoop-3.1.3//home/MQ/bin目录下# hadoop集群启停myhadoop.sh startmyhadoop.sh stop# 查看三台服务器 Java 进程脚本jpsall\n附录代码|操作|-|-|hadoop fs –ls / |    显示根目录下的所有文件和目录|hadoop fs –mkdir /test|    创建子目录/test，创建多级目录 加上 –p|hadoop fs -rm /test1.txt|    删除文件|hadoop fs -rm -r /test|    删除子目录（要加-r参数）|hadoop fs -put C:\\tmp\\test.txt \\test|    将本地文件上传到HDFS分布式文件系统|hadoop fs -cat \\test\\test.txt|    查看文件内容|hadoop fs -cp URI [URI …] |    cp 复制系统内文件|hadoop fs -get[-ignorecrc] [-crc] |    下载文件到本地|hadoop fs -mv URI [URI …] |    将文件从源路径移动到目标路径|hadoop fs -du URI [URI …]|    显示文件大小|\n","tags":["分布式","Hadoop","Windows","Linux"]},{"title":"Python|粒子群算法实现","url":"/2019/05/20/pso/","content":"粒子群算法，也称粒子群优化算法或鸟群觅食算法（Particle Swarm Optimization），缩写为PSO\n介绍粒子群算法（PSO）是模拟群体智能所建立起来的一种优化算法，主要用于解决最优化问题。基本思想是通过群体中个体之间的协作和信息共享来寻找最优解\n算法是模拟鸟群或蜂群的觅食行为。假设这样一个问题：一群鸟在随机的搜索食物，在一块区域里只有一块食物，所有的鸟都不知道食物在哪。但是它们知道自己的当前位置距离食物有多远。那么这群鸟找到食物的最优策略就是搜寻目前离食物最近的鸟的周围区域。\n基本概念粒子群算法就是对上面问题的一个抽象。\n\n每个鸟抽象为一个无质量，无体积的“粒子”\n每个粒子有一个适应度函数以模拟每只鸟与食物的距离\n每个粒子有一个速度决定它的飞行方向和距离，初始值可以随机确定\n每一次单位时间的飞行后，所有粒子分享信息，下一步将飞向自身最佳位置和全局最优位置的加权中心\n\n初始化为一群随机粒子，通过迭代找到最优。每次迭代中，粒子通过跟踪“个体极值（pbest）”和“全局极值(gbest)”来更新自己的位置。\n举个例子，假设在D维搜索空间中，有m个粒子其中第i个粒子的位置为矢量，记$\\vec{x}i=(x{i1},x{i2},\\ldots,x{iD})$其飞翔速度也是一个矢量，记$\\vec{v}i=(v{i1},v{i2},\\ldots,v{iD})$第i个粒子搜索到的最优位置为$\\vec{p}i=(p{i1},p{i2},\\ldots,p{iD})$整个粒子群搜索到的最优位置为$\\vec{p}{gbest}=(p{gbest1},p{gbest2},\\ldots,p{gbestD})$\n第i个粒子的位置和速度更新为$v{id}^{k+1}=wv{id}^{k}+c1rand()(p{id}-x{id}^k)+c_2rand()(p{gbest}-x{id}^k)$$x{id}^{k+1}=x{id}^{k}+v{id}^{k} \\qquad i=1,2,\\ldots,m \\quad d=1,2,\\ldots,D$其中，$w$称为惯性权重;$c1$和$c_2$为两个正常系数，称为加速因子;$rand()$为(0,1)之间的随机数;$v{id}^{k}$限制在一个最大速度$v_{max}$内。\n简单解释一下：\n\n惯性权重$w$   使粒子保持运动惯性，使其有扩展搜索空间的趋势，有能力探索新的区域。   表示微粒对当前自身运动状态的信任，依据自身的速度进行惯性运动。   较大的w有利于跳出局部极值，而较小的w有利于算法收敛。\n加速常数$c_1$和$c_2$  将c1和c2统一为一个控制参数，φ= c1+c2  如果φ很小，粒子群运动轨迹将非常缓慢；  如果φ很大，则微粒位置变化非常快；  实验表明，当φ=4.1（通常c1=2.0，c2=2.0）时，具有很好的收敛效果。\n最大速度$v_{max}$  决定粒子在一个循环中最大的移动距离，通常设定为粒子的范围宽度。\n粒子数  一般取20～40，对较难或特定类别的问题可以取100～200。\n\n算法流程PSO算法思想很简单，先初始化为一群随机粒子，通过迭代找到最优。每次迭代中，粒子通过跟踪“个体极值（pbest）”和“全局极值(gbest)”来更新自己的位置，当最大循环数以及最小错误要求停止。\n算法实现例子：$f(x)=x_1^2+x_2^2 \\qquad x_1,x_2 \\in[-10,10]$，求解最小值\n\n先建立一个PSO类，我们所要做的步骤，分别是设置参数，初始化种群，设置目标函数，进行迭代更新粒子位置class PSO():    # ----------------------初始化种群-------------------------    def __init__(self):        pass    #  ----------------------目标函数---------------------------    def function(self, x):        pass    # ----------------------更新粒子位置------------------------    def iterator(self):        pass\n初始化参数def __init__(self, pN, max_steps, dim=2, bound=[-10, 10], v_max=2, w=0.6, c1=2, c2=2):    self.pN = pN    self.dim = dim    self.steps = max_steps    self.w = w    self.c1 = c1    self.c2 = c2    self.x_bound = bound    self.x = np.random.uniform(self.x_bound[0], self.x_bound[1], (self.pN, self.dim))    self.v = np.random.rand(self.pN, self.dim) * v_max    self.pbest = self.x  # 个体的最佳位置    fitness = self.function(self.x)    self.gbest = self.x[np.argmin(fitness)]  # 全局最佳位置    self.p_fit = fitness  # 每个个体最佳适应值    self.fit = np.max(fitness)  # 全局最佳适应值\n设置目标函数def function(self, x):    return np.sum(np.square(x), axis=1)\n更新粒子位置def iterator(self):    for step in range(self.steps):        # self.g_fit[step] = self.fit        r1 = np.random.rand(self.pN, self.dim)        r2 = np.random.rand(self.pN, self.dim)        self.v = self.w * self.v + self.c1 * r1 * (self.pbest - self.x) + self.c2 * r2 * (self.gbest - self.x)        self.x = self.v + self.x        fitness = self.function(self.x)        plt.clf()        plt.scatter(self.x[:, 0], self.x[:, 1], c=&#x27;k&#x27;)        plt.scatter(self.gbest[0], self.gbest[1], c=&#x27;r&#x27;)        plt.xlim(self.x_bound[0], self.x_bound[1])        plt.ylim(self.x_bound[0], self.x_bound[1])        plt.pause(0.01)        update = np.greater(self.p_fit, fitness)        self.pbest[update] = self.x[update]        self.p_fit[update] = fitness[update]        if np.min(fitness) &lt; self.fit:            self.gbest = self.x[np.argmin(fitness)]            self.fit = np.min(fitness)\n最后进行一个测试if __name__ == &quot;__main__&quot;:    pso = PSO(100, 100, 2)    pso.iterator()    pso.show()\n\n粒子群算法是对现实中规律的总结和应用，具体怎么使用还要看我们遇到的问题，和对问题的理解\n\n\n\n代码import numpy as npimport matplotlib.pyplot as pltclass PSO():    # ----------------------初始化种群-------------------------    def __init__(self, pN, max_steps, dim=2, bound=[-10, 10], v_max=1, w=0.6, c1=2, c2=2):        self.pN = pN        self.dim = dim        self.steps = max_steps        self.w = w        self.c1 = c1        self.c2 = c2        self.x_bound = bound        self.x = np.random.uniform(self.x_bound[0], self.x_bound[1], (self.pN, self.dim))        self.v = np.random.rand(self.pN, self.dim) * v_max        self.pbest = self.x  # 个体的最佳位置        fitness = self.function(self.x)        self.gbest = self.x[np.argmin(fitness)]  # 全局最佳位置        self.p_fit = fitness  # 每个个体最佳适应值        self.fit = np.max(fitness)  # 全局最佳适应值        # self.g_fit = np.zeros((self.steps,1))    #  ----------------------目标函数---------------------------    def function(self, x):        return np.sum(np.square(x), axis=1)    # ----------------------更新粒子位置------------------------    def iterator(self):        for step in range(self.steps):            # self.g_fit[step] = self.fit            r1 = np.random.rand(self.pN, self.dim)            r2 = np.random.rand(self.pN, self.dim)            self.v = self.w * self.v + self.c1 * r1 * (self.pbest - self.x) + self.c2 * r2 * (self.gbest - self.x)            self.x = self.v + self.x            fitness = self.function(self.x)            plt.clf()            plt.scatter(self.x[:, 0], self.x[:, 1], c=&#x27;k&#x27;)            plt.scatter(self.gbest[0], self.gbest[1], c=&#x27;r&#x27;)            plt.xlim(self.x_bound[0], self.x_bound[1])            plt.ylim(self.x_bound[0], self.x_bound[1])            plt.pause(0.01)            update = np.greater(self.p_fit, fitness)            self.pbest[update] = self.x[update]            self.p_fit[update] = fitness[update]            if np.min(fitness) &lt; self.fit:                self.gbest = self.x[np.argmin(fitness)]                self.fit = np.min(fitness)    def show(self):        print(&quot;最佳位置：&quot;, self.gbest)        print(&quot;最优解：&quot;, self.fit)        plt.show()if __name__ == &quot;__main__&quot;:    pso = PSO(100, 100, 2)    pso.iterator()    pso.show()","tags":["Python","PSO"]},{"title":"Docker|Docker的安装及简单使用","url":"/2019/05/20/docker/","content":"本文的安装环境为win10专业版\n安装注意：适用于Windows的Docker需要运行Microsoft Hyper-V。\n先到控制面板-&gt;程序与功能-&gt;启用或关闭Windows功能中查看自己是否开启Hyper-V可以从官网下载，但是在国内会比较慢。可以点击这里下载。下载完成后，一路next即可，最终结果在命令行中测试一下\n使用运行docker run hello-world以测试从Docker Hub中拉取镜像并启动容器docker run hello-world删除镜像docker image docker rmi id\n例子用Dockerfile定义一个镜像，输出hello world\n首先新建一个文件夹，文件夹里放入三个文件app.pyfrom flask import Flaskfrom redis import Redis, RedisErrorimport osimport socketredis = Redis(host=&quot;redis&quot;, db=0, socket_connect_timeout=2, socket_timeout=2)app = Flask(__name__)@app.route(&quot;/&quot;)def hello():    try:        visits = redis.incr(&quot;counter&quot;)    except RedisError:        visits = &quot;&lt;i&gt;cannot connect to Redis, counter disabled&lt;/i&gt;&quot;    html = &quot;&lt;h3&gt;Hello &#123;name&#125;!&lt;/h3&gt;&quot; \\           &quot;&lt;b&gt;Hostname:&lt;/b&gt; &#123;hostname&#125;&lt;br/&gt;&quot; \\           &quot;&lt;b&gt;Visits:&lt;/b&gt; &#123;visits&#125;&quot;    return html.format(name=os.getenv(&quot;NAME&quot;, &quot;world&quot;), hostname=socket.gethostname(), visits=visits)if __name__ == &quot;__main__&quot;:    app.run(host=&#x27;0.0.0.0&#x27;, port=80)DockerfileFROM python:3.6-slimWORKDIR /appADD . /appRUN pip install --trusted-host mirrors.aliyun.com --index http://mirrors.aliyun.com/pypi/simple/ -r requirements.txtEXPOSE 80ENV NAME WorldCMD [&quot;python&quot;, &quot;app.py&quot;]requirements.txtFlaskRedis打开命令行cd 文件夹docker build -t firstapp .创建完成后，在镜像列表里就能看到了运行应用docker run -p 4040:80 firstapp\n大功告成！！！[&gt;_&lt;]\n","tags":["Docker"]},{"title":"Python|降维算法PCA和LDA的实现及总结","url":"/2019/05/19/%E9%99%8D%E7%BB%B4/","content":"以Iris数据集为例，分别实现PCA和LDA降维\nPCA算法原理主成分分析（Principal Component Analysis，PCA）是一种常用的线性降维数据分析方法，其实质是在能尽可能好的代表原特征的情况下，将原特征进行线性变换、映射至低纬度空间中。\n\n至于更详细的的可以看下面的PCA原理小结PCA(主成分分析)详解主成分分析（PCA）原理详解PCA降维操作\n\n算法实现首先将数据做中心化处理meanVal = np.mean(X, axis=0)W = X - meanVal这里说一下，中心化就是使得样本矩阵的中心回归到坐标系的原点，看下图应该比较好理解。也可以点这里更详细。\n计算中心化后数据的协方差矩阵covMat = np.cov(W, rowvar=0)计算协方差矩阵的特征值和特征向量eigVals, eigVects = np.linalg.eig(np.mat(covMat))找出特征值最大的k个特征所对应的特征向量，并组成向量TE = np.argsort(eigVals)k_E = E[:-(k + 1):-1]T = eigVects[:, k_E]Y=W*T即为降维到k维后的数据Y = W * T\n结果PCA算法def MyPca(X,k):    meanVal = np.mean(X, axis=0)    W = X - meanVal    covMat = np.cov(W, rowvar=0)    eigVals, eigVects = np.linalg.eig(np.mat(covMat))    E = np.argsort(eigVals)    k_E = E[:-(k + 1):-1]    T = eigVects[:, k_E]    Y = W * T    return Y带入Iris数据集data = load_iris()y = data.target #标签X = data.data带入数据，输出结果reduced_X = np.array(MyPca(X, 2))show2(reduced_X)\nLDA算法原理线性判别分析(linear discriminant analysis，LDA)是是一种监督学习的降维技术，投影后希望类内方差最小，类间方差最大，即每一种类别数据的投影点尽可能的接近，而不同类别的数据的类别中心之间的距离尽可能的大。\n\n这里推荐几篇文章，有更详细的数学推导线性判别分析（Linear Discriminant Analysis）（一）线性判别分析（Linear Discriminant Analysis）（二）\n\n算法实现首先将数据根据标签分类yi = set(y)xi = np.array([X[np.where(y == i)] for i in yi])计算所有样本均值$\\mu=\\frac{1}{m}\\sum\\limits{i=1}^m$和各类样本均值$\\mu_i=\\frac{1}{n_i}\\sum\\limits{x\\in xi}x$其中$m$表示总样本数，$n_i$表示第i类的样本数。u = np.array([np.mean(X, axis=0)])ui = np.array([np.mean(xi[i], axis=0) for i in range(xi.shape[0])])计算类内散度矩阵$S_w=\\sum\\limits{i=1}^c\\sum\\limits{x\\in x_i}(x-\\mu_i)(x-\\mu_i)^T$及类间散度矩阵$S_b=\\sum\\limits{i=1}^cn_i(\\mu_i-\\mu)(\\mu_i-\\mu)^T$其中$c$表示类别数。Sw = sum(np.dot((xi[i] - ui[i]).T, (xi[i] - ui[i])) for i in range(len(yi)))Sb = sum(len(xi[i]) * (ui[i].reshape(1, 4) - u).T * (ui[i].reshape(1, 4) - u) for i in range(len(yi)))计算$S_w^{-1}S_b$(由于$S_b$的秩最大为$c-1$，所以LDA最大只能降到$c-1$的维度)S=np.linalg.inv(Sw).dot(Sb)r=np.linalg.matrix_rank(S)if(k&gt;r):    print(&quot;k_max=&quot;,r)    k=r找出特征值最大的k个特征所对应的特征向量，并组成向量$W$，$Y=W*X$即为降维到k维后的数据eigVals, eigVects = np.linalg.eig(S)E = np.argsort(eigVals)k_E = E[:-(k + 1):-1]W = eigVects[:, k_E]Y=np.dot(X, W)\n结果LDA算法def MyLDA(X,y,k):    yi = set(y)    xi = np.array([X[np.where(y == i)] for i in yi])    u = np.array([np.mean(X, axis=0)])    ui = np.array([np.mean(xi[i], axis=0) for i in range(xi.shape[0])])    Sw = sum(np.dot((xi[i] - ui[i]).T, (xi[i] - ui[i]))             for i in range(len(yi)))    Sb = sum(len(xi[i]) * (ui[i].reshape(1, 4) - u).T * (ui[i].reshape(1, 4) - u)             for i in range(len(yi)))    S=np.linalg.inv(Sw).dot(Sb)    r=np.linalg.matrix_rank(S)    if(k&gt;r):        print(&quot;k_max=&quot;,r)        k=r    eigVals, eigVects = np.linalg.eig(S)    E = np.argsort(eigVals)    k_E = E[:-(k + 1):-1]    W = eigVects[:, k_E]    Y=np.dot(X, W)    return Y带入数据，输出结果LDA_2D = np.array(MyLDA(X,y,2))show2(LDA_2D)\n这样就将数据降到二维，但可能有人会疑惑，怎么知道降维后的信息量变化了多少呢？可以用这样的计算方法: $\\etak=\\frac{\\sum{j=1}^k\\lambdaj}{\\sum{j=1}^k\\lambda_j}$来表示降维后剩余的信息量\n总结总的来说，PCA和LDA的实现很简单，但是基本原理和推导需要扎实的数学基础，尤其是LDA中，尤其要注意矩阵的秩对结果的影响。PCA和LDA虽然都用到数据降维的思想，但是两者有着很大的不同，首先监督方式不一样，LDA是有监督的降维方法，而PCA是无监督的降维方法；再者目的也不一样，PCA是为了去除原始数据集中冗余的维度，让投影子空间的各个维度的方差尽可能大。而LDA是通过数据降维使得原始数据中不同的类别尽可能区分开来。\n代码import matplotlib.pyplot as pltfrom mpl_toolkits.mplot3d import Axes3Dimport numpy as npfrom sklearn.datasets import load_irisdef MyPCA(X,k):    meanVal = np.mean(X, axis=0)    W = X - meanVal    covMat = np.cov(W, rowvar=0)    eigVals, eigVects = np.linalg.eig(np.mat(covMat))    E = np.argsort(eigVals)    k_E = E[:-(k + 1):-1]    T = eigVects[:, k_E]    n = sum(eigVals[k_E])/sum(eigVals)    print(&quot;降到&quot;,k,&quot;维后保留的信息量是原来的&quot;,n * 100.0, &quot;%&quot;)    Y = W * T    return Ydef MyLDA(X,y,k):    yi = set(y)    xi = np.array([X[np.where(y == i)] for i in yi])    u = np.array([np.mean(X, axis=0)])    ui = np.array([np.mean(xi[i], axis=0) for i in range(xi.shape[0])])    Sw = sum(np.dot((xi[i] - ui[i]).T, (xi[i] - ui[i]))             for i in range(len(yi)))    Sb = sum(len(xi[i]) * (ui[i].reshape(1, 4) - u).T * (ui[i].reshape(1, 4) - u)             for i in range(len(yi)))    S=np.linalg.inv(Sw).dot(Sb)    r=np.linalg.matrix_rank(S)    if(k&gt;r):        print(&quot;k_max=&quot;,r)        k=r    eigVals, eigVects = np.linalg.eig(S)    E = np.argsort(eigVals)    k_E = E[:-(k + 1):-1]    W = eigVects[:, k_E]    n = sum(eigVals[k_E]) / sum(eigVals)    print(&quot;降到&quot;, k, &quot;维后保留的信息量是原来的&quot;, n * 100.0, &quot;%&quot;)    Y=np.dot(X, W)    return Ydef show2(reduced_X):    red_x, red_y = [], []    blue_x, blue_y = [], []    green_x, green_y = [], []    for i in range(len(reduced_X)):        if y[i] == 0:            red_x.append(reduced_X[i][0])            red_y.append(reduced_X[i][1])        elif y[i] == 1:            blue_x.append(reduced_X[i][0])            blue_y.append(reduced_X[i][1])        else:            green_x.append(reduced_X[i][0])            green_y.append(reduced_X[i][1])    plt.scatter(red_x, red_y, c=&#x27;r&#x27;, marker=&#x27;x&#x27;)    plt.scatter(blue_x, blue_y, c=&#x27;b&#x27;, marker=&#x27;*&#x27;)    plt.scatter(green_x, green_y, c=&#x27;g&#x27;, marker=&#x27;.&#x27;)    # plt.show()def show3(X):    red_x, red_y, red_z = [], [], []    blue_x, blue_y, blue_z = [], [], []    green_x, green_y, green_z = [], [], []    for i in range(len(X)):        if y[i] == 0:            red_x.append(X[i][0])            red_y.append(X[i][1])            red_z.append(X[i][2])        elif y[i] == 1:            blue_x.append(X[i][0])            blue_y.append(X[i][1])            blue_z.append(X[i][2])        else:            green_x.append(X[i][0])            green_y.append(X[i][1])            green_z.append(X[i][2])    fig = plt.figure()    ax = fig.gca(projection=&#x27;3d&#x27;)    ax.scatter(red_x, red_y, red_z, c=&#x27;r&#x27;, marker=&#x27;x&#x27;)    ax.scatter(blue_x, blue_y, blue_z, c=&#x27;b&#x27;, marker=&#x27;*&#x27;)    ax.scatter(green_x, green_y, green_z, c=&#x27;g&#x27;, marker=&#x27;.&#x27;)    # plt.show()if __name__ == &quot;__main__&quot;:    data = load_iris()    y = data.target    X = data.data    #PCA    #降到2维    PCA_2D = np.array(MyPCA(X, 2))    show2(PCA_2D)    # 降到3维    PCA_3D = np.array(MyPCA(X, 3))    show3(PCA_3D)    plt.show()    #LDA    # 降到2维    LDA_2D = np.array(MyLDA(X,y,2))    show2(LDA_2D)    plt.show()\n如有错误，欢迎指正；如果有更好的，欢迎分享。\n","tags":["Python","PCA","LDA"]},{"title":"JAVA|简单的Web Service","url":"/2019/05/16/%E5%88%86%E5%B8%83%E5%BC%8F4/","content":"编写Web Service客户端程序。\n什么是Web Service？\n为方便网络上不同节点之间互操作而定义的一套协议标准， 也可视为实现远程过程调用的一套协议标准。(W3C)\n方便了Business to Business的业务集成。可以将多个第三方服务组合成一种新的服务。\nWeb系统功能被扩展：不只是用于共享文档，不只是为“看”；Web系统也被用于节点之间的互操作。\n客户端-服务器模式\n跨平台、跨语言、面向接口编程\n实现面向服务构架(SOA：Service-oriented Architecture)的重要技术之一\n\n主要包含的标准协议\n消息编码标准(XML)\n传输协议标准(HTTP、SMTP、TCP、UDP)\n远程对象访问协议（即远程方法调用协议）：SOAP(Simple Object Access Protocol):\nWeb服务描述语言：WSDL(Web Services Description Language)  （主要描述服务接口定义）\n服务目录、服务注册、服务发现：UDDI(Universal Discovery Description and Integration)\n安全相关标准：签名、加密、认证等\n服务组合、服务编排\n\nSOAP\nWSDL与UDDI\n实现与调用Web Service的流程服务端的实现\n用常用高级编程语言（例如Java）定义Web服务接口\n根据Java定义的Web服务接口生成WSDL（中间件自动做）\n定义实现接口的Web服务实现类\n将Web服务实现类绑定到Web服务器\n将Web服务注册的UDDI中心\n\n客户端的实现\n从UDDI中心查找的目标Web服务的接口定义（WSDL）\n根据WSDL生成Web服务代理类(WSDL to Java)\n利用Web服务代理类调用Web服务接口中定义的具体方法\n\n例子题目：到免费公开Web Service目录网站（如http://www.webxml.com.cn）上找到一种自己感兴趣的Web Service，如：天气预报服务、飞机航班时刻表查询服务、火车时刻表查询服务、邮政编码查询服务、中国股票行情查询、及时外汇查询等，编写一个该服务的调用客户端程序。\n\n实现过程1.首先在Web Services的网站中找到目标Web服务的接口定义。（我选的是IP地址，主要要的是WSDL那一行）拷贝网址http://ws.webxml.com.cn/WebServices/IpAddressSearchWebService.asmx?wsdl2.打开命令行输入命令，根据WSDL生成Web服务代理类cd 你的文件夹wsimport -keep -p wsproxy 你拷贝的网址（比如：http://ws.webxml.com.cn/WebServices/IpAddressSearchWebService.asmx?wsdl）在你的文件夹中会出现一个wsproxy文件夹3.利用Web服务代理类调用Web服务接口中定义的具体方法，编写客户端。这步比较麻烦，有接口说明的简单点，没有的就要根据上一步生成的文件猜测了。下面是我的，可以比较着写。4.最后，编译并运行客户端javac .\\wsclient\\*.javajava wsclient.CodeInfoClient(这里是我的客户端的位置和名称)\nPS: 第一步的网站是免费的，但里面的网址不是都可以用的，如果第二步出错，换个网址试试\n再举个例子QQ在线查询wsimport -keep -p wsproxy http://ws.webxml.com.cn/webservices/qqOnlineWebService.asmx?wsdlCodeInfoClient.javapackage wsclient;import wsproxy.*; public class CodeInfoClient &#123;     public static void main(String[] args) &#123;        QqOnlineWebService service = new QqOnlineWebService();        QqOnlineWebServiceSoap pService = service.getQqOnlineWebServiceSoap();                 System.out.println(pService.qqCheckOnline(&quot;QQ号&quot;));            &#125; &#125;\n","tags":["Java","分布式","Web"]}]